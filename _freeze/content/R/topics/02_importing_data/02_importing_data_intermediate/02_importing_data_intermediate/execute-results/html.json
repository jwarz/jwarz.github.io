{
  "hash": "ea8fb8789181e578ed443b837ad9c1a0",
  "result": {
    "markdown": "---\ntitle: \"Intermediate Importing Data in R\"\nauthor: \"Joschka Schwarz\"\n---\n\n\n\n\nIn this course, you will take a deeper dive into the wide range of data formats out there. More specifically, you'll learn how to import data from relational databases and how to import and work with data coming from the web. Finally, you'll get hands-on experience with importing data from statistical software packages such as SAS, STATA, and SPSS.\n\n# 1. Importing data from databases (Part 1)\n\nMany companies store their information in relational databases. The R community has also developed R packages to get data from these architectures. You'll learn how to connect to a database and how to retrieve data from it.\n\n## Connect to a database\n\nTheory. Coming soon ...\n\n**1. Connect to a database**\n\nWelcome to part two of importing data in R!\n\n**2. Up to now**\n\nThe previous course dealt with accessing data stored in flat files or Excel files. In a professional setting, you'll also encounter data stored in relational databases.\n\n**3. Relational Databases**\n\nIn this video, I'll briefly talk about what a relational database is, and then I'll explain how you can connect to it. In the next video, I'll explain how you can import data from it!So, what's a relational database? There's no better way to show this than with an example.\n\n**4. company**\n\nTake this database, called company. It contains three tables,\n\n**5. company**\n\nemployees,\n\n**6. company**\n\nproducts and\n\n**7. company**\n\nsales.Like a flat file, information is displayed in a table format. The employees table has 5 records and three fields, namely id, name and started_at. The id here serves as a unique key for each row or record. Next, the products table contains the details on four products. We're dealing with data from a telecom company that's selling both with and without a contract. Also here, each product has an identifier. Finally, there's the sales table. It lists what products were sold by who, when, and for what price. Notice here that the ids in\n\n**8. company**\n\nemployee_id and\n\n**9. company**\n\nproduct_id correspond to the ids that you can find in the employees and products table respectively.\n\n**10. company**\n\nThe third sale for example, was done by the employee with id 6, so Julie. She sold the product with id 9, so the Biz Unlimited contract.\n\n**11. company**\n\nThese relations make this database very powerful. You only store all necessary information once in nicely separated tables, but can connect the dots between different records to model what's happening.\n\n**12. Database Management System**\n\nHow the data in a relational database is stored and shuffled around when you make adaptations, depends on the so-called database management system, or DBMS you're using. Open-source implementations such as MySQL, postgreSQL and SQLite are very popular, but there are also proprietary implementations such as Oracle Database and Microsoft SQL server. Practically all of these implementations use SQL, or sequel, as the language for querying and maintaining the database. SQL stands for Structured Query Language.\n\n**13. Databases in R**\n\nDepending on the type of database you want to connect to, you'll have to use different packages. Suppose the company database I introduced before is a MySQL database. This means you'll need the RMySQL package. For postgreSQL you'll need RpostgreSQL, for Oracle, you'll use ROracle and so on. How you interact with the database, so which R functions you use to access and manipulate the database, is specified in another R package called DBI. In more technical terms, DBI is an interface, and RMySQL is the implementation. Let's install the RMySQL package, which automatically installs the DBI package as well. Loading only the DBI package will be enough to get started.\n\n**14. Connect to database**\n\nThe first step is creating a connection to the remote MySQL database. You do this with dbConnect, as follows.The first argument specifies the driver that you will use to connect to the MySQL database. It sure looks a bit strange, but the MySQL function from the RMySQL package simply constructs a driver for us that dbConnect can use. Next, you have to specify the database name, where the database is hosted, through which port you want to connect, and finally the credentials to authenticate yourself. This is an actual database that we're hosting, so you can try these commands yourself!The result of the dbConnect call, con, is a DBI connection object. You'll need to pass this object to whatever function you're using to interact with the database.\n\n## Establish a connection\n\nThe first step to import data from a SQL database is creating a connection to it. As Filip explained, you need different packages depending on the database you want to connect to. All of these packages do this in a uniform way, as specified in the `DBI` package.\n\n<a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbConnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbConnect()`</a> creates a connection between your R session and a SQL database. The first argument has to be a `DBIdriver` object, that specifies how connections are made and how data is mapped between R and the database. Specifically for MySQL databases, you can build such a driver with <a href=\"http://www.rdocumentation.org/packages/RMySQL/functions/MySQLDriver-class\" target=\"_blank\" rel=\"noopener noreferrer\">`RMySQL::MySQL()`</a>. \n\nIf the MySQL database is a remote database hosted on a server, you'll also have to specify the following arguments in <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbConnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbConnect()`</a>: `dbname`, `host`, `port`, `user` and `password`. Most of these details have already been provided.\n\n**Steps**\n\n1. Load the `DBI` library, which is already installed on DataCamp's servers.\n2. Edit the <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbConnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbConnect()`</a> call to connect to the MySQL database. Change the `port` argument (`3306`) and `user` argument (`\"student\"`).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the DBI package\nlibrary(DBI)\n\n# Edit dbConnect() call\ncon <- dbConnect(RMySQL::MySQL(), \n                 dbname = \"tweater\", \n                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\", \n                 port = 3306,\n                 user = \"student\",\n                 password = \"datacamp\")\n```\n:::\n\n\n## Inspect the connection\n\nNow that you've successfully created the database connection, let's have a closer look at it. \n\n> *Question*\n> ---\n> With the object `con` available in your workspace, can you tell which of the following statements is true?<br>\n> <br>\n> ⬜ `con` is an `SQLConnection` object.<br>\n> ⬜ `con` is a `PostgreSQLConnection` object.<br>\n> ✅ `con` is an `MySQLConnection` object.<br>\n> ⬜ `con` is an `NoSQLConnection` object.<br>\n\n## Import table data\n\nTheory. Coming soon ...\n\n**1. Import table data**\n\nAfter successfully connecting to a database,\n\n**2. con**\n\nlike this, you'll probably want to see what's in there.\n\n**3. List and import tables**\n\nThe first step is listing all the table in the database. You can do this with the dbListTables function. Simply pass the con variable.As expected, we get a character vector of length three, corresponding to the table names I've introduced earlier. Next, you can choose to actually read the data from one of these tables, for example from the employees table. You use the dbReadTable function for this. Again, you specify the connection to use, con, but this time you also specify which table data you want to import:The result is a data frame, with exactly the same contents as in the original database table.DBI also specifies functions to create new tables, store new data in tables and to remove tables, but this is not really related to importing data so I won't talk about that here. The functions we've covered up to now already provide a pretty good starting point. Oh no, wait, there's one last thing!It's always polite to explicitly disconnect your database after you're done. You do this with dbDisconnect, as follows.If you now try to print con, you'll see that it is no longer available. Good riddance,\n\n## List the database tables\n\nAfter you've successfully connected to a remote MySQL database, the next step is to see what tables the database contains. You can do this with the <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbListTables\" target=\"_blank\" rel=\"noopener noreferrer\">`dbListTables()`</a> function. As you might remember from the video, this function requires the connection object as an input, and outputs a character vector with the table names.\n\n**Steps**\n\n1. Add code to create a vector `tables`, that contains the tables in the tweater database. You can connect to this database through the `con` object.\n2. Display the structure of `tables`; what's the class of this vector?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Build a vector of table names: tables\ntables <- dbListTables(con)\n\n# Display structure of tables\nstr(tables)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>  chr [1:3] \"comments\" \"tweats\" \"users\"\n```\n:::\n:::\n\n\nGood! [`dbListTables()`](http://www.rdocumentation.org/packages/DBI/functions/dbListTables) can be very useful to get a first idea about the contents of your database. Can you guess what kind of information this database contains?\n\n## Import users\n\nAs you might have guessed by now, the database contains data on a more tasty version of Twitter, namely Tweater. Users can post tweats with short recipes for delicious snacks. People can comment on these tweats. There are three tables: **users**, **tweats**, and **comments** that have relations among them. Which ones, you ask? You'll discover in a moment!\n\nLet's start by importing the data on the users into your R session. You do this with the <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbReadTable\" target=\"_blank\" rel=\"noopener noreferrer\">`dbReadTable()`</a> function. Simply pass it the connection object (`con`), followed by the name of the table you want to import. The resulting object is a standard R data frame.\n\n**Steps**\n\n1 Add code that imports the `\"users\"` table from the tweater database and store the resulting data frame as `users`.\n2. Print the `users` data frame.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import the users table from tweater: users\nusers <- dbReadTable(con, \"users\")\n\n# Print users\nusers\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"name\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"login\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"elisabeth\",\"3\":\"elismith\"},{\"1\":\"2\",\"2\":\"mike\",\"3\":\"mikey\"},{\"1\":\"3\",\"2\":\"thea\",\"3\":\"teatime\"},{\"1\":\"4\",\"2\":\"thomas\",\"3\":\"tomatotom\"},{\"1\":\"5\",\"2\":\"oliver\",\"3\":\"olivander\"},{\"1\":\"6\",\"2\":\"kate\",\"3\":\"katebenn\"},{\"1\":\"7\",\"2\":\"anjali\",\"3\":\"lianja\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Import all tables\n\nNext to the `users`, we're also interested in the `tweats` and `comments` tables. However, separate `dbReadTable()` calls for each and every one of the tables in your database would mean a lot of code duplication. Remember about the `lapply()` function? You can use it again here! A connection is already coded for you, as well as a vector `table_names`, containing the names of all the tables in the database.\n\n\n**Steps**\n\n1. Finish the `lapply()` function to import the `users`, `tweats` and `comments` tables in a single call. The result, a list of data frames, will be stored in the variable `tables`.\n2. Print `tables` to check if you got it right.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Get table names\ntable_names <- dbListTables(con)\n\n# Import all tables\ntables <- lapply(table_names, dbReadTable, conn = con)\n\n# Print out tables\ntables\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [[1]]\n#>      id tweat_id user_id            message\n#> 1  1022       87       7              nice!\n#> 2  1000       77       7             great!\n#> 3  1011       49       5            love it\n#> 4  1012       87       1   awesome! thanks!\n#> 5  1010       88       6              yuck!\n#> 6  1026       77       4      not my thing!\n#> 7  1004       49       1  this is fabulous!\n#> 8  1030       75       6           so easy!\n#> 9  1025       88       2             oh yes\n#> 10 1007       49       3           serious?\n#> 11 1020       77       1 couldn't be better\n#> 12 1014       77       1       saved my day\n#> \n#> [[2]]\n#>   id user_id\n#> 1 75       3\n#> 2 88       4\n#> 3 77       6\n#> 4 87       5\n#> 5 49       1\n#> 6 24       7\n#>                                                                  post\n#> 1                                       break egg. bake egg. eat egg.\n#> 2                           wash strawberries. add ice. blend. enjoy.\n#> 3                       2 slices of bread. add cheese. grill. heaven.\n#> 4               open and crush avocado. add shrimps. perfect starter.\n#> 5 nachos. add tomato sauce, minced meat and cheese. oven for 10 mins.\n#> 6                              just eat an apple. simply and healthy.\n#>         date\n#> 1 2015-09-05\n#> 2 2015-09-14\n#> 3 2015-09-21\n#> 4 2015-09-22\n#> 5 2015-09-22\n#> 6 2015-09-24\n#> \n#> [[3]]\n#>   id      name     login\n#> 1  1 elisabeth  elismith\n#> 2  2      mike     mikey\n#> 3  3      thea   teatime\n#> 4  4    thomas tomatotom\n#> 5  5    oliver olivander\n#> 6  6      kate  katebenn\n#> 7  7    anjali    lianja\n```\n:::\n:::\n\n\nWonderful! Now that you have an R version of all data that is contained in the database, you can dive a little deeper into the relations between the different data frames.\n\n## How do the tables relate?\n\nThe connection to the MySQL database `con` has already been created for you. `tables`, a list containing the three tables as data frames that you've created in the previous exercise, is also available.\n\nIf you have a closer look at these tables, you'll see that the `tweats` table, for example, contains a column `user_id`. The ids in the column refer to the users that have posted the tweat. Similarly, the `comments` contain both a `user_id` and a `tweat_id` column. It specifies which user posted a comment on which tweat.\n\n> *Question*\n> ---\n> With this new knowledge, can you tell **who** posted the **tweat** on which somebody **commented** \"awesome! thanks!\" (comment 1012)?<br>\n> <br>\n> ⬜ The user with id 1, so Kate.<br>\n> ⬜ There is not enough information to solve this.<br>\n> ⬜ The user with id 4, so Thomas.<br>\n> ✅ The user with user_id 5, so Oliver.<br>\n\n\n# 2. Importing data from databases (Part 2)\n\nImporting an entire table from a database while you might only need a tiny bit of information seems like a lot of unncessary work. In this chapter, you'll learn about SQL queries, which will help you make things more efficient by performing some computations on the database side.\n\n## SQL Queries from inside R\n\nTheory. Coming soon ...\n\n\n**1. SQL Queries from inside R**\n\nSo, connecting to and importing from a database is something you're familiar with by now.\n\n**2. dbReadTable()**\n\nHowever, with dbReadTable,\n\n**3. dbReadTable()**\n\nyou're importing an entire table. For the company example that had little data, that's not a problem, but what if you're dealing with a database that contains tables with millions of records? You'd have to import the entire table into R before you can do an analysis that might only need a fraction of this data.\n\n**4. dbReadTable()**\n\nIf there was a way to perform a lot of the data selection work\n\n**5. dbReadTable()**\n\non the database side,\n\n**6. dbReadTable()**\n\nyou only have to import those elements that you actually need inside R. This makes much more sense, doesn't it?\n\n**7. Selective importing**\n\nI am glad to tell you that this is possible, all from inside R! Remember that relational databases typically use SQL as the language for querying? Well, you'll be writing so called SQL Queries to retrieve data based on specific criteria. You can send these queries through R functions specified by the DBI package and implemented by an R package that depends on the database you're using. As we're working with MySQL databases, that's RMySQL here. Writing SQL queries is a entire topic of its own, so I will only treat some basic examples so that you got the idea.\n\n**8. company**\n\nLet's have a look at the company database again, that contained informations on sales of telecom products made by different employees.\n\n**9. company**\n\nSuppose that we want to have the names of the employees that started after the first of september in 2012. How to go about this?\n\n**10. Load package and connect**\n\nIn any case, we have to start with loading the DBI package, and creating a connection to the company database. This is an actual database, so you can try the code in this video yourself!\n\n**11. Example 1**\n\nTo solve the task at hand, you can read the entire employees table, and then subset it using the subset function.But there is another way. Have a look at this call of the dbGetQuery function.The result is exactly the same. The strange syntax inside the string here, is actually a very common SQL query, that uses three SQL keywords: SELECT, FROM, and WHERE. The SELECT keyword specifies which column to select, and corresponds to the select argument in the subset function. The FROM keyword specifies which table you want to get data from, and corresponds to the first argument in the subset function. Finally, the WHERE keyword specifies a condition that a record in the table has to meet. If you read this sentence out loud with some additions here and there, it sounds pretty natural: \"Select the name column from the employees table, where the started_at field is greater than the first of september in 2012.\"The first approach and the second approach might seem similar, but the conceptual difference is huge.\n\n**12. Example 1**\n\nIn the first case,\n\n**13. Example 1**\n\nyou're importing the entire employees table,\n\n**14. Example 1**\n\nand then do some subsetting in R. In the second case,\n\n**15. Example 1**\n\nyou're sending a SQL query to the database,\n\n**16. Example 1**\n\nthis query is run on the database side, and\n\n**17. Example 1**\n\nonly the results are imported into R. If you're dealing with huge tables, the second approach is way more efficient.Let's try another example.\n\n**18. company**\n\nSuppose you want to select the products that imply a contract,\n\n**19. company**\n\nso where contract is one. For these products, we're interested in all variables. The old approach of reading the entire table and then subsetting\n\n**20. Example 2**\n\nwould look like this.The new approach of sending an SQL query to the database and fetching the result, looks like this.The results are again exactly the same. Notice how the star after the SELECT keyword specifies to keep all columns from the products table. Also notice that in the SQL query, you have to use a single equals sign to specify a condition for the WHERE keyword, instead of a double equals sign, like you're used to in R.\n\n**21. Let's practice!**\n\nAfter this crash course on SQL syntax, let's see how you perform in some exercises. Good luck!\n\n## Query tweater (1)\n\nIn your life as a data scientist, you'll often be working with huge databases that contain tables with millions of rows. If you want to do some analyses on this data, it's possible that you only need a fraction of this data. In this case, it's a good idea to send SQL queries to your database, and only import the data you actually need into R.\n\n<a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbGetQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbGetQuery()`</a> is what you need. As usual, you first pass the connection object to it. The second argument is an SQL query in the form of a character string. This example selects the `age` variable from the `people` dataset where `gender` equals `\"male\"`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndbGetQuery(con, \"SELECT age FROM people WHERE gender = 'male'\")\n```\n:::\n\n\n**Steps**\n\n1. Use <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbGetQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbGetQuery()`</a> to create a data frame, `elisabeth`, that **selects** the `tweat_id` column **from** the `comments` table **where** elisabeth is the commenter, her `user_id` is 1\n2. Print out `elisabeth` so you can see if you queried the database correctly.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Connect to the database\nlibrary(DBI)\ncon <- dbConnect(RMySQL::MySQL(),\n                 dbname = \"tweater\",\n                 host = \"courses.csrrinzqubik.us-east-1.rds.amazonaws.com\",\n                 port = 3306,\n                 user = \"student\",\n                 password = \"datacamp\")\n\n# Import tweat_id column of comments where user_id is 1: elisabeth\nelisabeth <- dbGetQuery(con, \"SELECT tweat_id FROM comments WHERE user_id = 1\")\n\n# Print elisabeth\nelisabeth\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"tweat_id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"87\"},{\"1\":\"49\"},{\"1\":\"77\"},{\"1\":\"77\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNice! To make sure you understood SQL's `SELECT` - `FROM` - `WHERE` syntax, let's practice some more.\n\n## Query tweater (2)\n\nApart from checking equality, you can also check for *less than* and *greater than* relationships, with `<` and `>`, just like in R.\n\n**Steps**\n\n1. Create a data frame, `latest`, that **selects** the `post` column **from** the `tweats` table observations **where** the `date` is higher than `'2015-09-21'`.\n2. Print out `latest`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import post column of tweats where date is higher than '2015-09-21': latest\n# Import post column of tweats where date is higher than '2015-09-21': latest\nlatest <- dbGetQuery(con, \"SELECT post \n                           FROM tweats \n                           WHERE date > '2015-09-21'\")\n\n# Print latest\nlatest\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"post\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"open and crush avocado. add shrimps. perfect starter.\"},{\"1\":\"nachos. add tomato sauce, minced meat and cheese. oven for 10 mins.\"},{\"1\":\"just eat an apple. simply and healthy.\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNice! To make sure you understood SQL's `SELECT` - `FROM` - `WHERE` syntax, let's practice some more.\n\n## Query tweater (3)\n\nSuppose that you have a `people` table, with a bunch of information. This time, you want to find out the `age` and `country` of married males. Provided that there is a `married` column that's 1 when the person in question is married, the following query would work.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.sql .cell-code}\nSELECT age, country\n  FROM people\n    WHERE gender = \"male\" AND married = 1\n```\n:::\n\n\nCan you use a similar approach for a more specialized query on the `tweater` database?\n\n**Steps**\n\n1. Create an R data frame, `specific`, that **selects** the `message` column **from** the `comments` table **where** the `tweat_id` is 77 **and** the `user_id` is greater than 4.\n2. Print `specific`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create data frame specific\nspecific <- dbGetQuery(con, \"SELECT message\n                             FROM comments\n                             WHERE tweat_id = 77 AND user_id > 4\")\n\n# Print specific\nspecific\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"message\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"great!\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Query tweater (4)\n\nThere are also dedicated SQL functions that you can use in the `WHERE` clause of an SQL query. For example, `CHAR_LENGTH()` returns the number of characters in a string.\n\n**Steps**\n\n1. Create a data frame, `short`, that **selects** the `id` and `name` columns **from** the `users` table **where** the number of characters in the `name` is strictly less than 5.\n2. Print `short`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create data frame short\nshort <- dbGetQuery(con, \"SELECT id, name\n                          FROM users\n                          WHERE CHAR_LENGTH(name) < 5\")\n\n# Print short\nshort\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"name\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"2\",\"2\":\"mike\"},{\"1\":\"3\",\"2\":\"thea\"},{\"1\":\"6\",\"2\":\"kate\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Join the query madness!\n\nOf course, SQL does not stop with the the three keywords `SELECT`, `FROM` and `WHERE`. Another very often used keyword is `JOIN`, and more specifically `INNER JOIN`. Take this call for example:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.sql .cell-code}\nSELECT name, post\n  FROM users INNER JOIN tweats on users.id = user_id\n    WHERE date > \"2015-09-19\"\n```\n:::\n\n\nHere, the `users` table is joined with the `tweats` table. This is possible because the `id` column in the `users` table corresponds to the `user_id` column in the `tweats` table. Also notice how `name`, from the `users` table, and `post` and `date`, from the `tweats` table, can be referenced to without problems.\n\n> *Question*\n> ---\n> Can you predict the outcome of the following query?<br>\n> <br>\n> ⬜ Trying to get the results of this SQL query throws an error.<br>\n> ✅ A table with four observations, containing two columns: `post` and `message`.<br>\n> ⬜ A table with six observations, containing all columns in the `tweats` table.<br>\n> ⬜ A table with six observations, containing the columns `post` and `message`.<br>\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.sql .cell-code}\nSELECT post, message\n  FROM tweats INNER JOIN comments on tweats.id = tweat_id\n    WHERE tweat_id = 77\n```\n:::\n\n\n## DBI internals\n\nTheory. Coming soon ...\n\n**1. DBI internals**\n\nLet's turn back to a dbGetQuery function call from before.\n\n**2. dbGetQuery()**\n\nIt was incredibly easy to use. Simply pass the connection object and an SQL query, and you get a result.What it actually does behind the scenes is sending a query, with dbSendQuery, like this. This function returns a result, but this does not actually contain any records you wanted to import. For that, you need to use the function dbFetch. Finally, you have to manually clear the result.The combination of dbSendQuery, dbFetch and, dbClearResult gives the exact same result as dbGetQuery did before, so why do this? Well, the dbFetch query calls allow you to specify a maximum number of records to retrieve per fetch. This can be useful when you need to load in tons of records, but want to do this chunk by chunk.Suppose, for example,\n\n**3. dbFetch() one by one**\n\nyou want to get the result of the previous query, record by record. You can use this construction for that, with the same SQL query as before.This code first sends a query to the database, and then goes into a while loop that checks whether the query result still has data that has not yet been fetched. If there is still data available, the chunks are fetched record by record, and this chunk is printed at each iteration. The output indeed shows the two records, printed separately, one after the other.In this toy example, this approach is not really useful, but if you're working on a super complicated algorithm that involves millions of database records, you might want to consider a treatment of data in chunks, right?After all your hard work on the database,\n\n**4. Disconnect**\n\ndon't forget to disconnect from it.Give these more low-level DBI functions a try in the exercises.\n\n**5. Let's practice!**\n\nIn the next chapter, I'll be back to tell you more about importing data from the web. See you there!\n\n## Send - Fetch - Clear\n\nYou've used <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbGetQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbGetQuery()`</a> multiple times now. This is a virtual function from the `DBI` package, but is actually implemented by the `RMySQL` package. Behind the scenes, the following steps are performed:\n\n\n* Sending the specified query with <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbSendQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbSendQuery()`</a>;\n* Fetching the result of executing the query on the database with <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbFetch\" target=\"_blank\" rel=\"noopener noreferrer\">`dbFetch()`</a>;\n* Clearing the result with <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbClearResult\" target=\"_blank\" rel=\"noopener noreferrer\">`dbClearResult()`</a>.\n\nLet's not use <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbGetQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbGetQuery()`</a> this time and implement the steps above. This is tedious to write, but it gives you the ability to fetch the query's result in chunks rather than all at once. You can do this by specifying the `n` argument inside <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbFetch\" target=\"_blank\" rel=\"noopener noreferrer\">`dbFetch()`</a>.\n\n\n**Steps**\n\n1. Inspect the <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbSendQuery\" target=\"_blank\" rel=\"noopener noreferrer\">`dbSendQuery()`</a> call that has already been coded for you. It selects the comments for the users with an id above 4.\n2. Use <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbFetch\" target=\"_blank\" rel=\"noopener noreferrer\">`dbFetch()`</a> twice. In the first call, import only two records of the query result by setting the `n` argument to `2`. In the second call, import all remaining queries (don't specify `n`). In both calls, simply print the resulting data frames.\n3. Clear `res` with <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbClearResult\" target=\"_blank\" rel=\"noopener noreferrer\">`dbClearResult()`</a>.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Send query to the database\nres <- dbSendQuery(con, \"SELECT * FROM comments WHERE user_id > 4\")\n\n# Use dbFetch() twice\ndbFetch(res, n = 2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tweat_id\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"user_id\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"message\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1022\",\"2\":\"87\",\"3\":\"7\",\"4\":\"nice!\"},{\"1\":\"1000\",\"2\":\"77\",\"3\":\"7\",\"4\":\"great!\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ndbFetch(res)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tweat_id\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"user_id\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"message\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1011\",\"2\":\"49\",\"3\":\"5\",\"4\":\"love it\"},{\"1\":\"1010\",\"2\":\"88\",\"3\":\"6\",\"4\":\"yuck!\"},{\"1\":\"1030\",\"2\":\"75\",\"3\":\"6\",\"4\":\"so easy!\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Clear res\ndbClearResult(res)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] TRUE\n```\n:::\n:::\n\n\nPerfect! In our toy example, chopping up the fetches doesn't make a lot of sense, but make sure to remember this technique when you're struggling with huge databases!\n\n## Be polite and ...\n\nEvery time you connect to a database using <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbConnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbConnect()`</a>, you're creating a new connection to the database you're referencing. `RMySQL` automatically specifies a maximum of open connections and closes some of the connections for you, but still: it's always polite to manually disconnect from the database afterwards. You do this with the <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbDisconnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbDisconnect()`</a> function.\n\nThe code that connects you to the database is already available, can you finish the script?\n\n\n**Steps**\n\n1. Using the technique you prefer, build a data frame `long_tweats`. It **selects** the `post` and `date` columns **from** the observations in `tweats` **where** the character length of the `post` variable exceeds `40`.\n2. Print `long_tweats`.\n3. Disconnect from the database by using <a href=\"http://www.rdocumentation.org/packages/DBI/functions/dbDisconnect\" target=\"_blank\" rel=\"noopener noreferrer\">`dbDisconnect()`</a>.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Create the data frame  long_tweats\nlong_tweats <- dbGetQuery(con, \"SELECT post, date\n                                FROM tweats\n                                WHERE CHAR_LENGTH(post) > 40\")\n\n# Print long_tweats\nprint(long_tweats)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>                                                                  post\n#> 1                           wash strawberries. add ice. blend. enjoy.\n#> 2                       2 slices of bread. add cheese. grill. heaven.\n#> 3               open and crush avocado. add shrimps. perfect starter.\n#> 4 nachos. add tomato sauce, minced meat and cheese. oven for 10 mins.\n#>         date\n#> 1 2015-09-14\n#> 2 2015-09-21\n#> 3 2015-09-22\n#> 4 2015-09-22\n```\n:::\n\n```{.r .cell-code}\n# Disconnect from the database\ndbDisconnect(con)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] TRUE\n```\n:::\n:::\n\n\nWonderful! This concludes the chapter on databases. Of course, there is tons more to learn about interfacing to databases and working with them as efficiently as possible, but that's something for more advanced courses.\n\n# 3. Importing data from the web (Part 1)\n\nMore and more of the information that data scientists are using resides on the web. Importing this data into R requires an understanding of the protocols used on the web. In this chapter, you'll get a crash course in HTTP and learn to perform your own HTTP requests from inside R.\n\n## HTTP\n\nTheory. Coming soon ...\n\n**1. HTTP**\n\nMore and more of the information you'll be working with as a data scientist resides on the web.\n\n**2. Data on the web**\n\nIn fact, you've already worked with such data. Remember how you connected to a remote relational database to get the exact information you needed? The DBI package abstracted the fact that the data was in some remote location and fixed everything for you. In this chapter, you'll look at file formats that are specifically useful when used for web technology, like the JSON file. I'm first going to discuss what actually happens behind the scenes when you're importing data that's on the web.To understand what happens in the examples that follow, I'm going to give you a crash course on the basics of HTTP,\n\n**3. HTTP**\n\nshort for HyperText Transfer Protocol. It's basically a system of rules for how data should be exchanged between computers. In short, HTTP is the language of the web. If you browse to a webpage for example, your computer, the client, is actually sending an\n\n**4. HTTP**\n\nHTTP request to the\n\n**5. HTTP**\n\nserver. The server then sends back\n\n**6. HTTP**\n\ndata representing the webpage, so it sends a response, and the webpage pops up on your screen. There are several HTTP Methods, as they are called. To simply get a webpage from a server,\n\n**7. HTTP**\n\nyou use the GET Method, for example. Apart from GET, there are also other HTTP methods, but let's not dive into those here.Instead, let's have a look at some examples you might remember from the previous chapters, but this time all of the data will be residing on the web.\n\n**8. Example: CSV**\n\nLet's start with the states-dot-csv file for example, that's located at this link. The typical workflow would be to manually download the file through your favorite web browser, and then point to the path inside read dot csv.However,\n\n**9. Example: CSV**\n\nit can be done much easier! Have a look at this line, where we simply pass the URL as a character string.The result is exactly the same: a data frame with 5 observations and 4 variables. How could this be so easy? Well, behind the scenes, R figures out that you referred to a URL, and requests it using an HTTP GET request. The server responds with the csv file, that R can then read in just like it did before. Pretty nice, huh?Nowadays, there are many websites that only accept secure connections. You can only visit these websites, or download their files with the http_S_ prefix. Does R also know how to handle that? Well, let's find out with the same CSV file, but this time\n\n**10. Example: CSV**\n\nwith the HTTPS prefix.This works just the same, awesome. HTTPS support is baked in to R since R version 3 point 2 point 2.Experiment with importing data from the web\n\n## Import flat files from the web\n\nIn the video, you saw that the `utils` functions to import flat file data, such as <a href=\"http://www.rdocumentation.org/packages/utils/functions/read.table\" target=\"_blank\" rel=\"noopener noreferrer\">`read.csv()`</a> and <a href=\"http://www.rdocumentation.org/packages/utils/functions/read.table\" target=\"_blank\" rel=\"noopener noreferrer\">`read.delim()`</a>, are capable of automatically importing from URLs that point to flat files on the web.\n\nYou must be wondering whether Hadley Wickham's alternative package, `readr`, is equally potent. Well, figure it out in this exercise! The URLs for both a `.csv` file as well as a `.delim` file are already coded for you. It's up to you to actually import the data. If it works, that is…\n\n**Steps**\n\n1. Load the `readr` package. It's already installed on DataCamp's servers.\n2. Use `url_csv` to read in the `.csv` file it is pointing to. Use the <a href=\"https://cran.r-project.org/web/packages/readr/readr.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_csv()`</a> function. The `.csv` contains column names in the first row. Save the resulting data frame as `pools`.\n3. Similarly, use `url_delim` to read in the online `.txt` file. Use the <a href=\"https://cran.r-project.org/web/packages/readr/readr.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_tsv()`</a> function and store the result as `potatoes`.\n4. Print `pools` and `potatoes`. Looks correct?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the readr package\nlibrary(readr)\n\n# Import the csv file: pools\nurl_csv <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv\"\n\npools <- read_csv(url_csv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 20 Columns: 4\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (2): Name, Address\n#> dbl (2): Latitude, Longitude\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# Import the txt file: potatoes\nurl_delim <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/potatoes.txt\"\n\npotatoes <- read_tsv(url_delim)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 160 Columns: 8\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \"\\t\"\n#> dbl (8): area, temp, size, storage, method, texture, flavor, moistness\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# Print pools and potatoes\nprint(pools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 20 × 4\n#>    Name                                      Address             Latit…¹ Longi…²\n#>    <chr>                                     <chr>                 <dbl>   <dbl>\n#>  1 Acacia Ridge Leisure Centre               1391 Beaudesert Ro…   -27.6    153.\n#>  2 Bellbowrie Pool                           Sugarwood Street, …   -27.6    153.\n#>  3 Carole Park                               Cnr Boundary Road …   -27.6    153.\n#>  4 Centenary Pool (inner City)               400 Gregory Terrac…   -27.5    153.\n#>  5 Chermside Pool                            375 Hamilton Road,…   -27.4    153.\n#>  6 Colmslie Pool (Morningside)               400 Lytton Road, M…   -27.5    153.\n#>  7 Spring Hill Baths (inner City)            14 Torrington Stre…   -27.5    153.\n#>  8 Dunlop Park Pool (Corinda)                794 Oxley Road, Co…   -27.5    153.\n#>  9 Fortitude Valley Pool                     432 Wickham Street…   -27.5    153.\n#> 10 Hibiscus Sports Complex (upper MtGravatt) 90 Klumpp Road, Up…   -27.6    153.\n#> 11 Ithaca Pool ( Paddington)                 131 Caxton Street,…   -27.5    153.\n#> 12 Jindalee Pool                             11 Yallambee Road,…   -27.5    153.\n#> 13 Manly Pool                                1 Fairlead Crescen…   -27.5    153.\n#> 14 Mt Gravatt East Aquatic Centre            Cnr wecker Road an…   -27.5    153.\n#> 15 Musgrave Park Pool (South Brisbane)       100 Edmonstone Str…   -27.5    153.\n#> 16 Newmarket Pool                            71 Alderson Stret,…   -27.4    153.\n#> 17 Runcorn Pool                              37 Bonemill Road, …   -27.6    153.\n#> 18 Sandgate Pool                             231 Flinders Parad…   -27.3    153.\n#> 19 Langlands Parks Pool (Stones Corner)      5 Panitya Street, …   -27.5    153.\n#> 20 Yeronga Park Pool                         81 School Road, Ye…   -27.5    153.\n#> # … with abbreviated variable names ¹​Latitude, ²​Longitude\n```\n:::\n\n```{.r .cell-code}\nprint(potatoes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> # A tibble: 160 × 8\n#>     area  temp  size storage method texture flavor moistness\n#>    <dbl> <dbl> <dbl>   <dbl>  <dbl>   <dbl>  <dbl>     <dbl>\n#>  1     1     1     1       1      1     2.9    3.2       3  \n#>  2     1     1     1       1      2     2.3    2.5       2.6\n#>  3     1     1     1       1      3     2.5    2.8       2.8\n#>  4     1     1     1       1      4     2.1    2.9       2.4\n#>  5     1     1     1       1      5     1.9    2.8       2.2\n#>  6     1     1     1       2      1     1.8    3         1.7\n#>  7     1     1     1       2      2     2.6    3.1       2.4\n#>  8     1     1     1       2      3     3      3         2.9\n#>  9     1     1     1       2      4     2.2    3.2       2.5\n#> 10     1     1     1       2      5     2      2.8       1.9\n#> # … with 150 more rows\n```\n:::\n:::\n\n\nGreat! It seems to work without any additional problems!\n\n## Secure importing\n\nIn the previous exercises, you have been working with URLs that all start with `http://`. There is, however, a safer alternative to HTTP, namely HTTPS, which stands for HypterText Transfer Protocol Secure. Just remember this: HTTPS is relatively safe, HTTP is not.\n\nLuckily for us, you can use the standard importing functions with `https://` connections since R version 3.2.2.\n\n**Steps**\n\n1. Take a look at the URL in `url_csv`. It uses a secure connection, `https://`.\n2. Use <a href=\"http://www.rdocumentation.org/packages/utils/functions/read.table\" target=\"_blank\" rel=\"noopener noreferrer\">`read.csv()`</a> to import the file at `url_csv`. The `.csv` file it is referring to contains column names in the first row. Call it `pools1`.\n3. Use <a href=\"https://cran.r-project.org/web/packages/readr/readr.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_csv()`</a> to read in the same `.csv` file in `url_csv`. Call it `pools2`.\n4. Print out the structure of `pools1` and `pools2`. Looks like the importing went equally well as with a normal `http` connection!\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# https URL to the swimming_pools csv file.\nurl_csv <- \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv\"\n\n# Import the file using read.csv(): pools1\npools1 <- read.csv(url_csv)\n\n# Import the file using read_csv(): pools2\npools2 <- read_csv(url_csv)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Rows: 20 Columns: 4\n#> ── Column specification ────────────────────────────────────────────────────────\n#> Delimiter: \",\"\n#> chr (2): Name, Address\n#> dbl (2): Latitude, Longitude\n#> \n#> ℹ Use `spec()` to retrieve the full column specification for this data.\n#> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# Print the structure of pools1 and pools2\nstr(pools1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t20 obs. of  4 variables:\n#>  $ Name     : chr  \"Acacia Ridge Leisure Centre\" \"Bellbowrie Pool\" \"Carole Park\" \"Centenary Pool (inner City)\" ...\n#>  $ Address  : chr  \"1391 Beaudesert Road, Acacia Ridge\" \"Sugarwood Street, Bellbowrie\" \"Cnr Boundary Road and Waterford Road Wacol\" \"400 Gregory Terrace, Spring Hill\" ...\n#>  $ Latitude : num  -27.6 -27.6 -27.6 -27.5 -27.4 ...\n#>  $ Longitude: num  153 153 153 153 153 ...\n```\n:::\n\n```{.r .cell-code}\nstr(pools2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> spc_tbl_ [20 × 4] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n#>  $ Name     : chr [1:20] \"Acacia Ridge Leisure Centre\" \"Bellbowrie Pool\" \"Carole Park\" \"Centenary Pool (inner City)\" ...\n#>  $ Address  : chr [1:20] \"1391 Beaudesert Road, Acacia Ridge\" \"Sugarwood Street, Bellbowrie\" \"Cnr Boundary Road and Waterford Road Wacol\" \"400 Gregory Terrace, Spring Hill\" ...\n#>  $ Latitude : num [1:20] -27.6 -27.6 -27.6 -27.5 -27.4 ...\n#>  $ Longitude: num [1:20] 153 153 153 153 153 ...\n#>  - attr(*, \"spec\")=\n#>   .. cols(\n#>   ..   Name = col_character(),\n#>   ..   Address = col_character(),\n#>   ..   Latitude = col_double(),\n#>   ..   Longitude = col_double()\n#>   .. )\n#>  - attr(*, \"problems\")=<externalptr>\n```\n:::\n:::\n\n\nGreat! It seems to work without any additional problems!\n\n## Downloading files\n\nTheory. Coming soon ...\n\n**1. Downloading files**\n\nSimilar to what we did in the previous video,\n\n**2. Example: Excel**\n\nlet's now use the readxl package to import Excel data stored at this URL. Will the read_excel work out of the box here?Apparently, readxl does not know how to handle Excel files that are stored on the web, although I expect that Hadley Wickham will add this functionality in future releases. Does this mean we'll have to manually download the file, and then point to the local file like you would do before? Not at all!\n\n**3. download.file()**\n\nYou can use download dot file here, a function from the utils package. Let's first define the URL and the destination path, so where we want to place the downloaded file on our system. I'm going to call the file local_cities dot xlsx and place it my home directory.If you now use download dot file with the url as the first argument and the destination path as the second argument you're good to go.Perfect. What download dot file did is simple. It performed a GET request to the URL you specified and stored the contents of the response to the location you specified. The last step is to use the read_excel function from before to import the Excel data from the local file this time. We can again use the dest_path variable here.\n\n**4. Why download.file()?**\n\nYou might wonder why using download dot file is useful. The answer is again: reproducibility. You can specify URLs in your R scripts and download them through R functions instead of manually browsing the web which requires several mouseclicks.There's much more to learn about performing GET requests and other HTTP requests from inside R. In some cases, you'll have to authenticate yourself before you can download files, and pass additional parameters to your GET request. If you want to learn more about this, I suggest you check out the httr package by Hadley Wickham.\n\n## Import Excel files from the web\n\nWhen you learned about `gdata`, it was already mentioned that `gdata` can handle `.xls` files that are on the internet. `readxl` can't, at least not yet. The URL with which you'll be working is already available in the sample code. You will import it once using `gdata` and once with the `readxl` package via a workaround.\n\n\n**Steps**\n\n1. Load the `readxl` and `gdata` packages. They are already installed on DataCamp's servers.\n2. Import the `.xls` file located at the URL `url_xls` using <a href=\"http://www.rdocumentation.org/packages/gdata/functions/read.xls\" target=\"_blank\" rel=\"noopener noreferrer\">`read.xls()`</a> from `gdata`. Store the resulting data frame as `excel_gdata`.\n3. You can not use <a href=\"https://cran.r-project.org/web/packages/readxl/readxl.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_excel()`</a> directly with a URL. Complete the following instructions to work around this problem:\n4. Use <a href=\"http://www.rdocumentation.org/packages/utils/functions/download.file\" target=\"_blank\" rel=\"noopener noreferrer\">`download.file()`</a> to download the `.xls` file behind the URL and store it locally as `\"local_latitude.xls\"`.\n5. Call <a href=\"https://cran.r-project.org/web/packages/readxl/readxl.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_excel()`</a> to import the local file, `\"local_latitude.xls\"`. Name the resulting data frame `excel_readxl`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the readxl and gdata package\nlibrary(readxl)\nlibrary(gdata)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> gdata: read.xls support for 'XLS' (Excel 97-2004) files ENABLED.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> gdata: read.xls support for 'XLSX' (Excel 2007+) files ENABLED.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attache Paket: 'gdata'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Das folgende Objekt ist maskiert 'package:stats':\n#> \n#>     nobs\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Das folgende Objekt ist maskiert 'package:utils':\n#> \n#>     object.size\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Das folgende Objekt ist maskiert 'package:base':\n#> \n#>     startsWith\n```\n:::\n\n```{.r .cell-code}\n# Specification of url: url_xls\nurl_xls <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/latitude.xls\"\n\n# Import the .xls file with gdata: excel_gdata\nexcel_gdata <- read.xls(url_xls)\n\n# Download file behind URL, name it local_latitude.xls\ndownload.file(url_xls, \"data//local_latitude.xls\")\n\n# Import the local .xls file with readxl: excel_readxl\nexcel_readxl <- read_excel(\"data//local_latitude.xls\")\n```\n:::\n\n\nNice! It appears that `readxl` is not (yet?) able to deal with Excel files that are on the web. However, a simply workaround with [`download.file()`](http://www.rdocumentation.org/packages/utils/functions/download.file) fixes this.\n\n## Downloading any file, secure or not\n\nIn the previous exercise you've seen how you can read excel files on the web using the `read_excel` package by first downloading the file with the <a href=\"http://www.rdocumentation.org/packages/utils/functions/download.file\" target=\"_blank\" rel=\"noopener noreferrer\">`download.file()`</a> function.\n\nThere's more: with <a href=\"http://www.rdocumentation.org/packages/utils/functions/download.file\" target=\"_blank\" rel=\"noopener noreferrer\">`download.file()`</a> you can download any kind of file from the web, using HTTP and HTTPS: images, executable files, but also `.RData` files. An `RData` file is very efficient format to store R data.\n\nYou can load data from an `RData` file using the <a href=\"http://www.rdocumentation.org/packages/base/functions/load\" target=\"_blank\" rel=\"noopener noreferrer\">`load()`</a> function, but this function does not accept a URL string as an argument. In this exercise, you'll first download the `RData` file securely, and then import the local data file.\n\n\n**Steps**\n\n1. Take a look at the URL in `url_rdata`. It uses a secure connection, `https://`. This URL points to an `RData` file containing a data frame with some metrics on different kinds of wine.\n2. Download the file at `url_rdata` using <a href=\"http://www.rdocumentation.org/packages/utils/functions/download.file\" target=\"_blank\" rel=\"noopener noreferrer\">`download.file()`</a>. Call the file `\"wine_local.RData\"` in your working directory.\n3. Load the file you created, `wine_local.RData`, using the <a href=\"http://www.rdocumentation.org/packages/base/functions/load\" target=\"_blank\" rel=\"noopener noreferrer\">`load()`</a> function. It takes one argument, the path to the file, which is just the filename in our case. After running this command, the variable `wine` will automatically be available in your workspace.\n4. Print out the <a href=\"http://www.rdocumentation.org/packages/base/functions/summary\" target=\"_blank\" rel=\"noopener noreferrer\">`summary()`</a> of the `wine` dataset.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# https URL to the wine RData file.\nurl_rdata <- \"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/wine.RData\"\n\n# Download the wine file to your working directory\ndownload.file(url_rdata, \"data/wine_local.RData\")\n\n# Load the wine data into your workspace using load()\nload(\"data/wine_local.RData\")\n\n# Print out the summary of the wine data\nsummary(wine)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     Alcohol        Malic acid        Ash        Alcalinity of ash\n#>  Min.   :11.03   Min.   :0.74   Min.   :1.360   Min.   :10.60    \n#>  1st Qu.:12.36   1st Qu.:1.60   1st Qu.:2.210   1st Qu.:17.20    \n#>  Median :13.05   Median :1.87   Median :2.360   Median :19.50    \n#>  Mean   :12.99   Mean   :2.34   Mean   :2.366   Mean   :19.52    \n#>  3rd Qu.:13.67   3rd Qu.:3.10   3rd Qu.:2.560   3rd Qu.:21.50    \n#>  Max.   :14.83   Max.   :5.80   Max.   :3.230   Max.   :30.00    \n#>    Magnesium      Total phenols     Flavanoids    Nonflavanoid phenols\n#>  Min.   : 70.00   Min.   :0.980   Min.   :0.340   Min.   :0.1300      \n#>  1st Qu.: 88.00   1st Qu.:1.740   1st Qu.:1.200   1st Qu.:0.2700      \n#>  Median : 98.00   Median :2.350   Median :2.130   Median :0.3400      \n#>  Mean   : 99.59   Mean   :2.292   Mean   :2.023   Mean   :0.3623      \n#>  3rd Qu.:107.00   3rd Qu.:2.800   3rd Qu.:2.860   3rd Qu.:0.4400      \n#>  Max.   :162.00   Max.   :3.880   Max.   :5.080   Max.   :0.6600      \n#>  Proanthocyanins Color intensity       Hue           Proline      \n#>  Min.   :0.410   Min.   : 1.280   Min.   :1.270   Min.   : 278.0  \n#>  1st Qu.:1.250   1st Qu.: 3.210   1st Qu.:1.930   1st Qu.: 500.0  \n#>  Median :1.550   Median : 4.680   Median :2.780   Median : 672.0  \n#>  Mean   :1.587   Mean   : 5.055   Mean   :2.604   Mean   : 745.1  \n#>  3rd Qu.:1.950   3rd Qu.: 6.200   3rd Qu.:3.170   3rd Qu.: 985.0  \n#>  Max.   :3.580   Max.   :13.000   Max.   :4.000   Max.   :1680.0\n```\n:::\n:::\n\n\nGreat! Another way to load remote `RData` files is to use the [`url()`](http://www.rdocumentation.org/packages/base/functions/connections) function inside [`load()`](http://www.rdocumentation.org/packages/base/functions/load). However, this will not save the `RData` file to a local file.\n\n## Reading a text file from the web\n\nWow, you've learned a lot of ways to import a data file from the web in the previous exercises. Let's see if you can remember what's possible and what's not.\n\n> *Question*\n> ---\n> Which way of importing  data is *NOT* possible?<br>\n> <br>\n> ⬜ Importing a `.csv` file residing on the web using the URL with <a href=\"http://www.rdocumentation.org/packages/utils/functions/read.table\">`read.csv()`</a>: `read.csv(\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv\")`<br>\n> ⬜ Downloading a remote excel and saving it to your working directory using <a href=\"http://www.rdocumentation.org/packages/utils/functions/download.file\">`download.file()`</a>: `download.file(\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/latitude.xlsx\", \"lat.xlsx\")`<br>\n> ⬜ Importing a `.txt` file residing on the web using the URL with <a href=\"https://cran.r-project.org/web/packages/readr/readr.pdf\">`read_tsv()`</a>: `read_tsv(\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/potatoes.txt\")`<br>\n> ✅ Using the <a href=\"http://www.rdocumentation.org/packages/base/functions/load\">`load()`</a> function to load a remote `RData` file into the workspace with only the URL string: `load(\"https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/wine.RData\")`<br>\n\n## HTTP? httr! (1)\n\nDownloading a file from the Internet means sending a GET request and receiving the file you asked for. Internally, all the previously discussed functions use a GET request to download files.\n\n`httr` provides a convenient function, <a href=\"http://www.rdocumentation.org/packages/httr/functions/GET\" target=\"_blank\" rel=\"noopener noreferrer\">`GET()`</a> to execute this GET request. The result is a `response` object, that provides easy access to the status code, content-type and, of course, the actual content.\n\nYou can extract the content from the request using the <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> function. At the time of writing, there are three ways to retrieve this content: as a raw object, as a character vector, or an R object, such as a list. If you don't tell <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> how to retrieve the content through the `as` argument, it'll try its best to figure out which type is most appropriate based on the content-type.\n\n\n**Steps**\n\n1. Load the `httr` package. It's already installed on DataCamp's servers.\n2. Use <a href=\"http://www.rdocumentation.org/packages/httr/functions/GET\" target=\"_blank\" rel=\"noopener noreferrer\">`GET()`</a> to get the URL stored in `url`. Store the result of this `GET()` call as `resp`.\n3. Print the `resp` object. What information does it contain?\n4. Get the content of `resp` using <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> and set the `as` argument to `\"raw\"`. Assign the resulting vector to `raw_content`.\n5. Print the first values in `raw_content` with <a href=\"http://www.rdocumentation.org/packages/utils/functions/head\" target=\"_blank\" rel=\"noopener noreferrer\">`head()`</a>.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the httr package\nlibrary(httr)\n\n# Get the url, save response to resp\nurl  <- \"http://www.example.com/\"\nresp <- GET(url) \n\n# Print resp\nresp\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Response [http://www.example.com/]\n#>   Date: 2022-12-09 09:59\n#>   Status: 200\n#>   Content-Type: text/html; charset=UTF-8\n#>   Size: 1.26 kB\n#> <!doctype html>\n#> <html>\n#> <head>\n#>     <title>Example Domain</title>\n#> \n#>     <meta charset=\"utf-8\" />\n#>     <meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" />\n#>     <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n#>     <style type=\"text/css\">\n#>     body {\n#> ...\n```\n:::\n\n```{.r .cell-code}\n# Get the raw content of resp: raw_content\nraw_content <- content(resp, as = \"raw\")\n\n# Print the head of raw_content\nhead(raw_content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 3c 21 64 6f 63 74\n```\n:::\n:::\n\n\nGreat! The raw content of the response doesn't make a lot of sense, does it? Luckily, the [`content()`](http://www.rdocumentation.org/packages/httr/functions/content) function by default, if you don't specify the `as` argument, figures out what type of data you're dealing with and parses it for you.\n\n## HTTP? httr! (2)\n\nWeb content does not limit itself to HTML pages and files stored on remote servers such as DataCamp's Amazon S3 instances. There are many other data formats out there. A very common one is JSON. This format  is very often used by so-called Web APIs, interfaces to web servers with which you as a client can communicate to get or store information in more complicated ways.\n\nYou'll learn about Web APIs and JSON in the video and exercises that follow, but some experimentation never hurts, does it?\n\n**Steps**\n\n1. Use <a href=\"http://www.rdocumentation.org/packages/httr/functions/GET\" target=\"_blank\" rel=\"noopener noreferrer\">`GET()`</a> to get the `url` that has already been specified in the sample code. Store the response as `resp`.\n2. Print `resp`. What is the content-type?\n3. Use <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> to get the content of `resp`. Set the `as` argument to `\"text\"`. Simply print out the result. What do you see?\n4. Use <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> to get the content of `resp`, but this time do not specify a second argument. R figures out automatically that you're dealing with a JSON, and converts the JSON to a named R list.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Get the url\nurl <- \"http://www.omdbapi.com/?apikey=72bc447a&t=Annie+Hall&y=&plot=short&r=json\"\n\n# Print resp\nresp <- GET(url)\nprint(resp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Response [http://www.omdbapi.com/?apikey=72bc447a&t=Annie+Hall&y=&plot=short&r=json]\n#>   Date: 2022-12-09 09:59\n#>   Status: 200\n#>   Content-Type: application/json; charset=utf-8\n#>   Size: 1.02 kB\n```\n:::\n\n```{.r .cell-code}\n# Print content of resp as text\nprint(content(resp, as = \"text\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"{\\\"Title\\\":\\\"Annie Hall\\\",\\\"Year\\\":\\\"1977\\\",\\\"Rated\\\":\\\"PG\\\",\\\"Released\\\":\\\"20 Apr 1977\\\",\\\"Runtime\\\":\\\"93 min\\\",\\\"Genre\\\":\\\"Comedy, Romance\\\",\\\"Director\\\":\\\"Woody Allen\\\",\\\"Writer\\\":\\\"Woody Allen, Marshall Brickman\\\",\\\"Actors\\\":\\\"Woody Allen, Diane Keaton, Tony Roberts\\\",\\\"Plot\\\":\\\"Alvy Singer, a divorced Jewish comedian, reflects on his relationship with ex-lover Annie Hall, an aspiring nightclub singer, which ended abruptly just like his previous marriages.\\\",\\\"Language\\\":\\\"English, German\\\",\\\"Country\\\":\\\"United States\\\",\\\"Awards\\\":\\\"Won 4 Oscars. 31 wins & 8 nominations total\\\",\\\"Poster\\\":\\\"https://m.media-amazon.com/images/M/MV5BZDg1OGQ4YzgtM2Y2NS00NjA3LWFjYTctMDRlMDI3NWE1OTUyXkEyXkFqcGdeQXVyMjUzOTY1NTc@._V1_SX300.jpg\\\",\\\"Ratings\\\":[{\\\"Source\\\":\\\"Internet Movie Database\\\",\\\"Value\\\":\\\"8.0/10\\\"},{\\\"Source\\\":\\\"Rotten Tomatoes\\\",\\\"Value\\\":\\\"97%\\\"},{\\\"Source\\\":\\\"Metacritic\\\",\\\"Value\\\":\\\"92/100\\\"}],\\\"Metascore\\\":\\\"92\\\",\\\"imdbRating\\\":\\\"8.0\\\",\\\"imdbVotes\\\":\\\"266,470\\\",\\\"imdbID\\\":\\\"tt0075686\\\",\\\"Type\\\":\\\"movie\\\",\\\"DVD\\\":\\\"05 Jul 2000\\\",\\\"BoxOffice\\\":\\\"$38,251,425\\\",\\\"Production\\\":\\\"N/A\\\",\\\"Website\\\":\\\"N/A\\\",\\\"Response\\\":\\\"True\\\"}\"\n```\n:::\n\n```{.r .cell-code}\n# Print content of resp\nprint(content(resp))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> $Title\n#> [1] \"Annie Hall\"\n#> \n#> $Year\n#> [1] \"1977\"\n#> \n#> $Rated\n#> [1] \"PG\"\n#> \n#> $Released\n#> [1] \"20 Apr 1977\"\n#> \n#> $Runtime\n#> [1] \"93 min\"\n#> \n#> $Genre\n#> [1] \"Comedy, Romance\"\n#> \n#> $Director\n#> [1] \"Woody Allen\"\n#> \n#> $Writer\n#> [1] \"Woody Allen, Marshall Brickman\"\n#> \n#> $Actors\n#> [1] \"Woody Allen, Diane Keaton, Tony Roberts\"\n#> \n#> $Plot\n#> [1] \"Alvy Singer, a divorced Jewish comedian, reflects on his relationship with ex-lover Annie Hall, an aspiring nightclub singer, which ended abruptly just like his previous marriages.\"\n#> \n#> $Language\n#> [1] \"English, German\"\n#> \n#> $Country\n#> [1] \"United States\"\n#> \n#> $Awards\n#> [1] \"Won 4 Oscars. 31 wins & 8 nominations total\"\n#> \n#> $Poster\n#> [1] \"https://m.media-amazon.com/images/M/MV5BZDg1OGQ4YzgtM2Y2NS00NjA3LWFjYTctMDRlMDI3NWE1OTUyXkEyXkFqcGdeQXVyMjUzOTY1NTc@._V1_SX300.jpg\"\n#> \n#> $Ratings\n#> $Ratings[[1]]\n#> $Ratings[[1]]$Source\n#> [1] \"Internet Movie Database\"\n#> \n#> $Ratings[[1]]$Value\n#> [1] \"8.0/10\"\n#> \n#> \n#> $Ratings[[2]]\n#> $Ratings[[2]]$Source\n#> [1] \"Rotten Tomatoes\"\n#> \n#> $Ratings[[2]]$Value\n#> [1] \"97%\"\n#> \n#> \n#> $Ratings[[3]]\n#> $Ratings[[3]]$Source\n#> [1] \"Metacritic\"\n#> \n#> $Ratings[[3]]$Value\n#> [1] \"92/100\"\n#> \n#> \n#> \n#> $Metascore\n#> [1] \"92\"\n#> \n#> $imdbRating\n#> [1] \"8.0\"\n#> \n#> $imdbVotes\n#> [1] \"266,470\"\n#> \n#> $imdbID\n#> [1] \"tt0075686\"\n#> \n#> $Type\n#> [1] \"movie\"\n#> \n#> $DVD\n#> [1] \"05 Jul 2000\"\n#> \n#> $BoxOffice\n#> [1] \"$38,251,425\"\n#> \n#> $Production\n#> [1] \"N/A\"\n#> \n#> $Website\n#> [1] \"N/A\"\n#> \n#> $Response\n#> [1] \"True\"\n```\n:::\n:::\n\n\nGreat! The fact that `httr` converts the JSON response body automatically to an R list is very convenient.\n\n# 4. Importing data from the web (Part 2)\n\nImporting data from the web is one thing; actually being able to extract useful information is another. Learn more about the JSON format to get one step closer to web domination.\n\n## APIs & JSON\n\nTheory. Coming soon ...\n\n**1. APIs &amp; JSON**\n\nIn the previous video and exercises,\n\n**2. Other data formats**\n\nyou've seen how you can get files from the web. In the last exercise, you also saw that there is also another format to represent data, namely JSON. The JSON format is very simple, concise and well-structured. On top of that, it is human-readable, but also easy to interpret and generate for machines. This makes it perfect to communicate with Web APIs.\n\n**3. API**\n\nWhat is an API, I hear you asking? Well, it's short for Application Programming Interface. Very generally put, it is a set of routines and protocols for building software components. It is a way in which different software components interact. This can happen in thousands of ways, but we will only focus on the web API. Typically, this is an interface to get data and processed information from a server or to add data to a server, through the HTTP methods you learned about earlier.\n\n**4. Twitter**\n\nAs an example, take Twitter. They also have an API, which you can check out here. After authentication, you can simply request particular URLs from twitter with the GET request, allowing you to get the tweets for a particular person for example. Twitter does all the work for you on their servers, and spits out the information you need. You can also use the API to programatically place comments on somebody's tweets for example. The possible applications are endless. Say you're an avid tweeter and want to find out which tweets had the most impact. Maybe some of your more controversial tweets caused a lot of retweets and reactions? With the raw data from Twitter's API you can research this.But why are APIs and JSON useful in the first place? All the information is available on webpage already, right?\n\n**5. Info on Rain Man (1988)**\n\nWell, suppose you want to get some data on the movie Rain Man, from 1988. You could download the corresponding URL of IMDb, read it in, and then start programmatically searching your way through the HTML code, which is more than 4000 lines, to get the information you need. This is pretty error-prone and really slow.Luckily, there are alternatives. As it happens,\n\n**6. Rain Man JSON (OMDb API)**\n\nthere's an API called the OMDb API, able to give you information on pratically any movie you can think of. It simply takes a URL, with some additional parameters such as the id of the movie you want to get info about and what type the response should be, that the API understands.If you simply visit this web page, you will see something like this. This is a JSON, containing everything we need to know in a nicely structured format.To convert this JSON into an R data structure,\n\n**7. jsonlite**\n\nyou can use the jsonlite package by Jeroen Ooms. The package is an improvement of earlier R packages to handle JSONs, where converting from and to JSONs is more consistent and robust, such that it works nicely in all use cases.\n\n**8. Rain Man list in R**\n\nLet's install and load jsonlite, and then simply call fromJSON on the URL. This will download the JSON data for you and convert it to a named R list. We now have all the information in R, ready to do our analysis. This is way better than the messy HTML page where we would have to dig through to get the bits and pieces of interest, isn't it?\n\n## From JSON to R\n\nIn the simplest setting, <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> can convert character strings that represent JSON data into a nicely structured R list. Give it a try!\n\n**Steps**\n\n1. Load the `jsonlite` package. It's already installed on DataCamp's servers.\n2. `wine_json` represents a JSON. Use `fromJSON()` to convert it to a list, named `wine`.\n3. Display the structure of `wine`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the jsonlite package\nlibrary(jsonlite)\n\n# wine_json is a JSON\nwine_json <- '{\"name\":\"Chateau Migraine\", \"year\":1997, \"alcohol_pct\":12.4, \"color\":\"red\", \"awarded\":false}'\n\n# Convert wine_json into a list: wine\nwine <- fromJSON(wine_json)\n\n# Print structure of wine\nstr(wine)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> List of 5\n#>  $ name       : chr \"Chateau Migraine\"\n#>  $ year       : int 1997\n#>  $ alcohol_pct: num 12.4\n#>  $ color      : chr \"red\"\n#>  $ awarded    : logi FALSE\n```\n:::\n:::\n\n\n## Quandl API\n\nAs Filip showed in the video, <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> also works if you pass a URL as a character string or the path to a local file that contains JSON data. Let's try this out on the Quandl API, where you can fetch all sorts of financial and economical data.\n\n**Steps**\n\n1. `quandl_url` represents a URL. Use `fromJSON()` directly on this URL and store the result in `quandl_data`.\n2. Display the structure of `quandl_data`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definition of quandl_url\nquandl_url <- \"https://www.quandl.com/api/v3/datasets/WIKI/FB/data.json?auth_token=i83asDsiWUUyfoypkgMz\"\n\n# Import Quandl data: quandl_data\nquandl_data <- fromJSON(quandl_url)\n\n# Print structure of quandl_data\nstr(quandl_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> List of 1\n#>  $ dataset_data:List of 10\n#>   ..$ limit       : NULL\n#>   ..$ transform   : NULL\n#>   ..$ column_index: NULL\n#>   ..$ column_names: chr [1:13] \"Date\" \"Open\" \"High\" \"Low\" ...\n#>   ..$ start_date  : chr \"2012-05-18\"\n#>   ..$ end_date    : chr \"2018-03-27\"\n#>   ..$ frequency   : chr \"daily\"\n#>   ..$ data        : chr [1:1472, 1:13] \"2018-03-27\" \"2018-03-26\" \"2018-03-23\" \"2018-03-22\" ...\n#>   ..$ collapse    : NULL\n#>   ..$ order       : NULL\n```\n:::\n:::\n\n\nGreat! You successfully imported JSON data directly from the web. If you have a close look at the structure of `quandl_data`, you'll see that the `data` element is a matrix.\n\n## OMDb API\n\nIn the video, you saw how easy it is to interact with an API once you know how to formulate requests. You also saw how to fetch all information on Rain Man from OMDb. Simply perform a <a href=\"http://www.rdocumentation.org/packages/httr/functions/GET\" target=\"_blank\" rel=\"noopener noreferrer\">`GET()`</a> call, and next ask for the contents with the <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> function. This <a href=\"http://www.rdocumentation.org/packages/httr/functions/content\" target=\"_blank\" rel=\"noopener noreferrer\">`content()`</a> function, which is part of the `httr` package, uses `jsonlite` behind the scenes to import the JSON data into R.\n\nHowever, by now you also know that `jsonlite` can handle URLs itself. Simply passing the request URL to <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> will get your data into R. In this exercise, you will be using this technique to compare the release year of two movies in the Open Movie Database.\n\n**Steps**\n\n1. Two URLs are included in the sample code, as well as a `fromJSON()` call to build `sw4`. Add a similar call to build `sw3`.\n2. Print out the element named `Title` of both `sw4` and `sw3`. You can use the `$` operator. What movies are we dealing with here?\n3. Write an expression that evaluates to `TRUE` if `sw4` was released later than `sw3`. This information is stored in the `Year` element of the named lists.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Definition of the URLs\nurl_sw4 <- \"http://www.omdbapi.com/?apikey=72bc447a&i=tt0076759&r=json\"\nurl_sw3 <- \"http://www.omdbapi.com/?apikey=72bc447a&i=tt0121766&r=json\"\n\n# Import two URLs with fromJSON(): sw4 and sw3\nsw4 <- fromJSON(url_sw4)\nsw3 <- fromJSON(url_sw3)\n\n\n# Print out the Title element of both lists\nprint(sw4$Title)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"Star Wars: Episode IV - A New Hope\"\n```\n:::\n\n```{.r .cell-code}\nprint(sw3$Title)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] \"Star Wars: Episode III - Revenge of the Sith\"\n```\n:::\n\n```{.r .cell-code}\n# Is the release year of sw4 later than sw3?\nsw4$Year > sw3$Year\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] FALSE\n```\n:::\n:::\n\n\nWell done! The fourth episode of the Star Wars saga was released before the third one! Enough of the [`fromJSON()`](http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON) now. Let's try to convert some R data into JSON format now.\n\n## JSON & jsonlite\n\nTheory. Coming soon ...\n\n**1. JSON &amp; jsonlite**\n\nIn this video, let's dive into the JSON format and the jsonlite package some more.So, what does a typical JSON look like? I'll try to be short on this.You have JSON objects, and you have JSON arrays.\n\n**2. JSON object**\n\nA typical JSON object looks like this. It's unordered collection of name/value pairs. where the name is a string and the value can be a string, a number, boolean, null, another JSON object, or a JSON array.\n\n**3. JSON object**\n\nLet's convert this JSON to an R string by wrapping it in quotes. I use single quotes here so that I don't have to escape every double quote. Now let's pass this string to jsonlite's fromJSON function, that converts a JSON to R code, and ask for the structure of the result.The result is a named list in R, which contains the same information. You can also see that the elements have different classes: we have characters, integers and logicals.\n\n**4. JSON array**\n\nNext, there are also JSON arrays. This is an ordered sequence of zero or more values, like this one.Calling fromJSON on this JSON structure results in an integer vector.However, this actually is a simplification, because JSON arrays, just like JSON objects, are heterogeneous; they can contain elements of different types. This JSON array for example, is perfectly valid as well.Trying to convert this JSON into R, give the following result.The numbers were coerced to characters, as was the logical value. The null keyword was converted to an NA in R. This had to be done because R vectors can only contain a single basic type, remember?Both the JSON object as the JSON array can contain other JSON objects and arrays, how would that work?\n\n**5. JSON Nesting**\n\nSuppose we add some information to the JSON object from before. This time, I formatted the JSON such that it becomes more readable.We can extend it as follows.\n\n**6. JSON Nesting**\n\nLet's fromJSON this, and see what we get.We get a nested named list, makes perfect sense if you ask me.\n\n**7. JSON Array of JSON Objects**\n\nFinally, let's build an array of JSON objects, of three persons for example, like this.Wow, this was unexpected. We simply got a data frame. But if you think of it, this is a great mapping. We have three JSON objects, on Frank, Julie and Zach, and they all have the same fields, id and name. This perfectly fits the description of an R data frame. The wonderful thing is that jsonlite deals with all of this for us. There are many more use cases of JSON objects and arrays, but I won't go through each and every one of them.next to fromJSON,\n\n**8. Other jsonlite functions**\n\nthere are other useful functions in the jsonlite package, such as tojson, to convert r data structures back to json, and prettify and minify, to change how jsons are displayed. you'll learn all about these in the exercises that follow!If you use the jsonlite package you normally won't be dealing with JSONs directly, but it's good to have a basic level of understanding of them.\n\n## JSON practice (1)\n\nJSON is built on two structures: objects and arrays. To help you experiment with these, two JSON strings are included in the sample code. It's up to you to change them appropriately and then call `jsonlite`'s <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> function on them each time.\n\n\n**Steps**\n\n1. Change the assignment of `json1` such that the R vector after conversion contains the numbers 1 up to 6, in ascending order. Next, call <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> on `json1`.\n2. Adapt the code for `json2` such that it's converted to a named list with two elements: `a`, containing the numbers 1, 2 and 3 and `b`, containing the numbers 4, 5 and 6. Next, call <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> on `json2`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Challenge 1\njson1 <- '[1, 2, 3, 4, 5, 6]'\nfromJSON(json1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 1 2 3 4 5 6\n```\n:::\n\n```{.r .cell-code}\n# Challenge 2\njson2 <- '{\"a\": [1, 2, 3], \"b\": [4, 5, 6]}'\nfromJSON(json2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> $a\n#> [1] 1 2 3\n#> \n#> $b\n#> [1] 4 5 6\n```\n:::\n:::\n\n\n\n## JSON practice (2)\n\nWe prepared two more JSON strings in the sample code. Can you change them and call `jsonlite`'s <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> function on them, similar to the previous exercise?\n\n\n**Steps**\n\n1. Remove characters from `json1` to build a 2 by 2 matrix containing only 1, 2, 3 and 4. Call <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> on `json1`.\n2. Add characters to `json2` such that the data frame in which the json is converted contains an additional observation in the last row. For this observations, `a` equals 5 and `b` equals 6. Call <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a> one last time, on `json2`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Challenge 1\njson1 <- '[[1, 2], [3, 4]]'\nfromJSON(json1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n```\n:::\n\n```{.r .cell-code}\n# Challenge 2\njson2 <- '[{\"a\": 1, \"b\": 2}, {\"a\": 3, \"b\": 4}, {\"a\": 5, \"b\": 6}]'\nfromJSON(json2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"a\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"b\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"2\",\"_rn_\":\"1\"},{\"1\":\"3\",\"2\":\"4\",\"_rn_\":\"2\"},{\"1\":\"5\",\"2\":\"6\",\"_rn_\":\"3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nGreat! As you can see different JSON data structures will lead to different data structures in `R`.\n\n## toJSON()\n\nApart from converting JSON to R with <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`fromJSON()`</a>, you can also use <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`toJSON()`</a> to convert R data to a JSON format. In its most basic use, you simply pass this function an R object to convert to a JSON. The result is an R object of the class `json`, which is basically a character string representing that JSON.\n\nFor this exercise, you will be working with a `.csv` file containing information on the amount of desalinated water that is produced around the world. As you'll see, it contains a lot of missing values. This data can be found on the URL that is specified in the sample code.\n\n\n**Steps**\n\n1. Use a function of the `utils` package to import the `.csv` file directly from the URL specified in `url_csv`. Save the resulting data frame as `water`. Make sure that strings are *not* imported as factors.\n2. Convert the data frame `water` to a JSON. Call the resulting object `water_json`.\n3. Print out `water_json`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# URL pointing to the .csv file\nurl_csv <- \"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/water.csv\"\n\n# Import the .csv file located at url_csv\nwater <- utils::read.csv(url_csv, stringsAsFactors = FALSE)\n\n# Convert the data file according to the requirements\nwater_json <- toJSON(water)\n\n# Print out water_json\nprint(water_json)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [{\"water\":\"Algeria\",\"X1992\":0.064,\"X2002\":0.017},{\"water\":\"American Samoa\"},{\"water\":\"Angola\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"Antigua and Barbuda\",\"X1992\":0.0033},{\"water\":\"Argentina\",\"X1992\":0.0007,\"X1997\":0.0007,\"X2002\":0.0007},{\"water\":\"Australia\",\"X1992\":0.0298,\"X2002\":0.0298},{\"water\":\"Austria\",\"X1992\":0.0022,\"X2002\":0.0022},{\"water\":\"Bahamas\",\"X1992\":0.0013,\"X2002\":0.0074},{\"water\":\"Bahrain\",\"X1992\":0.0441,\"X2002\":0.0441,\"X2007\":0.1024},{\"water\":\"Barbados\",\"X2007\":0.0146},{\"water\":\"British Virgin Islands\",\"X2007\":0.0042},{\"water\":\"Canada\",\"X1992\":0.0027,\"X2002\":0.0027},{\"water\":\"Cape Verde\",\"X1992\":0.002,\"X1997\":0.0017},{\"water\":\"Cayman Islands\",\"X1992\":0.0033},{\"water\":\"Central African Rep.\"},{\"water\":\"Chile\",\"X1992\":0.0048,\"X2002\":0.0048},{\"water\":\"Colombia\",\"X1992\":0.0027,\"X2002\":0.0027},{\"water\":\"Cuba\",\"X1992\":0.0069,\"X1997\":0.0069,\"X2002\":0.0069},{\"water\":\"Cyprus\",\"X1992\":0.003,\"X1997\":0.003,\"X2002\":0.0335},{\"water\":\"Czech Rep.\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"Denmark\",\"X1992\":0.015,\"X2002\":0.015},{\"water\":\"Djibouti\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"Ecuador\",\"X1992\":0.0022,\"X1997\":0.0022,\"X2002\":0.0022},{\"water\":\"Egypt\",\"X1992\":0.025,\"X1997\":0.025,\"X2002\":0.1},{\"water\":\"El Salvador\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"Finland\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"France\",\"X1992\":0.0117,\"X2002\":0.0117},{\"water\":\"Gibraltar\",\"X1992\":0.0077},{\"water\":\"Greece\",\"X1992\":0.01,\"X2002\":0.01},{\"water\":\"Honduras\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"Hungary\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"India\",\"X1997\":0.0005,\"X2002\":0.0005},{\"water\":\"Indonesia\",\"X1992\":0.0187,\"X2002\":0.0187},{\"water\":\"Iran\",\"X1992\":0.003,\"X1997\":0.003,\"X2002\":0.003,\"X2007\":0.2},{\"water\":\"Iraq\",\"X1997\":0.0074,\"X2002\":0.0074},{\"water\":\"Ireland\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"Israel\",\"X1992\":0.0256,\"X2002\":0.0256,\"X2007\":0.14},{\"water\":\"Italy\",\"X1992\":0.0973,\"X2002\":0.0973},{\"water\":\"Jamaica\",\"X1992\":0.0005,\"X1997\":0.0005,\"X2002\":0.0005},{\"water\":\"Japan\",\"X1997\":0.04,\"X2002\":0.04},{\"water\":\"Jordan\",\"X1997\":0.002,\"X2007\":0.0098},{\"water\":\"Kazakhstan\",\"X1997\":1.328,\"X2002\":1.328},{\"water\":\"Kuwait\",\"X1992\":0.507,\"X1997\":0.231,\"X2002\":0.4202},{\"water\":\"Lebanon\",\"X2007\":0.0473},{\"water\":\"Libya\",\"X2002\":0.018},{\"water\":\"Malaysia\",\"X1992\":0.0043,\"X2002\":0.0043},{\"water\":\"Maldives\",\"X1992\":0.0004},{\"water\":\"Malta\",\"X1992\":0.024,\"X1997\":0.031,\"X2002\":0.031},{\"water\":\"Marshall Islands\",\"X1992\":0.0007},{\"water\":\"Mauritania\",\"X1992\":0.002,\"X2002\":0.002},{\"water\":\"Mexico\",\"X1992\":0.0307,\"X2002\":0.0307},{\"water\":\"Morocco\",\"X1992\":0.0034,\"X1997\":0.0034,\"X2002\":0.007},{\"water\":\"Namibia\",\"X1992\":0.0003,\"X2002\":0.0003},{\"water\":\"Netherlands Antilles\",\"X1992\":0.063},{\"water\":\"Nicaragua\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"Nigeria\",\"X1992\":0.003,\"X2002\":0.003},{\"water\":\"Norway\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"Oman\",\"X1997\":0.034,\"X2002\":0.034,\"X2007\":0.109},{\"water\":\"Peru\",\"X1992\":0.0054,\"X2002\":0.0054},{\"water\":\"Poland\",\"X1992\":0.007,\"X2002\":0.007},{\"water\":\"Portugal\",\"X1992\":0.0016,\"X2002\":0.0016},{\"water\":\"Qatar\",\"X1992\":0.065,\"X1997\":0.099,\"X2002\":0.099,\"X2007\":0.18},{\"water\":\"Saudi Arabia\",\"X1992\":0.683,\"X1997\":0.727,\"X2002\":0.863,\"X2007\":1.033},{\"water\":\"Senegal\",\"X1992\":0,\"X2002\":0},{\"water\":\"Somalia\",\"X1992\":0.0001,\"X2002\":0.0001},{\"water\":\"South Africa\",\"X1992\":0.018,\"X2002\":0.018},{\"water\":\"Spain\",\"X1992\":0.1002,\"X2002\":0.1002},{\"water\":\"Sudan\",\"X1992\":0.0004,\"X1997\":0.0004,\"X2002\":0.0004},{\"water\":\"Sweden\",\"X1992\":0.0002,\"X2002\":0.0002},{\"water\":\"Trinidad and Tobago\",\"X2007\":0.036},{\"water\":\"Tunisia\",\"X1992\":0.008,\"X2002\":0.013},{\"water\":\"Turkey\",\"X1992\":0.0005,\"X2002\":0.0005,\"X2007\":0.0005},{\"water\":\"United Arab Emirates\",\"X1992\":0.163,\"X1997\":0.385,\"X2007\":0.95},{\"water\":\"United Kingdom\",\"X1992\":0.0333,\"X2002\":0.0333},{\"water\":\"United States\",\"X1992\":0.58,\"X2002\":0.58},{\"water\":\"Venezuela\",\"X1992\":0.0052,\"X2002\":0.0052},{\"water\":\"Yemen, Rep.\",\"X1992\":0.01,\"X2002\":0.01}]\n```\n:::\n:::\n\n\nCongratulations! As you can see, the JSON you printed out isn't easy to read. In the next exercise, you will print out some more JSONs, and explore ways to prettify or minify the output.\n\n## Minify and prettify\n\nJSONs can come in different formats. Take these two JSONs, that are in fact exactly the same: the first one is in a minified format, the second one is in a pretty format with indentation, whitespace and new lines:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.json .cell-code}\n# Mini\n{\"a\":1,\"b\":2,\"c\":{\"x\":5,\"y\":6}}\n\n# Pretty\n{\n  \"a\": 1,\n  \"b\": 2,\n  \"c\": {\n    \"x\": 5,\n    \"y\": 6\n  }\n}\n```\n:::\n\n\nUnless you're a computer, you surely prefer the second version. However, the standard form that <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`toJSON()`</a> returns, is the minified version, as it is more concise. You can adapt this behavior by setting the `pretty` argument inside <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/fromJSON\" target=\"_blank\" rel=\"noopener noreferrer\">`toJSON()`</a> to `TRUE`. If you already have a JSON string, you can use <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/prettify\" target=\"_blank\" rel=\"noopener noreferrer\">`prettify()`</a> or <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/prettify\" target=\"_blank\" rel=\"noopener noreferrer\">`minify()`</a> to make the JSON pretty or as concise as possible.\n\n\n**Steps**\n\n1. Convert the `mtcars` dataset, which is available in R by default, to a *pretty* `JSON`. Call the resulting JSON `pretty_json`.\n2. Print out `pretty_json`. Can you understand the output easily?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Convert mtcars to a pretty JSON: pretty_json\npretty_json <- toJSON(mtcars, pretty = T)\n\n# Print pretty_json\npretty_json\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [\n#>   {\n#>     \"mpg\": 21,\n#>     \"cyl\": 6,\n#>     \"disp\": 160,\n#>     \"hp\": 110,\n#>     \"drat\": 3.9,\n#>     \"wt\": 2.62,\n#>     \"qsec\": 16.46,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 4,\n#>     \"_row\": \"Mazda RX4\"\n#>   },\n#>   {\n#>     \"mpg\": 21,\n#>     \"cyl\": 6,\n#>     \"disp\": 160,\n#>     \"hp\": 110,\n#>     \"drat\": 3.9,\n#>     \"wt\": 2.875,\n#>     \"qsec\": 17.02,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 4,\n#>     \"_row\": \"Mazda RX4 Wag\"\n#>   },\n#>   {\n#>     \"mpg\": 22.8,\n#>     \"cyl\": 4,\n#>     \"disp\": 108,\n#>     \"hp\": 93,\n#>     \"drat\": 3.85,\n#>     \"wt\": 2.32,\n#>     \"qsec\": 18.61,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 1,\n#>     \"_row\": \"Datsun 710\"\n#>   },\n#>   {\n#>     \"mpg\": 21.4,\n#>     \"cyl\": 6,\n#>     \"disp\": 258,\n#>     \"hp\": 110,\n#>     \"drat\": 3.08,\n#>     \"wt\": 3.215,\n#>     \"qsec\": 19.44,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 1,\n#>     \"_row\": \"Hornet 4 Drive\"\n#>   },\n#>   {\n#>     \"mpg\": 18.7,\n#>     \"cyl\": 8,\n#>     \"disp\": 360,\n#>     \"hp\": 175,\n#>     \"drat\": 3.15,\n#>     \"wt\": 3.44,\n#>     \"qsec\": 17.02,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 2,\n#>     \"_row\": \"Hornet Sportabout\"\n#>   },\n#>   {\n#>     \"mpg\": 18.1,\n#>     \"cyl\": 6,\n#>     \"disp\": 225,\n#>     \"hp\": 105,\n#>     \"drat\": 2.76,\n#>     \"wt\": 3.46,\n#>     \"qsec\": 20.22,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 1,\n#>     \"_row\": \"Valiant\"\n#>   },\n#>   {\n#>     \"mpg\": 14.3,\n#>     \"cyl\": 8,\n#>     \"disp\": 360,\n#>     \"hp\": 245,\n#>     \"drat\": 3.21,\n#>     \"wt\": 3.57,\n#>     \"qsec\": 15.84,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 4,\n#>     \"_row\": \"Duster 360\"\n#>   },\n#>   {\n#>     \"mpg\": 24.4,\n#>     \"cyl\": 4,\n#>     \"disp\": 146.7,\n#>     \"hp\": 62,\n#>     \"drat\": 3.69,\n#>     \"wt\": 3.19,\n#>     \"qsec\": 20,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 4,\n#>     \"carb\": 2,\n#>     \"_row\": \"Merc 240D\"\n#>   },\n#>   {\n#>     \"mpg\": 22.8,\n#>     \"cyl\": 4,\n#>     \"disp\": 140.8,\n#>     \"hp\": 95,\n#>     \"drat\": 3.92,\n#>     \"wt\": 3.15,\n#>     \"qsec\": 22.9,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 4,\n#>     \"carb\": 2,\n#>     \"_row\": \"Merc 230\"\n#>   },\n#>   {\n#>     \"mpg\": 19.2,\n#>     \"cyl\": 6,\n#>     \"disp\": 167.6,\n#>     \"hp\": 123,\n#>     \"drat\": 3.92,\n#>     \"wt\": 3.44,\n#>     \"qsec\": 18.3,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 4,\n#>     \"carb\": 4,\n#>     \"_row\": \"Merc 280\"\n#>   },\n#>   {\n#>     \"mpg\": 17.8,\n#>     \"cyl\": 6,\n#>     \"disp\": 167.6,\n#>     \"hp\": 123,\n#>     \"drat\": 3.92,\n#>     \"wt\": 3.44,\n#>     \"qsec\": 18.9,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 4,\n#>     \"carb\": 4,\n#>     \"_row\": \"Merc 280C\"\n#>   },\n#>   {\n#>     \"mpg\": 16.4,\n#>     \"cyl\": 8,\n#>     \"disp\": 275.8,\n#>     \"hp\": 180,\n#>     \"drat\": 3.07,\n#>     \"wt\": 4.07,\n#>     \"qsec\": 17.4,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 3,\n#>     \"_row\": \"Merc 450SE\"\n#>   },\n#>   {\n#>     \"mpg\": 17.3,\n#>     \"cyl\": 8,\n#>     \"disp\": 275.8,\n#>     \"hp\": 180,\n#>     \"drat\": 3.07,\n#>     \"wt\": 3.73,\n#>     \"qsec\": 17.6,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 3,\n#>     \"_row\": \"Merc 450SL\"\n#>   },\n#>   {\n#>     \"mpg\": 15.2,\n#>     \"cyl\": 8,\n#>     \"disp\": 275.8,\n#>     \"hp\": 180,\n#>     \"drat\": 3.07,\n#>     \"wt\": 3.78,\n#>     \"qsec\": 18,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 3,\n#>     \"_row\": \"Merc 450SLC\"\n#>   },\n#>   {\n#>     \"mpg\": 10.4,\n#>     \"cyl\": 8,\n#>     \"disp\": 472,\n#>     \"hp\": 205,\n#>     \"drat\": 2.93,\n#>     \"wt\": 5.25,\n#>     \"qsec\": 17.98,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 4,\n#>     \"_row\": \"Cadillac Fleetwood\"\n#>   },\n#>   {\n#>     \"mpg\": 10.4,\n#>     \"cyl\": 8,\n#>     \"disp\": 460,\n#>     \"hp\": 215,\n#>     \"drat\": 3,\n#>     \"wt\": 5.424,\n#>     \"qsec\": 17.82,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 4,\n#>     \"_row\": \"Lincoln Continental\"\n#>   },\n#>   {\n#>     \"mpg\": 14.7,\n#>     \"cyl\": 8,\n#>     \"disp\": 440,\n#>     \"hp\": 230,\n#>     \"drat\": 3.23,\n#>     \"wt\": 5.345,\n#>     \"qsec\": 17.42,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 4,\n#>     \"_row\": \"Chrysler Imperial\"\n#>   },\n#>   {\n#>     \"mpg\": 32.4,\n#>     \"cyl\": 4,\n#>     \"disp\": 78.7,\n#>     \"hp\": 66,\n#>     \"drat\": 4.08,\n#>     \"wt\": 2.2,\n#>     \"qsec\": 19.47,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 1,\n#>     \"_row\": \"Fiat 128\"\n#>   },\n#>   {\n#>     \"mpg\": 30.4,\n#>     \"cyl\": 4,\n#>     \"disp\": 75.7,\n#>     \"hp\": 52,\n#>     \"drat\": 4.93,\n#>     \"wt\": 1.615,\n#>     \"qsec\": 18.52,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 2,\n#>     \"_row\": \"Honda Civic\"\n#>   },\n#>   {\n#>     \"mpg\": 33.9,\n#>     \"cyl\": 4,\n#>     \"disp\": 71.1,\n#>     \"hp\": 65,\n#>     \"drat\": 4.22,\n#>     \"wt\": 1.835,\n#>     \"qsec\": 19.9,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 1,\n#>     \"_row\": \"Toyota Corolla\"\n#>   },\n#>   {\n#>     \"mpg\": 21.5,\n#>     \"cyl\": 4,\n#>     \"disp\": 120.1,\n#>     \"hp\": 97,\n#>     \"drat\": 3.7,\n#>     \"wt\": 2.465,\n#>     \"qsec\": 20.01,\n#>     \"vs\": 1,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 1,\n#>     \"_row\": \"Toyota Corona\"\n#>   },\n#>   {\n#>     \"mpg\": 15.5,\n#>     \"cyl\": 8,\n#>     \"disp\": 318,\n#>     \"hp\": 150,\n#>     \"drat\": 2.76,\n#>     \"wt\": 3.52,\n#>     \"qsec\": 16.87,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 2,\n#>     \"_row\": \"Dodge Challenger\"\n#>   },\n#>   {\n#>     \"mpg\": 15.2,\n#>     \"cyl\": 8,\n#>     \"disp\": 304,\n#>     \"hp\": 150,\n#>     \"drat\": 3.15,\n#>     \"wt\": 3.435,\n#>     \"qsec\": 17.3,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 2,\n#>     \"_row\": \"AMC Javelin\"\n#>   },\n#>   {\n#>     \"mpg\": 13.3,\n#>     \"cyl\": 8,\n#>     \"disp\": 350,\n#>     \"hp\": 245,\n#>     \"drat\": 3.73,\n#>     \"wt\": 3.84,\n#>     \"qsec\": 15.41,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 4,\n#>     \"_row\": \"Camaro Z28\"\n#>   },\n#>   {\n#>     \"mpg\": 19.2,\n#>     \"cyl\": 8,\n#>     \"disp\": 400,\n#>     \"hp\": 175,\n#>     \"drat\": 3.08,\n#>     \"wt\": 3.845,\n#>     \"qsec\": 17.05,\n#>     \"vs\": 0,\n#>     \"am\": 0,\n#>     \"gear\": 3,\n#>     \"carb\": 2,\n#>     \"_row\": \"Pontiac Firebird\"\n#>   },\n#>   {\n#>     \"mpg\": 27.3,\n#>     \"cyl\": 4,\n#>     \"disp\": 79,\n#>     \"hp\": 66,\n#>     \"drat\": 4.08,\n#>     \"wt\": 1.935,\n#>     \"qsec\": 18.9,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 1,\n#>     \"_row\": \"Fiat X1-9\"\n#>   },\n#>   {\n#>     \"mpg\": 26,\n#>     \"cyl\": 4,\n#>     \"disp\": 120.3,\n#>     \"hp\": 91,\n#>     \"drat\": 4.43,\n#>     \"wt\": 2.14,\n#>     \"qsec\": 16.7,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 5,\n#>     \"carb\": 2,\n#>     \"_row\": \"Porsche 914-2\"\n#>   },\n#>   {\n#>     \"mpg\": 30.4,\n#>     \"cyl\": 4,\n#>     \"disp\": 95.1,\n#>     \"hp\": 113,\n#>     \"drat\": 3.77,\n#>     \"wt\": 1.513,\n#>     \"qsec\": 16.9,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 5,\n#>     \"carb\": 2,\n#>     \"_row\": \"Lotus Europa\"\n#>   },\n#>   {\n#>     \"mpg\": 15.8,\n#>     \"cyl\": 8,\n#>     \"disp\": 351,\n#>     \"hp\": 264,\n#>     \"drat\": 4.22,\n#>     \"wt\": 3.17,\n#>     \"qsec\": 14.5,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 5,\n#>     \"carb\": 4,\n#>     \"_row\": \"Ford Pantera L\"\n#>   },\n#>   {\n#>     \"mpg\": 19.7,\n#>     \"cyl\": 6,\n#>     \"disp\": 145,\n#>     \"hp\": 175,\n#>     \"drat\": 3.62,\n#>     \"wt\": 2.77,\n#>     \"qsec\": 15.5,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 5,\n#>     \"carb\": 6,\n#>     \"_row\": \"Ferrari Dino\"\n#>   },\n#>   {\n#>     \"mpg\": 15,\n#>     \"cyl\": 8,\n#>     \"disp\": 301,\n#>     \"hp\": 335,\n#>     \"drat\": 3.54,\n#>     \"wt\": 3.57,\n#>     \"qsec\": 14.6,\n#>     \"vs\": 0,\n#>     \"am\": 1,\n#>     \"gear\": 5,\n#>     \"carb\": 8,\n#>     \"_row\": \"Maserati Bora\"\n#>   },\n#>   {\n#>     \"mpg\": 21.4,\n#>     \"cyl\": 4,\n#>     \"disp\": 121,\n#>     \"hp\": 109,\n#>     \"drat\": 4.11,\n#>     \"wt\": 2.78,\n#>     \"qsec\": 18.6,\n#>     \"vs\": 1,\n#>     \"am\": 1,\n#>     \"gear\": 4,\n#>     \"carb\": 2,\n#>     \"_row\": \"Volvo 142E\"\n#>   }\n#> ]\n```\n:::\n:::\n\n\n3. Convert `pretty_json` to a minimal version using <a href=\"http://www.rdocumentation.org/packages/jsonlite/functions/prettify\" target=\"_blank\" rel=\"noopener noreferrer\">`minify()`</a>. Store this version under a new variable, `mini_json`.\n4. Print out `mini_json`. Which version do you prefer, the pretty one or the minified one?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Minify pretty_json: mini_json\nmini_json <- minify(pretty_json)\n\n# Print mini_json\nmini_json\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [{\"mpg\":21,\"cyl\":6,\"disp\":160,\"hp\":110,\"drat\":3.9,\"wt\":2.62,\"qsec\":16.46,\"vs\":0,\"am\":1,\"gear\":4,\"carb\":4,\"_row\":\"Mazda RX4\"},{\"mpg\":21,\"cyl\":6,\"disp\":160,\"hp\":110,\"drat\":3.9,\"wt\":2.875,\"qsec\":17.02,\"vs\":0,\"am\":1,\"gear\":4,\"carb\":4,\"_row\":\"Mazda RX4 Wag\"},{\"mpg\":22.8,\"cyl\":4,\"disp\":108,\"hp\":93,\"drat\":3.85,\"wt\":2.32,\"qsec\":18.61,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":1,\"_row\":\"Datsun 710\"},{\"mpg\":21.4,\"cyl\":6,\"disp\":258,\"hp\":110,\"drat\":3.08,\"wt\":3.215,\"qsec\":19.44,\"vs\":1,\"am\":0,\"gear\":3,\"carb\":1,\"_row\":\"Hornet 4 Drive\"},{\"mpg\":18.7,\"cyl\":8,\"disp\":360,\"hp\":175,\"drat\":3.15,\"wt\":3.44,\"qsec\":17.02,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":2,\"_row\":\"Hornet Sportabout\"},{\"mpg\":18.1,\"cyl\":6,\"disp\":225,\"hp\":105,\"drat\":2.76,\"wt\":3.46,\"qsec\":20.22,\"vs\":1,\"am\":0,\"gear\":3,\"carb\":1,\"_row\":\"Valiant\"},{\"mpg\":14.3,\"cyl\":8,\"disp\":360,\"hp\":245,\"drat\":3.21,\"wt\":3.57,\"qsec\":15.84,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":4,\"_row\":\"Duster 360\"},{\"mpg\":24.4,\"cyl\":4,\"disp\":146.7,\"hp\":62,\"drat\":3.69,\"wt\":3.19,\"qsec\":20,\"vs\":1,\"am\":0,\"gear\":4,\"carb\":2,\"_row\":\"Merc 240D\"},{\"mpg\":22.8,\"cyl\":4,\"disp\":140.8,\"hp\":95,\"drat\":3.92,\"wt\":3.15,\"qsec\":22.9,\"vs\":1,\"am\":0,\"gear\":4,\"carb\":2,\"_row\":\"Merc 230\"},{\"mpg\":19.2,\"cyl\":6,\"disp\":167.6,\"hp\":123,\"drat\":3.92,\"wt\":3.44,\"qsec\":18.3,\"vs\":1,\"am\":0,\"gear\":4,\"carb\":4,\"_row\":\"Merc 280\"},{\"mpg\":17.8,\"cyl\":6,\"disp\":167.6,\"hp\":123,\"drat\":3.92,\"wt\":3.44,\"qsec\":18.9,\"vs\":1,\"am\":0,\"gear\":4,\"carb\":4,\"_row\":\"Merc 280C\"},{\"mpg\":16.4,\"cyl\":8,\"disp\":275.8,\"hp\":180,\"drat\":3.07,\"wt\":4.07,\"qsec\":17.4,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":3,\"_row\":\"Merc 450SE\"},{\"mpg\":17.3,\"cyl\":8,\"disp\":275.8,\"hp\":180,\"drat\":3.07,\"wt\":3.73,\"qsec\":17.6,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":3,\"_row\":\"Merc 450SL\"},{\"mpg\":15.2,\"cyl\":8,\"disp\":275.8,\"hp\":180,\"drat\":3.07,\"wt\":3.78,\"qsec\":18,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":3,\"_row\":\"Merc 450SLC\"},{\"mpg\":10.4,\"cyl\":8,\"disp\":472,\"hp\":205,\"drat\":2.93,\"wt\":5.25,\"qsec\":17.98,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":4,\"_row\":\"Cadillac Fleetwood\"},{\"mpg\":10.4,\"cyl\":8,\"disp\":460,\"hp\":215,\"drat\":3,\"wt\":5.424,\"qsec\":17.82,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":4,\"_row\":\"Lincoln Continental\"},{\"mpg\":14.7,\"cyl\":8,\"disp\":440,\"hp\":230,\"drat\":3.23,\"wt\":5.345,\"qsec\":17.42,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":4,\"_row\":\"Chrysler Imperial\"},{\"mpg\":32.4,\"cyl\":4,\"disp\":78.7,\"hp\":66,\"drat\":4.08,\"wt\":2.2,\"qsec\":19.47,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":1,\"_row\":\"Fiat 128\"},{\"mpg\":30.4,\"cyl\":4,\"disp\":75.7,\"hp\":52,\"drat\":4.93,\"wt\":1.615,\"qsec\":18.52,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":2,\"_row\":\"Honda Civic\"},{\"mpg\":33.9,\"cyl\":4,\"disp\":71.1,\"hp\":65,\"drat\":4.22,\"wt\":1.835,\"qsec\":19.9,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":1,\"_row\":\"Toyota Corolla\"},{\"mpg\":21.5,\"cyl\":4,\"disp\":120.1,\"hp\":97,\"drat\":3.7,\"wt\":2.465,\"qsec\":20.01,\"vs\":1,\"am\":0,\"gear\":3,\"carb\":1,\"_row\":\"Toyota Corona\"},{\"mpg\":15.5,\"cyl\":8,\"disp\":318,\"hp\":150,\"drat\":2.76,\"wt\":3.52,\"qsec\":16.87,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":2,\"_row\":\"Dodge Challenger\"},{\"mpg\":15.2,\"cyl\":8,\"disp\":304,\"hp\":150,\"drat\":3.15,\"wt\":3.435,\"qsec\":17.3,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":2,\"_row\":\"AMC Javelin\"},{\"mpg\":13.3,\"cyl\":8,\"disp\":350,\"hp\":245,\"drat\":3.73,\"wt\":3.84,\"qsec\":15.41,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":4,\"_row\":\"Camaro Z28\"},{\"mpg\":19.2,\"cyl\":8,\"disp\":400,\"hp\":175,\"drat\":3.08,\"wt\":3.845,\"qsec\":17.05,\"vs\":0,\"am\":0,\"gear\":3,\"carb\":2,\"_row\":\"Pontiac Firebird\"},{\"mpg\":27.3,\"cyl\":4,\"disp\":79,\"hp\":66,\"drat\":4.08,\"wt\":1.935,\"qsec\":18.9,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":1,\"_row\":\"Fiat X1-9\"},{\"mpg\":26,\"cyl\":4,\"disp\":120.3,\"hp\":91,\"drat\":4.43,\"wt\":2.14,\"qsec\":16.7,\"vs\":0,\"am\":1,\"gear\":5,\"carb\":2,\"_row\":\"Porsche 914-2\"},{\"mpg\":30.4,\"cyl\":4,\"disp\":95.1,\"hp\":113,\"drat\":3.77,\"wt\":1.513,\"qsec\":16.9,\"vs\":1,\"am\":1,\"gear\":5,\"carb\":2,\"_row\":\"Lotus Europa\"},{\"mpg\":15.8,\"cyl\":8,\"disp\":351,\"hp\":264,\"drat\":4.22,\"wt\":3.17,\"qsec\":14.5,\"vs\":0,\"am\":1,\"gear\":5,\"carb\":4,\"_row\":\"Ford Pantera L\"},{\"mpg\":19.7,\"cyl\":6,\"disp\":145,\"hp\":175,\"drat\":3.62,\"wt\":2.77,\"qsec\":15.5,\"vs\":0,\"am\":1,\"gear\":5,\"carb\":6,\"_row\":\"Ferrari Dino\"},{\"mpg\":15,\"cyl\":8,\"disp\":301,\"hp\":335,\"drat\":3.54,\"wt\":3.57,\"qsec\":14.6,\"vs\":0,\"am\":1,\"gear\":5,\"carb\":8,\"_row\":\"Maserati Bora\"},{\"mpg\":21.4,\"cyl\":4,\"disp\":121,\"hp\":109,\"drat\":4.11,\"wt\":2.78,\"qsec\":18.6,\"vs\":1,\"am\":1,\"gear\":4,\"carb\":2,\"_row\":\"Volvo 142E\"}]\n```\n:::\n:::\n\n\nGreat! Hopefully you agree that the pretty format is way easier to read and understand than the minified format! This exercise concludes the course on importing data!\n\n# 5. Importing data from statistical software packages\n\nNext to R, there are also other commonly used statistical software packages: SAS, STATA and SPSS. Each of them has their own file format. Learn how to use the haven and foreign packages to get them into R with remarkable ease!\n\n## haven\n\nTheory. Coming soon ...\n\n\n**1. haven**\n\nOne thing we haven't discussed yet, is data from other\n\n**2. Statistical Software Packages**\n\nstatistical software packages. The most common\n\n**3. Statistical Software Packages**\n\nones are SAS, short for Statistical Analysis Software, STATA, which stands for statistics and data, and SPSS, or the statistical package for social sciences.Which software people use depends on the field of study or personal preference.\n\n**4. Statistical Software Packages**\n\nSAS, for example, is one of the most wide spread Business Analytic software tools and is also commonly used in Biostatistics or Medical Sciences. On the other hand, STATA is a typical tool for Economists. SPSS is often used in Social Sciences, hence the name.\n\n**5. Statistical Software Packages**\n\nIn the end, each software uses and produces their own file types. The most common extensions are listed here.\n\n**6. R packages to import data**\n\nNo matter the package your data comes from, R is prepared for every file that'll come along! In the rest of this chapter, you will learn how to use two R packages that can import data from these software environments: haven and foreign. The first one is written by Hadley Wickham, the other one by the R core team. The foreign package has been around for a longer time, while haven is still in development today, which is late 2015. Wickham aims to provide a more consistent, easier to use and faster alternative to foreign. On the other hand, foreign supports more data formats. But let's not jump to conclusions here. In this video, I'll talk about haven some more, and in the next video I'll talk about foreign. After that, you can choose for yourself which package you prefer.\n\n**7. haven**\n\nSo, the haven package. This package can deal with SAS, STATA and SPSS data files. It does this by wrapping around the ReadStat C library by Evan Miller. Just like readr and readxl, the package is extremely simple to use. You pass the path to the data file and an R data frame results.After you've installed haven with install-dot-packages, you can load it with the library function.\n\n**8. SAS data**\n\nLet's start with loading a SAS data file first. Suppose you have a file, 'ontime dot sas7bdat' in your current working directory. It contains data on the percentage of flights that arrived on time for several airlines in the US. To import this data as a data frame on time, you simply use the function read_sas and pass the path to the data file:\n\n**9. SAS data**\n\nIf you print its structure, you'll see that each variable in the data frame also has a label attribute. If you're familiar with SAS, you know that you can label variables in SAS datasets. Well, it's these same labels that are also available inside R now.\n\n**10. SAS data**\n\nWhen simply printing ontime, you don't see any difference with a normal data frame without labels.\n\n**11. SAS data**\n\nIf you use RStudio's View function to explore a dataset, though,\n\n**12. SAS data**\n\nyou'll see the labels:Can you read the data here? In March of 1999, for example,\n\n**13. SAS data**\n\nit appears that around 79 percent of all Delta Airline flights were on time.\n\n**14. STATA data**\n\nNext up is STATA. Haven is able to import both Stata 13 and 14 files with the read_stata function. You can also use read_dta, which does exactly the same.\n\n**15. STATA data**\n\nJust like before, simply passing the path to the dot dta file will do the trick. Suppose that the same statistics on the us airlines are now available as a dot dta file, ontime dot dta, which is in your current working directory, you can try either one of these calls.The printout looks pretty familiar again, but there's something different here. The names of the Airlines are converted to numbers, they aren't character strings anymore. How did that come about?\n\n**16. STATA data**\n\nIf you have a look at the class of the Airline column of ontime, it appears to be of class labelled.This is the R version of the labelled vector, a common data structure in other statistical packages. If you simply print this Airline column, you can see the airline names from before.R assigned numbers for each variable according to their alphabetical order. As you want to continue your analysis in R, it's a good idea to convert this vector to a standard R class, such as a factor.\n\n**17. as_factor()**\n\nInstead of the standard as dot factor function, of base R, you'll need 'haven's as underscore factor for this.This is the type of categorical variables we're used to. In this case, it might be even better to have simple characters for the airline names, as these are not really categories. The base R as dot character function can do this for you. Let's just place it around the previous call.\n\n**18. as_factor()**\n\nIf you assign this result to the Airline column of ontime again, you've made the ontime data frame ready for some more analysis, with the names as simple character strings.\n\n**19. SPSS data**\n\nLast but not least, there is SPSS data. Here, you'll want to use read_spss. Based on the extension, haven will decide for you which function to call: read_por for dot por files, or read_sav for dot sav files.Let's once more load in the airline data, that's stored as a dot sav file in the datasets folder of our personal directory.Again, a data frame results. The Airline column is a so-called labelled vector again. The column names here are slightly different from before.\n\n**20. Statistical Software Packages**\n\nIt should be clear by now: haven is incredibly easy to use and simply does what's it supposed to. Have a quick look at the summary here, now with the corresponding functions.\n\n## Import SAS data with haven\n\n`haven` is an extremely easy-to-use package to import data from three software packages: SAS, STATA and SPSS. Depending on the software, you use different functions:\n\n* SAS: <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_sas()`</a>\n* STATA: <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_dta()`</a> (or <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_stata()`</a>, which are identical)\n* SPSS: <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_sav()`</a> or <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_por()`</a>, depending on the file type.\n\nAll these functions take one key argument: the path to your local file. In fact, you can even pass a URL; `haven` will then automatically download the file for you before importing it.\n\nYou'll be working with data on the age, gender, income, and purchase level (0 = low, 1 = high) of 36 individuals (Source: <a href=\"http://support.sas.com/learn/\" target=\"_blank\" rel=\"noopener noreferrer\">SAS</a>). The information is stored in a SAS file, `sales.sas7bdat`, which is available in your current working directory. You can also download the data <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/sales.sas7bdat\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.\n\n**Steps**\n\n1. Load the `haven` package; it's already installed on DataCamp's servers.\n2. Import the data file `\"sales.sas7bdat\"`. Call the imported data frame `sales`.\n3. Display the structure of `sales` with <a href=\"http://www.rdocumentation.org/packages/utils/functions/str\" target=\"_blank\" rel=\"noopener noreferrer\">`str()`</a>. Some columns represent categorical variables, so they should be factors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the haven package\nlibrary(haven)\n\n# Import sales.sas7bdat: sales\nsales <- read_sas(\"data/sales.sas7bdat\")\n\n# Display the structure of sales\nstr(sales)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> tibble [431 × 4] (S3: tbl_df/tbl/data.frame)\n#>  $ purchase: num [1:431] 0 0 1 1 0 0 0 0 0 0 ...\n#>  $ age     : num [1:431] 41 47 41 39 32 32 33 45 43 40 ...\n#>  $ gender  : chr [1:431] \"Female\" \"Female\" \"Female\" \"Female\" ...\n#>  $ income  : chr [1:431] \"Low\" \"Low\" \"Low\" \"Low\" ...\n```\n:::\n:::\n\n\nCongratulations! As you can see, [`read_sas()`](http://cran.r-project.org/web/packages/haven/haven.pdf) enables you to import <b>SAS</b> data files easily.\n\n## Import STATA data with haven\n\nNext up are STATA data files; you can use <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_dta()`</a> for these.\n\nWhen inspecting the result of the `read_dta()` call, you will notice that one column will be imported as a `labelled` vector, an R equivalent for the common data structure in other statistical environments. In order to effectively continue working on the data in R, it's best to change this data into a standard R class. To convert a variable of the class `labelled` to a factor, you'll need `haven`'s <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`as_factor()`</a> function.\n\nIn this exercise, you will work with data on yearly import and export numbers of sugar, both in USD and in weight. The data can be found at:\n<a href=\"http://assets.datacamp.com/production/course_1478/datasets/trade.dta\" target=\"_blank\" rel=\"noopener noreferrer\">http://assets.datacamp.com/production/course_1478/datasets/trade.dta</a>\n\n**Steps**\n\n1. Import the data file directly from the URL using <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_dta()`</a>, and store it as `sugar`.\n2. Print out the structure of `sugar`. The `Date` column has class `labelled`.\n3. Convert the values in the `Date` column of `sugar` to dates, using `as.Date(as_factor(___))`.\n4. Print out the structure of `sugar` once more. Looks better now?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import the data from the URL: sugar\nsugar <- read_dta(\"http://assets.datacamp.com/production/course_1478/datasets/trade.dta\")\n\n# Structure of sugar\nstr(sugar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> tibble [10 × 5] (S3: tbl_df/tbl/data.frame)\n#>  $ Date    : dbl+lbl [1:10] 10,  9,  8,  7,  6,  5,  4,  3,  2,  1\n#>    ..@ label       : chr \"Date\"\n#>    ..@ format.stata: chr \"%9.0g\"\n#>    ..@ labels      : Named num [1:10] 1 2 3 4 5 6 7 8 9 10\n#>    .. ..- attr(*, \"names\")= chr [1:10] \"2004-12-31\" \"2005-12-31\" \"2006-12-31\" \"2007-12-31\" ...\n#>  $ Import  : num [1:10] 37664782 16316512 11082246 35677943 9879878 ...\n#>   ..- attr(*, \"label\")= chr \"Import\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Weight_I: num [1:10] 54029106 21584365 14526089 55034932 14806865 ...\n#>   ..- attr(*, \"label\")= chr \"Weight_I\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Export  : num [1:10] 5.45e+07 1.03e+08 3.79e+07 4.85e+07 7.15e+07 ...\n#>   ..- attr(*, \"label\")= chr \"Export\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Weight_E: num [1:10] 9.34e+07 1.58e+08 8.80e+07 1.12e+08 1.32e+08 ...\n#>   ..- attr(*, \"label\")= chr \"Weight_E\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  - attr(*, \"label\")= chr \"Written by R.\"\n```\n:::\n\n```{.r .cell-code}\n# Convert values in Date column to dates\nsugar$Date <- as.Date(as_factor(sugar$Date))\n\n# Structure of sugar again\nstr(sugar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> tibble [10 × 5] (S3: tbl_df/tbl/data.frame)\n#>  $ Date    : Date[1:10], format: \"2013-12-31\" \"2012-12-31\" ...\n#>  $ Import  : num [1:10] 37664782 16316512 11082246 35677943 9879878 ...\n#>   ..- attr(*, \"label\")= chr \"Import\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Weight_I: num [1:10] 54029106 21584365 14526089 55034932 14806865 ...\n#>   ..- attr(*, \"label\")= chr \"Weight_I\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Export  : num [1:10] 5.45e+07 1.03e+08 3.79e+07 4.85e+07 7.15e+07 ...\n#>   ..- attr(*, \"label\")= chr \"Export\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  $ Weight_E: num [1:10] 9.34e+07 1.58e+08 8.80e+07 1.12e+08 1.32e+08 ...\n#>   ..- attr(*, \"label\")= chr \"Weight_E\"\n#>   ..- attr(*, \"format.stata\")= chr \"%9.0g\"\n#>  - attr(*, \"label\")= chr \"Written by R.\"\n```\n:::\n:::\n\n\n## What does the graphic tell?\n\nA plot can be very useful to explore the relationship between two variables. If you pass the <a href=\"http://www.rdocumentation.org/packages/graphics/functions/plot\" target=\"_blank\" rel=\"noopener noreferrer\">`plot()`</a> function two arguments, the first one will be plotted on the x-axis, the second one will be plotted on the y-axis.\n\nThe sugar trading data is again available at <a href=\"http://assets.datacamp.com/production/course_1478/datasets/trade.dta\" target=\"_blank\" rel=\"noopener noreferrer\">http://assets.datacamp.com/production/course_1478/datasets/trade.dta</a>.\n\n> *Question*\n> ---\n> After you've imported the data frame, you should plot two of its variables, `Import` against `Weight_I`, and describe their relationship!<br>\n> <br>\n> ⬜ The relation between the import figures in USD and the import figures in weight can be described with a quadratic function that has a local maximum.<br>\n> ✅ The import figures in USD and the import figures in weight are rather positively correlated.<br>\n> ⬜ The import figures in USD and the import figures in weight are negatively associated. Along the points there is a monotonic decreasing trend.<br>\n> ⬜ No relationship can be guessed between the weight and the value of the imported sugar.<br>\n\n## Import SPSS data with haven\n\nThe `haven` package can also import data files from SPSS. Again, importing the data is pretty straightforward. Depending on the SPSS data file you're working with, you'll need either <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_sav()`</a> - for `.sav` files - or <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_por()`</a> - for `.por` files.\n\nIn this exercise, you will work with data on four of the Big Five personality traits for 434 persons (Source: <a href=\"http://staff.bath.ac.uk/pssiw/stats2/page16/page16.html\" target=\"_blank\" rel=\"noopener noreferrer\">University of Bath</a>). The Big Five is a psychological concept including, originally, five dimensions of personality to classify human personality. The SPSS dataset is called <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/person.sav\" target=\"_blank\" rel=\"noopener noreferrer\">`person.sav`</a> and is available in your working directory.\n\n\n**Steps**\n\n1. Use <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_sav()`</a> to import the SPSS data in `\"person.sav\"`. Name the imported data frame `traits`.\n2. `traits` contains several missing values, or `NA`s. Run <a href=\"http://www.rdocumentation.org/packages/base/functions/summary\" target=\"_blank\" rel=\"noopener noreferrer\">`summary()`</a> on it to find out how many `NA`s are contained in each variable.\n3. Print out a subset of those individuals that scored high on Extroversion *and* on Agreeableness, i.e. scoring higher than 40 on each of these two categories. You can use `subset()` for this.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import person.sav: traits\ntraits <- read_sav(\"data/person.sav\")\n\n# Summarize traits\nsummary(traits)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>     Neurotic      Extroversion   Agreeableness   Conscientiousness\n#>  Min.   : 0.00   Min.   : 5.00   Min.   :15.00   Min.   : 7.00    \n#>  1st Qu.:18.00   1st Qu.:26.00   1st Qu.:39.00   1st Qu.:25.00    \n#>  Median :24.00   Median :31.00   Median :45.00   Median :30.00    \n#>  Mean   :23.63   Mean   :30.23   Mean   :44.55   Mean   :30.85    \n#>  3rd Qu.:29.00   3rd Qu.:34.00   3rd Qu.:50.00   3rd Qu.:36.00    \n#>  Max.   :44.00   Max.   :65.00   Max.   :73.00   Max.   :58.00    \n#>  NA's   :14      NA's   :16      NA's   :19      NA's   :14\n```\n:::\n\n```{.r .cell-code}\n# Print out a subset\nsubset(traits, Extroversion > 40 & Agreeableness > 40)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Neurotic\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Extroversion\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Agreeableness\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Conscientiousness\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"38\",\"2\":\"43\",\"3\":\"49\",\"4\":\"29\"},{\"1\":\"20\",\"2\":\"42\",\"3\":\"46\",\"4\":\"31\"},{\"1\":\"18\",\"2\":\"42\",\"3\":\"49\",\"4\":\"31\"},{\"1\":\"42\",\"2\":\"43\",\"3\":\"44\",\"4\":\"29\"},{\"1\":\"30\",\"2\":\"42\",\"3\":\"51\",\"4\":\"24\"},{\"1\":\"18\",\"2\":\"42\",\"3\":\"50\",\"4\":\"25\"},{\"1\":\"27\",\"2\":\"45\",\"3\":\"55\",\"4\":\"23\"},{\"1\":\"18\",\"2\":\"43\",\"3\":\"57\",\"4\":\"34\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nGreat! You imported a data file from SPSS correctly using `read_sav()`. Deepen your knowledge in the following exercise!\n\n## Factorize, round two\n\nIn the last exercise you learned how to import a data file using the command <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`read_sav()`</a>. With SPSS data files, it can also happen that some of the variables you import have the `labelled` class. This is done to keep all the labelling information that was originally present in the `.sav` and `.por` files. It's advised to coerce (or change) these variables to factors or other standard R classes.\n\nThe data for this exercise involves information on employees and their demographic and economic attributes (Source: <a href=\"http://cehd.gmu.edu/book/dimitrov/spss\" target=\"_blank\" rel=\"noopener noreferrer\">QRiE</a>). The data can be found on the following URL:\n\n<a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/employee.sav\" target=\"_blank\" rel=\"noopener noreferrer\">http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/employee.sav</a>\n\n\n**Steps**\n\n1. Import the SPSS data straight from the URL and store the resulting data frame as `work`.\n2. Display the summary of the `GENDER` column of `work`. This information doesn't give you a lot of useful information, right?\n3. Convert the `GENDER` column in `work` to a factor, the class to denote categorical variables in R. Use <a href=\"http://cran.r-project.org/web/packages/haven/haven.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">`as_factor()`</a>.\n4. Once again display the summary of the `GENDER` column. This time, the printout makes much more sense.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import SPSS data from the URL: work\nwork <- read_sav(\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/employee.sav\")\n\n# Display summary of work$GENDER\nsummary(work$GENDER)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    Length     Class      Mode \n#>       474 character character\n```\n:::\n\n```{.r .cell-code}\n# Convert work$GENDER to a factor\nwork$GENDER <- as_factor(work$GENDER)\n\n# Display summary of work$GENDER again\nsummary(work$GENDER)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Female   Male \n#>    216    258\n```\n:::\n:::\n\n\nWell done! The [`as_factor()`](http://cran.r-project.org/web/packages/haven/haven.pdf) function has more arguments you can specify, have a look at its documentation to discover more! Proceed to the next video.\n\n## foreign\n\nTheory. Coming soon ...\n\n**1. foreign**\n\nYou already know how to import your data using Wickham's haven package, great!\n\n**2. foreign**\n\nHowever, I also told you that there is another alternative, the foreign package, written by the R core team. Although it's somewhat less consistent in naming and use, it's a very comprehensive tool that can work with all kinds of foreign data formats. Apart from importing SAS, STATA and SPSS files, it can also handle even more exotic formats, from Systat and Weka for example. It's also able to export data again to various formats. I'll only discuss importing SAS, STATA and SPSS data though. Before I get to it, let me install and load the foreign package.\n\n**3. SAS**\n\nLet's start with SAS first. Well, here the first drawback of foreign in comparison to haven emerges. Foreign cannot import single SAS data files, such as dot sas7bdat files. With foreign only so-called SAS libraries can be read. These libraries usually are of the format dot-xport. If you are really looking for an alternative to haven here, you can check out a package called sas7bdat.\n\n**4. STATA**\n\nWhen it comes to STATA, foreign can be used to read dot dta files of Stata versions 5 to 12 today. You can do this with the read dot dta function. As you saw before, the R core team packages such as utils and this foreign package, use dots in their function names, while Wickham's packages use underscores. Have a look at this simplified usage of the read dot dta function.As you probably expected you first have to define a file path. This could be a local file or a URL.\n\n**5. read.dta()**\n\nBasically, this is already sufficient to import a data set, as this call to import the US airlines punctuality data set shows.\n\n**6. read.dta()**\n\nHave a look at the structure of this data frame. The Airline variable is already a factor. This is because the convert dot factors argument of the read dot dta function is TRUE by default. This then automatically creates factors from labelled STATA values. This is something you had to do in the haven package manually with as_factor, remember?\n\n**7. read.dta() - convert.factors**\n\nLet's see what happens if we set convert dot factors to FALSE.The Airline column is now integer. Is this information on Airlines lost then? Not at all. Notice all the information that is stored in the data frame's attributes. From the version attribute, for example, you can tell that we're dealing with a STATA 7 file. The label dot table attribute, contains a mapping between the integer airline codes and their actual names. To work with the dataset easily, you'll want to stick to the default argument of convert dot factors though, which is TRUE.\n\n**8. read.dta() - more arguments**\n\nSimilar to convert dot factors, there's also convert dot dates to specify whether you want STATA time and date information to be converted to R Date and POSIXct objects. As this is something you'll typically want to do, the defaults here TRUE.Finally, I also wanted to mention the missing dot type argument. If you're familiar with STATA 8 and later, you'll know that there is support for different types of missing values, 27 of them to be precise. In R, there's only one type of missing values, NA. If you set the missing type argument to FALSE, all these different missing values are converted to NA. If it's set to TRUE, a list with information on how different values for different variables are missing are included in the attributes of the returned data frame.\n\n**9. SPSS**\n\nImporting SPSS files with foreign works quite the same. This time though, you'll need the read dot spss function. Not very surprising is it?Have another look at a trimmed down version of its usage.As usual, the file path comes first. For the rest, all argument names are different when you compare to the read dta function from before. This is what I meant with not really consistent before'use dot value dot labels', which is TRUE by default, specifies whether variables that are labelled vectors in SPSS should be converted to R factors. This argument thus is similar to the the convert dot factor argument from read data.The 'to dot data dot frame' argument tells R whether or not to return the SPSS data as a data frame. Strangely, it's FALSE by default, which has foreign build a list containing all different columns. But you already know that a data frame is simply a special kind of list, so the difference is not that big.Next to these two arguments, there are many more, such as trim factor names, trim values and use missings. Their purpose is often similar to what you've seen for the read dot dta function, but not always. Foreign aims at a specific treatment of different types of data files. This does not benefit the consistency, but provides full control over how actually data files are imported.To learn more about importing data with foreign, you can always consult the documentation. But save that for later,\n\n## Import STATA data with foreign (1)\n\nThe `foreign` package offers a simple function to import and read *STATA* data: <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`read.dta()`</a>.\n\nIn this exercise, you will import data on the US presidential elections in the year 2000. The data in `florida.dta` contains the total numbers of votes for each of the four candidates as well as the total number of votes per election area in the state of Florida (Source: <a href=\"http://results.elections.myflorida.com/\" target=\"_blank\" rel=\"noopener noreferrer\">Florida Department of State</a>). The file is available in your working directory, you can download it <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/florida.dta\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> if you want to experiment some more.\n\n**Steps**\n\n1. Load the `foreign` package; it's already installed on DataCamp's servers.\n2. Import the data on the elections in Florida, `\"florida.dta\"`, and name the resulting data frame `florida`. Use <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`read.dta()`</a> without specifying extra arguments.\n3. Check out the last 6 observations of `florida` with `tail()`\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load the foreign package\nlibrary(\"foreign\")\n\n# Import florida.dta and name the resulting data frame florida\nflorida <- read.dta(\"data/florida.dta\")\n\n# Check tail() of florida\ntail(florida)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"gore\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"bush\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"buchanan\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"nader\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"total\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2647\",\"2\":\"4051\",\"3\":\"27\",\"4\":\"59\",\"5\":\"6784\",\"_rn_\":\"62\"},{\"1\":\"1399\",\"2\":\"2326\",\"3\":\"26\",\"4\":\"29\",\"5\":\"3780\",\"_rn_\":\"63\"},{\"1\":\"97063\",\"2\":\"82214\",\"3\":\"396\",\"4\":\"2436\",\"5\":\"182109\",\"_rn_\":\"64\"},{\"1\":\"3835\",\"2\":\"4511\",\"3\":\"46\",\"4\":\"149\",\"5\":\"8541\",\"_rn_\":\"65\"},{\"1\":\"5637\",\"2\":\"12176\",\"3\":\"120\",\"4\":\"265\",\"5\":\"18198\",\"_rn_\":\"66\"},{\"1\":\"2796\",\"2\":\"4983\",\"3\":\"88\",\"4\":\"93\",\"5\":\"7960\",\"_rn_\":\"67\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nCongratulations! Your first exercise on using `foreign` to import STATA data is complete. Proceed to the next exercise to learn the proper handling of the arguments that [`read.dta()`](http://www.rdocumentation.org/packages/foreign/functions/read.dta) includes!\n\n## Import STATA data with foreign (2)\n\nData can be very diverse, going from character vectors to categorical variables, dates and more. It's in these cases that the additional arguments of <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`read.dta()`</a> will come in handy.\n\nThe arguments you will use most often are `convert.dates`, `convert.factors`, `missing.type` and `convert.underscore`. Their meaning is pretty straightforward, as Filip explained in the video. It's all about correctly converting STATA data to standard R data structures. Type `?read.dta` to find out about about the default values.\n\nThe dataset for this exercise contains socio-economic measures and access to education for different individuals (Source: <a href=\"http://datatopics.worldbank.org/Gender/topic/education\" target=\"_blank\" rel=\"noopener noreferrer\">World Bank</a>). This data is available as <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/edequality.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`edequality.dta`</a>, which is located in the `worldbank` folder in your working directory.\n\n\n**Steps**\n\n1. Specify the path to the file using <a href=\"http://www.rdocumentation.org/packages/base/functions/file.path\" target=\"_blank\" rel=\"noopener noreferrer\">`file.path()`</a>. Call it `path`. Remember the `\"edequality.dta\"` file is located in the `\"worldbank\"` folder.\n2. Use the `path` variable to import the data file in three different ways; each time show its structure with <a href=\"http://www.rdocumentation.org/packages/utils/functions/str\" target=\"_blank\" rel=\"noopener noreferrer\">`str()`</a>:\n\n    * `edu_equal_1`: By passing only the file `path` to <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`read.dta()`</a>.\n    * `edu_equal_2`: By passing the file `path`, and setting `convert.factors` to `FALSE`.\n    * `edu_equal_3`: By passing the file `path`, and setting `convert.underscore` to `TRUE`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Specify the file path using file.path(): path\npath <- file.path(\"data\", \"edequality.dta\")\n\n# Create and print structure of edu_equal_1\nedu_equal_1 <- read.dta(path)\nstr(edu_equal_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t12214 obs. of  27 variables:\n#>  $ hhid              : num  1 1 1 2 2 3 4 4 5 6 ...\n#>  $ hhweight          : num  627 627 627 627 627 ...\n#>  $ location          : Factor w/ 2 levels \"urban location\",..: 1 1 1 1 1 2 2 2 1 1 ...\n#>  $ region            : Factor w/ 9 levels \"Sofia city\",\"Bourgass\",..: 8 8 8 9 9 4 4 4 8 8 ...\n#>  $ ethnicity_head    : Factor w/ 4 levels \"Bulgaria\",\"Turks\",..: 2 2 2 1 1 1 1 1 1 1 ...\n#>  $ age               : num  37 11 8 73 70 75 79 80 82 83 ...\n#>  $ gender            : Factor w/ 2 levels \"male\",\"female\": 2 2 1 1 2 1 1 2 2 2 ...\n#>  $ relation          : Factor w/ 9 levels \"head                      \",..: 1 3 3 1 2 1 1 2 1 1 ...\n#>  $ literate          : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 2 2 2 2 2 2 2 ...\n#>  $ income_mnt        : num  13.3 13.3 13.3 142.5 142.5 ...\n#>  $ income            : num  160 160 160 1710 1710 ...\n#>  $ aggregate         : num  1042 1042 1042 3271 3271 ...\n#>  $ aggr_ind_annual   : num  347 347 347 1635 1635 ...\n#>  $ educ_completed    : int  2 4 4 4 3 3 3 3 4 4 ...\n#>  $ grade_complete    : num  4 3 0 3 4 4 4 4 5 5 ...\n#>  $ grade_all         : num  4 11 8 11 8 8 8 8 13 13 ...\n#>  $ unemployed        : int  2 1 1 1 1 1 1 1 1 1 ...\n#>  $ reason_OLF        : int  NA NA NA 3 3 3 9 9 3 3 ...\n#>  $ sector            : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ occupation        : int  NA NA NA NA NA NA 5 5 NA NA ...\n#>  $ earn_mont         : num  0 0 0 0 0 0 20 20 0 0 ...\n#>  $ earn_ann          : num  0 0 0 0 0 0 240 240 0 0 ...\n#>  $ hours_week        : num  NA NA NA NA NA NA 30 35 NA NA ...\n#>  $ hours_mnt         : num  NA NA NA NA NA ...\n#>  $ fulltime          : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ hhexp             : num  100 100 100 343 343 ...\n#>  $ legacy_pension_amt: num  NA NA NA NA NA NA NA NA NA NA ...\n#>  - attr(*, \"datalabel\")= chr \"\"\n#>  - attr(*, \"time.stamp\")= chr \"\"\n#>  - attr(*, \"formats\")= chr [1:27] \"%9.0g\" \"%9.0g\" \"%9.0g\" \"%9.0g\" ...\n#>  - attr(*, \"types\")= int [1:27] 100 100 108 108 108 100 108 108 108 100 ...\n#>  - attr(*, \"val.labels\")= chr [1:27] \"\" \"\" \"location\" \"region\" ...\n#>  - attr(*, \"var.labels\")= chr [1:27] \"hhid\" \"hhweight\" \"location\" \"region\" ...\n#>  - attr(*, \"expansion.fields\")=List of 12\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_su1\" \"cluster\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_strata1\" \"strata\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_stages\" \"1\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_version\" \"2\"\n#>   ..$ : chr [1:3] \"_dta\" \"__XijVarLabcons\" \"(sum) cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_Xij\" \"cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_str\" \"0\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_j\" \"group\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_ver\" \"v.2\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_i\" \"hhid dur\"\n#>   ..$ : chr [1:3] \"_dta\" \"note1\" \"variables g1pc, g2pc, g3pc, g4pc, g5pc, g7pc, g8pc, g9pc, g10pc, g11pc, g12pc,  gall, health, rent, durables we\"| __truncated__\n#>   ..$ : chr [1:3] \"_dta\" \"note0\" \"1\"\n#>  - attr(*, \"version\")= int 7\n#>  - attr(*, \"label.table\")=List of 12\n#>   ..$ location: Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"urban location\" \"rural location\"\n#>   ..$ region  : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"Sofia city\" \"Bourgass\" \"Varna\" \"Lovetch\" ...\n#>   ..$ ethnic  : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"Bulgaria\" \"Turks\" \"Roma\" \"Other\"\n#>   ..$ s2_q2   : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"male\" \"female\"\n#>   ..$ s2_q3   : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"head                      \" \"spouse/partner            \" \"child                     \" \"son/daughter-in-law       \" ...\n#>   ..$ lit     : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n#>   ..$         : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"never attanded\" \"primary\" \"secondary\" \"postsecondary\"\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"Not unemployed\" \"Unemployed\"\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"student\" \"housewife/childcare\" \"in retirement\" \"illness, disability\" ...\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"agriculture\" \"mining\" \"manufacturing\" \"utilities\" ...\n#>   ..$         : Named int [1:5] 1 2 3 4 5\n#>   .. ..- attr(*, \"names\")= chr [1:5] \"private company\" \"public works program\" \"government,public sector, army\" \"private individual\" ...\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n```\n:::\n\n```{.r .cell-code}\n# Create and print structure of edu_equal_2\nedu_equal_2 <- read.dta(path, convert.factors = F)\nstr(edu_equal_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t12214 obs. of  27 variables:\n#>  $ hhid              : num  1 1 1 2 2 3 4 4 5 6 ...\n#>  $ hhweight          : num  627 627 627 627 627 ...\n#>  $ location          : int  1 1 1 1 1 2 2 2 1 1 ...\n#>  $ region            : int  8 8 8 9 9 4 4 4 8 8 ...\n#>  $ ethnicity_head    : int  2 2 2 1 1 1 1 1 1 1 ...\n#>  $ age               : num  37 11 8 73 70 75 79 80 82 83 ...\n#>  $ gender            : int  2 2 1 1 2 1 1 2 2 2 ...\n#>  $ relation          : int  1 3 3 1 2 1 1 2 1 1 ...\n#>  $ literate          : int  1 2 2 2 2 2 2 2 2 2 ...\n#>  $ income_mnt        : num  13.3 13.3 13.3 142.5 142.5 ...\n#>  $ income            : num  160 160 160 1710 1710 ...\n#>  $ aggregate         : num  1042 1042 1042 3271 3271 ...\n#>  $ aggr_ind_annual   : num  347 347 347 1635 1635 ...\n#>  $ educ_completed    : int  2 4 4 4 3 3 3 3 4 4 ...\n#>  $ grade_complete    : num  4 3 0 3 4 4 4 4 5 5 ...\n#>  $ grade_all         : num  4 11 8 11 8 8 8 8 13 13 ...\n#>  $ unemployed        : int  2 1 1 1 1 1 1 1 1 1 ...\n#>  $ reason_OLF        : int  NA NA NA 3 3 3 9 9 3 3 ...\n#>  $ sector            : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ occupation        : int  NA NA NA NA NA NA 5 5 NA NA ...\n#>  $ earn_mont         : num  0 0 0 0 0 0 20 20 0 0 ...\n#>  $ earn_ann          : num  0 0 0 0 0 0 240 240 0 0 ...\n#>  $ hours_week        : num  NA NA NA NA NA NA 30 35 NA NA ...\n#>  $ hours_mnt         : num  NA NA NA NA NA ...\n#>  $ fulltime          : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ hhexp             : num  100 100 100 343 343 ...\n#>  $ legacy_pension_amt: num  NA NA NA NA NA NA NA NA NA NA ...\n#>  - attr(*, \"datalabel\")= chr \"\"\n#>  - attr(*, \"time.stamp\")= chr \"\"\n#>  - attr(*, \"formats\")= chr [1:27] \"%9.0g\" \"%9.0g\" \"%9.0g\" \"%9.0g\" ...\n#>  - attr(*, \"types\")= int [1:27] 100 100 108 108 108 100 108 108 108 100 ...\n#>  - attr(*, \"val.labels\")= chr [1:27] \"\" \"\" \"location\" \"region\" ...\n#>  - attr(*, \"var.labels\")= chr [1:27] \"hhid\" \"hhweight\" \"location\" \"region\" ...\n#>  - attr(*, \"expansion.fields\")=List of 12\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_su1\" \"cluster\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_strata1\" \"strata\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_stages\" \"1\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_version\" \"2\"\n#>   ..$ : chr [1:3] \"_dta\" \"__XijVarLabcons\" \"(sum) cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_Xij\" \"cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_str\" \"0\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_j\" \"group\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_ver\" \"v.2\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_i\" \"hhid dur\"\n#>   ..$ : chr [1:3] \"_dta\" \"note1\" \"variables g1pc, g2pc, g3pc, g4pc, g5pc, g7pc, g8pc, g9pc, g10pc, g11pc, g12pc,  gall, health, rent, durables we\"| __truncated__\n#>   ..$ : chr [1:3] \"_dta\" \"note0\" \"1\"\n#>  - attr(*, \"version\")= int 7\n#>  - attr(*, \"label.table\")=List of 12\n#>   ..$ location: Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"urban location\" \"rural location\"\n#>   ..$ region  : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"Sofia city\" \"Bourgass\" \"Varna\" \"Lovetch\" ...\n#>   ..$ ethnic  : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"Bulgaria\" \"Turks\" \"Roma\" \"Other\"\n#>   ..$ s2_q2   : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"male\" \"female\"\n#>   ..$ s2_q3   : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"head                      \" \"spouse/partner            \" \"child                     \" \"son/daughter-in-law       \" ...\n#>   ..$ lit     : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n#>   ..$         : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"never attanded\" \"primary\" \"secondary\" \"postsecondary\"\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"Not unemployed\" \"Unemployed\"\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"student\" \"housewife/childcare\" \"in retirement\" \"illness, disability\" ...\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"agriculture\" \"mining\" \"manufacturing\" \"utilities\" ...\n#>   ..$         : Named int [1:5] 1 2 3 4 5\n#>   .. ..- attr(*, \"names\")= chr [1:5] \"private company\" \"public works program\" \"government,public sector, army\" \"private individual\" ...\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n```\n:::\n\n```{.r .cell-code}\n# Create and print structure of edu_equal_3\nedu_equal_3 <- read.dta(path, convert.underscore = T)\nstr(edu_equal_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t12214 obs. of  27 variables:\n#>  $ hhid              : num  1 1 1 2 2 3 4 4 5 6 ...\n#>  $ hhweight          : num  627 627 627 627 627 ...\n#>  $ location          : Factor w/ 2 levels \"urban location\",..: 1 1 1 1 1 2 2 2 1 1 ...\n#>  $ region            : Factor w/ 9 levels \"Sofia city\",\"Bourgass\",..: 8 8 8 9 9 4 4 4 8 8 ...\n#>  $ ethnicity.head    : Factor w/ 4 levels \"Bulgaria\",\"Turks\",..: 2 2 2 1 1 1 1 1 1 1 ...\n#>  $ age               : num  37 11 8 73 70 75 79 80 82 83 ...\n#>  $ gender            : Factor w/ 2 levels \"male\",\"female\": 2 2 1 1 2 1 1 2 2 2 ...\n#>  $ relation          : Factor w/ 9 levels \"head                      \",..: 1 3 3 1 2 1 1 2 1 1 ...\n#>  $ literate          : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 2 2 2 2 2 2 2 ...\n#>  $ income.mnt        : num  13.3 13.3 13.3 142.5 142.5 ...\n#>  $ income            : num  160 160 160 1710 1710 ...\n#>  $ aggregate         : num  1042 1042 1042 3271 3271 ...\n#>  $ aggr.ind.annual   : num  347 347 347 1635 1635 ...\n#>  $ educ.completed    : int  2 4 4 4 3 3 3 3 4 4 ...\n#>  $ grade.complete    : num  4 3 0 3 4 4 4 4 5 5 ...\n#>  $ grade.all         : num  4 11 8 11 8 8 8 8 13 13 ...\n#>  $ unemployed        : int  2 1 1 1 1 1 1 1 1 1 ...\n#>  $ reason.OLF        : int  NA NA NA 3 3 3 9 9 3 3 ...\n#>  $ sector            : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ occupation        : int  NA NA NA NA NA NA 5 5 NA NA ...\n#>  $ earn.mont         : num  0 0 0 0 0 0 20 20 0 0 ...\n#>  $ earn.ann          : num  0 0 0 0 0 0 240 240 0 0 ...\n#>  $ hours.week        : num  NA NA NA NA NA NA 30 35 NA NA ...\n#>  $ hours.mnt         : num  NA NA NA NA NA ...\n#>  $ fulltime          : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ hhexp             : num  100 100 100 343 343 ...\n#>  $ legacy.pension.amt: num  NA NA NA NA NA NA NA NA NA NA ...\n#>  - attr(*, \"datalabel\")= chr \"\"\n#>  - attr(*, \"time.stamp\")= chr \"\"\n#>  - attr(*, \"formats\")= chr [1:27] \"%9.0g\" \"%9.0g\" \"%9.0g\" \"%9.0g\" ...\n#>  - attr(*, \"types\")= int [1:27] 100 100 108 108 108 100 108 108 108 100 ...\n#>  - attr(*, \"val.labels\")= chr [1:27] \"\" \"\" \"location\" \"region\" ...\n#>  - attr(*, \"var.labels\")= chr [1:27] \"hhid\" \"hhweight\" \"location\" \"region\" ...\n#>  - attr(*, \"expansion.fields\")=List of 12\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_su1\" \"cluster\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_strata1\" \"strata\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_stages\" \"1\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_version\" \"2\"\n#>   ..$ : chr [1:3] \"_dta\" \"__XijVarLabcons\" \"(sum) cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_Xij\" \"cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_str\" \"0\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_j\" \"group\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_ver\" \"v.2\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_i\" \"hhid dur\"\n#>   ..$ : chr [1:3] \"_dta\" \"note1\" \"variables g1pc, g2pc, g3pc, g4pc, g5pc, g7pc, g8pc, g9pc, g10pc, g11pc, g12pc,  gall, health, rent, durables we\"| __truncated__\n#>   ..$ : chr [1:3] \"_dta\" \"note0\" \"1\"\n#>  - attr(*, \"version\")= int 7\n#>  - attr(*, \"label.table\")=List of 12\n#>   ..$ location: Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"urban location\" \"rural location\"\n#>   ..$ region  : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"Sofia city\" \"Bourgass\" \"Varna\" \"Lovetch\" ...\n#>   ..$ ethnic  : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"Bulgaria\" \"Turks\" \"Roma\" \"Other\"\n#>   ..$ s2_q2   : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"male\" \"female\"\n#>   ..$ s2_q3   : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"head                      \" \"spouse/partner            \" \"child                     \" \"son/daughter-in-law       \" ...\n#>   ..$ lit     : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n#>   ..$         : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"never attanded\" \"primary\" \"secondary\" \"postsecondary\"\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"Not unemployed\" \"Unemployed\"\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"student\" \"housewife/childcare\" \"in retirement\" \"illness, disability\" ...\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"agriculture\" \"mining\" \"manufacturing\" \"utilities\" ...\n#>   ..$         : Named int [1:5] 1 2 3 4 5\n#>   .. ..- attr(*, \"names\")= chr [1:5] \"private company\" \"public works program\" \"government,public sector, army\" \"private individual\" ...\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n```\n:::\n:::\n\n\nGreat! Can you tell the difference between the different versions of [`read.dta()`](http://www.rdocumentation.org/packages/foreign/functions/read.dta)? For this data, the first version (where you simply specified the file path) will be most useful to work with. Head over to the next exercise to see if you actually understand your data!\n\n## Do you know your data?\n\nThe previous exercise dealt about socio-economic indicators and access to education of different individuals. The `edu_equal_1` dataset that you've built is already available in the workspace. Now that you have it in R, it's pretty easy to get some basic insights.\n\nFor example, you can ask yourself *how many observations (e.g. how many people) have an `age` higher than 40 and are `literate`?* When you call\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nstr(edu_equal_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> 'data.frame':\t12214 obs. of  27 variables:\n#>  $ hhid              : num  1 1 1 2 2 3 4 4 5 6 ...\n#>  $ hhweight          : num  627 627 627 627 627 ...\n#>  $ location          : Factor w/ 2 levels \"urban location\",..: 1 1 1 1 1 2 2 2 1 1 ...\n#>  $ region            : Factor w/ 9 levels \"Sofia city\",\"Bourgass\",..: 8 8 8 9 9 4 4 4 8 8 ...\n#>  $ ethnicity_head    : Factor w/ 4 levels \"Bulgaria\",\"Turks\",..: 2 2 2 1 1 1 1 1 1 1 ...\n#>  $ age               : num  37 11 8 73 70 75 79 80 82 83 ...\n#>  $ gender            : Factor w/ 2 levels \"male\",\"female\": 2 2 1 1 2 1 1 2 2 2 ...\n#>  $ relation          : Factor w/ 9 levels \"head                      \",..: 1 3 3 1 2 1 1 2 1 1 ...\n#>  $ literate          : Factor w/ 2 levels \"no\",\"yes\": 1 2 2 2 2 2 2 2 2 2 ...\n#>  $ income_mnt        : num  13.3 13.3 13.3 142.5 142.5 ...\n#>  $ income            : num  160 160 160 1710 1710 ...\n#>  $ aggregate         : num  1042 1042 1042 3271 3271 ...\n#>  $ aggr_ind_annual   : num  347 347 347 1635 1635 ...\n#>  $ educ_completed    : int  2 4 4 4 3 3 3 3 4 4 ...\n#>  $ grade_complete    : num  4 3 0 3 4 4 4 4 5 5 ...\n#>  $ grade_all         : num  4 11 8 11 8 8 8 8 13 13 ...\n#>  $ unemployed        : int  2 1 1 1 1 1 1 1 1 1 ...\n#>  $ reason_OLF        : int  NA NA NA 3 3 3 9 9 3 3 ...\n#>  $ sector            : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ occupation        : int  NA NA NA NA NA NA 5 5 NA NA ...\n#>  $ earn_mont         : num  0 0 0 0 0 0 20 20 0 0 ...\n#>  $ earn_ann          : num  0 0 0 0 0 0 240 240 0 0 ...\n#>  $ hours_week        : num  NA NA NA NA NA NA 30 35 NA NA ...\n#>  $ hours_mnt         : num  NA NA NA NA NA ...\n#>  $ fulltime          : int  NA NA NA NA NA NA 1 1 NA NA ...\n#>  $ hhexp             : num  100 100 100 343 343 ...\n#>  $ legacy_pension_amt: num  NA NA NA NA NA NA NA NA NA NA ...\n#>  - attr(*, \"datalabel\")= chr \"\"\n#>  - attr(*, \"time.stamp\")= chr \"\"\n#>  - attr(*, \"formats\")= chr [1:27] \"%9.0g\" \"%9.0g\" \"%9.0g\" \"%9.0g\" ...\n#>  - attr(*, \"types\")= int [1:27] 100 100 108 108 108 100 108 108 108 100 ...\n#>  - attr(*, \"val.labels\")= chr [1:27] \"\" \"\" \"location\" \"region\" ...\n#>  - attr(*, \"var.labels\")= chr [1:27] \"hhid\" \"hhweight\" \"location\" \"region\" ...\n#>  - attr(*, \"expansion.fields\")=List of 12\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_su1\" \"cluster\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_strata1\" \"strata\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_stages\" \"1\"\n#>   ..$ : chr [1:3] \"_dta\" \"_svy_version\" \"2\"\n#>   ..$ : chr [1:3] \"_dta\" \"__XijVarLabcons\" \"(sum) cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_Xij\" \"cons\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_str\" \"0\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_j\" \"group\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_ver\" \"v.2\"\n#>   ..$ : chr [1:3] \"_dta\" \"ReS_i\" \"hhid dur\"\n#>   ..$ : chr [1:3] \"_dta\" \"note1\" \"variables g1pc, g2pc, g3pc, g4pc, g5pc, g7pc, g8pc, g9pc, g10pc, g11pc, g12pc,  gall, health, rent, durables we\"| __truncated__\n#>   ..$ : chr [1:3] \"_dta\" \"note0\" \"1\"\n#>  - attr(*, \"version\")= int 7\n#>  - attr(*, \"label.table\")=List of 12\n#>   ..$ location: Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"urban location\" \"rural location\"\n#>   ..$ region  : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"Sofia city\" \"Bourgass\" \"Varna\" \"Lovetch\" ...\n#>   ..$ ethnic  : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"Bulgaria\" \"Turks\" \"Roma\" \"Other\"\n#>   ..$ s2_q2   : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"male\" \"female\"\n#>   ..$ s2_q3   : Named int [1:9] 1 2 3 4 5 6 7 8 9\n#>   .. ..- attr(*, \"names\")= chr [1:9] \"head                      \" \"spouse/partner            \" \"child                     \" \"son/daughter-in-law       \" ...\n#>   ..$ lit     : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n#>   ..$         : Named int [1:4] 1 2 3 4\n#>   .. ..- attr(*, \"names\")= chr [1:4] \"never attanded\" \"primary\" \"secondary\" \"postsecondary\"\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"Not unemployed\" \"Unemployed\"\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"student\" \"housewife/childcare\" \"in retirement\" \"illness, disability\" ...\n#>   ..$         : Named int [1:10] 1 2 3 4 5 6 7 8 9 10\n#>   .. ..- attr(*, \"names\")= chr [1:10] \"agriculture\" \"mining\" \"manufacturing\" \"utilities\" ...\n#>   ..$         : Named int [1:5] 1 2 3 4 5\n#>   .. ..- attr(*, \"names\")= chr [1:5] \"private company\" \"public works program\" \"government,public sector, army\" \"private individual\" ...\n#>   ..$         : Named int [1:2] 1 2\n#>   .. ..- attr(*, \"names\")= chr [1:2] \"no\" \"yes\"\n```\n:::\n:::\n\n\nYou'll see that `age` is an integer, and `literate` is a factor, with the levels \"yes\" and \"no\". The following expression thus answers the question:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnrow(subset(edu_equal_1, age > 40 & literate == \"yes\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> [1] 6506\n```\n:::\n:::\n\n\nUp to you to answer a similar question now:\n\n> *Question*\n> ---\n> How many observations/individuals of Bulgarian ethnicity have an income above 1000?<br>\n> <br>\n> ⬜ 9457<br>\n> ⬜ 1000<br>\n> ✅ 8997<br>\n> ⬜ 10840<br>\n\n## Import SPSS data with foreign (1)\n\nAll great things come in pairs. Where `foreign` provided <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.dta\" target=\"_blank\" rel=\"noopener noreferrer\">`read.dta()`</a> to read Stata data, there's also <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.spss\" target=\"_blank\" rel=\"noopener noreferrer\">`read.spss()`</a> to read SPSS data files. To get a data frame, make sure to set `to.data.frame = TRUE` inside <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.spss\" target=\"_blank\" rel=\"noopener noreferrer\">`read.spss()`</a>.\n\nIn this exercise, you'll be working with socio-economic variables from different countries (Source: <a href=\"http://cw.routledge.com/textbooks/9780415372985/resources/datasets.asp\" target=\"_blank\" rel=\"noopener noreferrer\">Quantative Data Analysis in Education</a>). The SPSS data is in a file called `international.sav`, which is in your working directory. You can also download it <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/international.sav\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> if you want to play around with it some more.\n\n\n**Steps**\n\n1. Import the data file `\"international.sav\"` and have R convert it to a data frame. Store this data frame as `demo`.\n2. Create a boxplot of the `gdp` variable of `demo`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Import international.sav as a data frame: demo\ndemo <- read.spss(\"data/international.sav\", to.data.frame = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> re-encoding from CP1252\n```\n:::\n\n```{.r .cell-code}\n# Create boxplot of gdp variable of demo\nboxplot(demo$gdp)\n```\n\n::: {.cell-output-display}\n![](02_importing_data_intermediate_files/figure-html/unnamed-chunk-39-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n## Excursion: Correlation\n\nIf you're familiar with statistics, you'll have heard about Pearson's Correlation. It is a measurement to evaluate the linear dependency between two variables, say \\\\(X\\\\) and \\\\(Y\\\\). It can range from -1 to 1; if it's close to 1 it means that there is a strong positive association between the variables. If \\\\(X\\\\) is high, also \\\\(Y\\\\) tends to be high. If it's close to -1, there is a strong negative association: If \\\\(X\\\\) is high, \\\\(Y\\\\) tends to be low. When the Pearson correlation between two variables is 0, these variables are possibly independent: there is no association between \\\\(X\\\\) and \\\\(Y\\\\).\n\nYou can calculate the correlation between two vectors with the <a href=\"http://www.rdocumentation.org/packages/stats/functions/cor\">`cor()`</a> function. Take this code for example, that computes the correlation between the columns `height` and `width` of a fictional data frame `size`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncor(size$height, size$width)\n```\n:::\n\n\nThe data you've worked with in the previous exercise, <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/international.sav\" target=\"_blank\" rel=\"noopener noreferrer\">international.sav</a>, is again available in your working directory. It's now up to import it and undertake the correct calculations to answer the following question:\n\n> *Question*\n> ---\n> What is the correlation coefficient for the two numerical variables `gdp` and `f_illit` (female illiteracy rate)?<br>\n> <br>\n> ⬜ The correlation is very close to 0. Therefore, no association is existing between female illiteracy and GDP for the data set that is used.<br>\n> ✅ The correlation is around -0.45. There is a negative correlation, but it is rather weak.<br>\n> ⬜ The correlation is almost equal to +1. GDP and female illiteracy are almost perfectly, positive correlated.<br>\n> ⬜ The correlation is around +0.45. There is a positive correlation, but it is rather weak.<br>\n\n\n## Import SPSS data with foreign (2)\n\nIn the previous exercise, you used the `to.data.frame` argument inside <a href=\"http://www.rdocumentation.org/packages/foreign/functions/read.spss\" target=\"_blank\" rel=\"noopener noreferrer\">`read.spss()`</a>. There are many other ways in which to customize the way your SPSS data is imported.\n\nIn this exercise you will experiment with another argument, `use.value.labels`. It specifies whether variables with value labels should be converted into R factors with levels that are named accordingly. The argument is `TRUE` by default which means that so called labelled variables inside SPSS are converted to factors inside R.\n\nYou'll again be working with the <a href=\"http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/international.sav\" target=\"_blank\" rel=\"noopener noreferrer\">international.sav</a> data, which is available in your current working directory.\n\n**Steps**\n\n1. Import the data file `\"international.sav\"` as a data frame, `demo_1`.\n2. Print the first few rows of `demo_1` using the <a href=\"http://www.rdocumentation.org/packages/utils/functions/head\" target=\"_blank\" rel=\"noopener noreferrer\">`head()`</a> function.\n3. Import the data file `\"international.sav\"` as a data frame, `demo_2`, but this time in a way such that variables with value labels are *not* converted to R factors.\n4. Again, print the first few rows of `demo_2`. Can you tell the difference between the two data frames?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# foreign is already loaded\n\n# Import international.sav as demo_1\ndemo_1 <- read.spss(\"data/international.sav\", to.data.frame = T)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> re-encoding from CP1252\n```\n:::\n\n```{.r .cell-code}\n# Print out the head of demo_1\nhead(demo_1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"country\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"contint\"],\"name\":[3],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"m_illit\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f_illit\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"lifeexpt\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"gdp\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"Argentina\",\"3\":\"Americas\",\"4\":\"3.0\",\"5\":\"3.0\",\"6\":\"16\",\"7\":\"3375\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"Benin\",\"3\":\"Africa\",\"4\":\"45.2\",\"5\":\"74.5\",\"6\":\"7\",\"7\":\"521\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"Burundi\",\"3\":\"Africa\",\"4\":\"33.2\",\"5\":\"48.1\",\"6\":\"5\",\"7\":\"86\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"Chile\",\"3\":\"Americas\",\"4\":\"4.2\",\"5\":\"4.4\",\"6\":\"14\",\"7\":\"4523\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"Dominican Republic\",\"3\":\"Americas\",\"4\":\"12.0\",\"5\":\"12.7\",\"6\":\"12\",\"7\":\"2408\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"El Salvador\",\"3\":\"Americas\",\"4\":\"17.6\",\"5\":\"22.9\",\"6\":\"11\",\"7\":\"2302\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Import international.sav as demo_2\ndemo_2 <- read.spss(\"data/international.sav\", to.data.frame = T, use.value.labels = F)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> re-encoding from CP1252\n```\n:::\n\n```{.r .cell-code}\n# Print out the head of demo_2\nhead(demo_2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"country\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"contint\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"m_illit\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"f_illit\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"lifeexpt\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"gdp\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"Argentina\",\"3\":\"2\",\"4\":\"3.0\",\"5\":\"3.0\",\"6\":\"16\",\"7\":\"3375\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"Benin\",\"3\":\"1\",\"4\":\"45.2\",\"5\":\"74.5\",\"6\":\"7\",\"7\":\"521\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"Burundi\",\"3\":\"1\",\"4\":\"33.2\",\"5\":\"48.1\",\"6\":\"5\",\"7\":\"86\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"Chile\",\"3\":\"2\",\"4\":\"4.2\",\"5\":\"4.4\",\"6\":\"14\",\"7\":\"4523\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"Dominican Republic\",\"3\":\"2\",\"4\":\"12.0\",\"5\":\"12.7\",\"6\":\"12\",\"7\":\"2408\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"El Salvador\",\"3\":\"2\",\"4\":\"17.6\",\"5\":\"22.9\",\"6\":\"11\",\"7\":\"2302\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::",
    "supporting": [
      "02_importing_data_intermediate_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}