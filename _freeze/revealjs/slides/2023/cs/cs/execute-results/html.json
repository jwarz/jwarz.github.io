{
  "hash": "1ca09b4b36f4b1421c56d24756d8e67f",
  "result": {
    "engine": "knitr",
    "markdown": "---\n# TITLE & AUTHOR\ntitle: \"CoreSignal Analysis\"\nsubtitle: \"Current Status\"\nauthor: \"Joschka Schwarz\"\ninstitute: \"Hamburg University of Technology\"\ndate: today\ndate-format: \"dddd, D[<sup style='font-size:65%;font-style:italic;'>th</sup>] [of] MMMM YYYY\"\nsection-divs: true\nfilters:\n   - lightbox\nlightbox: auto\nengine: knitr\nknitr:\n  opts_chunk: \n    class-output: hscroll\n---\n\n\n\n\n## Table of Contents {data-state=\"hide-menubar\"}\n<ul class=\"menu\"><ul>\n\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n</style>\n:::\n\n\n# Preperation {data-stack-name=\"Prep\"}\nInput for CoreSignal\n\n# Data sources I {data-stack-name=\"Data I\"}\n1^st^ objective: Prepare `CrunchBase` / `PitchBook` and `CoreSignal` data\n\n## Load & Init Companies (CrunchBase, PitchBook & CoreSignal)\n\n::::::: {.panel-tabset}\n\n### CBPB: SELECT\n\nCrunchbase data contains **150,838** startups with a valid funding trajectory.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np_load(arrow, dplyr, tidyr)\n\nfunded_companies_prqt <- open_dataset(\"funded_companies_identifiers.parquet\") \nfunded_companies_prqt\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 150,838 × 3\n#>   company_id            domain linkedin_url                                     \n#>        <int> <list<character>> <chr>                                            \n#> 1          1               [1] <NA>                                             \n#> 2          2               [1] https://www.linkedin.com/company/luna-pharmaceut…\n#> 3          3               [1] http://www.linkedin.com/company/chainsync        \n#> # ℹ 150,835 more rows\n```\n\n\n:::\n:::\n\n\n::: {.fragment}\n\nMultiple domains (Unnesting via `Arrow` not possible. Options: `Spark` & `sparklyr.nested`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_unnested_tbl <- funded_companies_prqt |> collect() |> \n                      # 1. Allow multiple domains per company. No multiple linkedin handles.\n                      unnest(domain) \nfc_unnested_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 155,413 × 3\n#>   company_id domain              linkedin_url                                   \n#>        <int> <chr>               <chr>                                          \n#> 1          1 zana.io             <NA>                                           \n#> 2          2 premamawellness.com https://www.linkedin.com/company/luna-pharmace…\n#> 3          3 chainsync.com       http://www.linkedin.com/company/chainsync      \n#> # ℹ 155,410 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\n\n### CBPB: WRANGLE\n\n1. Must have identifier (domain, linkedin)\n2. Clean identifiers\n3. Remove duplicates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(stringr)\nfc_unnested_tbl |> \n  \n  # 1. At least 1 identifier: 4.518 observations are filtered out\n  filter(if_any(c(domain, linkedin_url), ~!is.na(.))) |>\n  \n  # 2. Extract linkedin handle & clean domains\n  mutate(linkedin_handle = linkedin_url |> str_extract(\"(?<=linkedin\\\\.com/company/).*?(?=(?:\\\\?|$|/))\")) |>\n  mutate(domain          = domain |> clean_domain()) |>\n\n  # 3. Remove 532 duplicates\n  distinct()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 150,363 × 3\n#>   company_id domain              linkedin_handle          \n#>        <int> <chr>               <chr>                    \n#> 1          1 zana.io             <NA>                     \n#> 2          2 premamawellness.com luna-pharmaceuticals-inc-\n#> 3          3 chainsync.com       chainsync                \n#> # ℹ 150,360 more rows\n```\n\n\n:::\n:::\n\n\n--> [145.991]{style=\"color:#cc0000; font-weight: bold;\"} distinct examineable companies.\n\n### CBPB: CLEAN\n\n`Issue:` Some extracted domains are not unique and associated with multiple companies.<br> `Manual Cleaning:` Domains with a count exceeding two were analyzed and set to NA if they do not correspond to the actual one.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ANALYZE\n# fc_wrangled_tbl |> \n#   distinct(company_id, domain) |> \n#   count(domain, sort = T) |> \n#   filter(n>2)`\n\nunwanted_domains_cb <- c(\"webflow.io\", \"angel.co\", \"weebly.com\", \"wordpress.com\", \"wixsite.com\", \"squarespace.com\", \n                         \"webflow.io\", \"crypt2esports.com\", \"myshopify.com\", \"business.site\", \"mystrikingly.com\", \n                         \"launchrock.com\", \"square.site\", \"google.com\", \"sites.google.com\", \"t.co\", \"linktr.ee\",\n                         \"netlify.app\", \"itunes.apple.com\", \"apple.com\", \"crunchb.com\", \"tumblr.com\", \"linkedin.com\",\n                         \"godaddysites.com\", \"mit.edu\", \"paloaltonetworks.com\", \" wpengine.com\", \"facebook.com\",\n                         \"intuit.com\", \"medium.com\", \"salesforce.com\", \"strikingly.com\", \"wix.com\", \"cisco.com\",\n                         \"digi.me\", \"apps.apple.com\", \"bit.ly\", \"fleek.co\", \"harvard.edu\", \"ibm.com\", \"jimdo.com\",\n                         \"myftpupload.com\", \"odoo.com\", \"storenvy.com\", \"twitter.com\", \"umd.edu\", \"umich.edu\", \"vmware.com\", \"webs.com\")\n\n# Not all observations with unwanted domains are bad per se:\nwanted_ids_cb <- c(angel = 128006, `catapult-centres-uk` = 115854, digime1 = 140904, digimi2 = 95430, fleek = 50738, \n                   jimdo = 108655, medium = 113415, storenvy = 85742, strikingly = 95831, substack = 34304, \n                   tumblr = 84838, twitter = 53139, weebly = 91365, wpengine = 91720)\n\n# Set misleading domains to NA\nfunded_companies_clnd <- fc_wrangled_tbl |> \n                              \n  mutate(domain = if_else(\n    domain %in% unwanted_domains_cb & !(company_id %in% wanted_ids_cb), \n    NA_character_, domain))\n```\n:::\n\n\n### CS: SELECT\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nIt appears that CoreSignal has been able to locate **45.026** companies within our gathered data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Selection & Wrangle has been done already\ncs_companies_base_slct <- readRDS(\"cs_companies_base_slct.rds\") \ncs_companies_base_slct\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 45,362 × 4\n#>      id name                                domain               linkedin_handle\n#>   <int> <chr>                               <chr>                <chr>          \n#> 1   305 Blueprint, a David's Bridal Company blueprintregistry.c… blueprint-regi…\n#> 2   793 BookingLive                         bookinglive.com      bookinglive    \n#> 3  2425 Brandvee                            momentum.ai          brandvee       \n#> # ℹ 45,359 more rows\n```\n\n\n:::\n:::\n\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_slct$id |> n_distinct()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> [1] 45026\n```\n\n\n:::\n:::\n\n\n:::\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_slct |> janitor::get_dupes(id)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 672 × 5\n#>        id dupe_count name          domain           linkedin_handle\n#>     <int>      <int> <chr>         <chr>            <chr>          \n#> 1  596494          2 Vi            vi.co            vitrainer      \n#> 2  596494          2 Vi            vi.co            vi             \n#> 3 1324413          2 Patch Lending patchlending.com patch-of-land  \n#> # ℹ 669 more rows\n```\n\n\n:::\n:::\n\n\n:::\n\n### CS: WRANGLE\n\nNothing to wrangle ...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_wrangled <- cs_companies_base_slct |> select(-name) |> \n  \n                                        # Add suffixes to col names\n                                        rename_with(~ paste(., \"cs\", sep = \"_\"))\n```\n:::\n\n\n### CS: CLEAN\n\n::: {.callout-important}\nMore cleaning necessary (same as CBPB)! The task was undertaken with a limited degree of enthusiasm.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunwanted_domains_cs    <- c(\"bit.ly\", \"linktr.ee\", \"facebook.com\", \"linkedin.com\", \"twitter.com\", \"crunchbase.com\")\nwanted_ids_cs          <- c(crunchbase = 1634413, linkedin = 8568581, twitter = 24745469)\n\ncs_companies_base_clnd <- cs_companies_base_wrangled |> \n  \n  mutate(domain_cs = if_else(\n    domain_cs %in% unwanted_domains_cs & !(id_cs %in% wanted_ids_cs), \n    NA_character_, \n    domain_cs)\n    )\n```\n:::\n\n\n\n:::::::\n\n# Data sources II {data-stack-name=\"Data II\"}\n2^nd^ objective: Match `CrunchBase` / `PitchBook` with `CoreSignal` data\n\n## Join *companies*, *member experiences* and *funding* information\n\n::::::: {.panel-tabset}\n\n### Companies\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nWe were able to match [37.287]{.fragment fragment-index=1 style=\"color:#cc0000; font-style: italic;\"} CS & CB/PB companies.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncb_cs_joined <- funded_companies_clnd |> \n\n    # Leftjoins\n    left_join(cs_companies_base_clnd |> select(id_cs, domain_cs),          by = c(domain          = \"domain_cs\"),          na_matches = \"never\") |> \n    left_join(cs_companies_base_clnd |> select(id_cs, linkedin_handle_cs), by = c(linkedin_handle = \"linkedin_handle_cs\"), na_matches = \"never\") |> \n\n    # Remove obs with no cs_id\n    filter(!is.na(id_cs)) |>\n    \n    # Remove matches, that matched different domains, but same company (e.g. company_id: 83060, id_cs: 4507928) block.xyz & squareup.com\n    select(company_id, id_cs) |> \n    distinct()\n    \ncb_cs_joined\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 38,118 × 2\n#>   company_id    id_cs\n#>        <int>    <int>\n#> 1          2  8345218\n#> 2          5 28149599\n#> 3          8  4469271\n#> 4         11  5349023\n#> 5         12  9364263\n#> # ℹ 38,113 more rows\n```\n\n\n:::\n:::\n\n\n::: {.fragment fragment-index=1}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncb_cs_joined |> distinct(company_id) |> nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> [1] 37287\n```\n\n\n:::\n:::\n\n\n:::\n\n### Jobs (all)\n\nWe got over 460 million employment observations from CoreSignal.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Other data versions\n# 1. Complete: \nmember_experience_dt \n#> {462.711.794}  \n\n# 2. Distinct1: \nmember_experience_dist_dt <- unique(member_experience_dt) \n#> {432.368.479}\n\n# 3. Distinct2: \nunique(member_experience_dist_dt[order(id)], by = setdiff(names(member_experience_dist_dt), \"id\")) \n#> {431.899.547}\n```\n:::\n\n\n### Jobs (dist)\n\nBut only ~50 Mil distinct employments\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Load distinct member experiences\nme_dist8_prqt <- arrow::open_dataset(\"cs_me_dist8_unest_empl_hist.parquet\") \nme_dist8_prqt |> glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> FileSystemDataset with 1 Parquet file\n#> 51,621,196 rows x 10 columns\n#> $ id_tie                 <int32> 16615559, 16615560, 16615561, 16615562, 1661556…\n#> $ id                    <double> 2244288231, 254049663, 948937291, 254049667, 25…\n#> $ member_id              <int32> 179313066, 179313066, 179313066, 179313066, 179…\n#> $ company_id             <int32> 865089, 9098713, 9098713, NA, 865089, 9020540, …\n#> $ company_name          <string> \"heritage community bank\", \"aurora bank fsb\", \"…\n#> $ title                 <string> \"AVP Chief Compliance/BSA Officer\", \"AVP Compli…\n#> $ date_from_parsed <date32[day]> 2010-02-01, 2012-07-01, 2011-11-01, 1997-07-01,…\n#> $ date_to_parsed   <date32[day]> 2011-11-01, 2013-06-01, 2012-07-01, 2006-05-01,…\n#> $ date_from_parsed_year  <int32> 2010, 2012, 2011, 1997, 2006, 2019, 2017, 2021,…\n#> $ date_to_parsed_year    <int32> 2011, 2013, 2012, 2006, 2010, 2021, 2018, NA, 1…\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\nExample\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nme_orig <- open_dataset(\"~/02_diss/01_coresignal/02_data/member_experience/me_orig/\")\nme_dist <- open_dataset(\"~/02_diss/01_coresignal/02_data/member_experience/me_dist/\")\n\nme_orig |> filter(member_id == 4257, company_id == 9007053) |> collect() |> as_tibble() |> arrange(date_from_parsed) |> print(n=19)\nme_dist |> filter(member_id == 4257, company_id == 9007053) |> collect() |> as_tibble() |> arrange(date_from_parsed)\n```\n:::\n\n\n### Jobs (focal)\n\nOver 10 million [(valid: must have starting date)]{style=\"color:#cc0000; font-style: italic;\"} employments at our crunchbase / pitchbook data set companies. 385.100 with a title containing the string [founder]{style=\"color:rgb(0, 94, 115); font-style: italic;\"}.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Distinct company ids\ncb_cs_joined_cs_ids <- cb_cs_joined |> distinct(id_cs) |> pull(id_cs)\nme_wrangled_prqt    <- me_dist8_prqt |> \n  \n                          # Select features\n                          select(member_id, company_id, exp_id = \"id\", date_from_parsed) |> \n                          \n                          # Select observations\n                          filter(company_id %in% cb_cs_joined_cs_ids) |> \n                          # - 967.080 observations (date_to not considered yet)\n                          filter(!is.na(date_from_parsed)) |> \n\n                          # Add suffix to col names\n                          rename_with(~ paste(., \"cs\", sep = \"_\")) |> \n                          compute()\n\nme_wrangled_prqt |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Table\n#> 11,050,164 rows x 4 columns\n#> $ member_id_cs              <int32> 9436436, 9436453, 9436478, 9436478, 9436513,…\n#> $ company_id_cs             <int32> 573738, 3073966, 4577566, 4577566, 4577566, …\n#> $ exp_id_cs                <double> 1891262301, 923902432, 1399967039, 525842890…\n#> $ date_from_parsed_cs <date32[day]> 2018-04-01, 2015-04-01, 2006-01-01, 2004-03-…\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\n### Funding\n\nMultiple Funding Dates --> [Take oldest]{style=\"color:#cc0000;\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_wrangled_tbl <- funded_companies_tbl |> \n  \n  # Consider multiple founding dates: Take oldest founding date\n  unnest(founded_on) |> \n  arrange(company_id, founded_on) |> \n  group_by(company_id) |> slice(1) |> ungroup()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.cell-top-margin {\n    margin-top: 0.5rem;\n}\n</style>\n:::\n\n\nExample of funding round data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_wrangled_tbl$funding_rounds[[1]] |>  \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 15\n#> Columns: 14\n#> $ round_id             <int> 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n#> $ round_uuid_pb        <chr> NA, \"47208-70T\", NA, \"58843-18T\", NA, NA, NA, \"78…\n#> $ round_uuid_cb        <chr> \"a6d3bfd9-5afa-47ce-86de-30a3abad6c9b\", NA, \"ea3b…\n#> $ announced_on         <date> 2013-01-01, 2014-04-01, 2015-06-01, 2015-10-07, …\n#> $ round_new            <int> 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13\n#> $ round                <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n#> $ exit_cycle           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n#> $ last                 <int> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1…\n#> $ round_type_new       <fct> Seed, Series A, Series B, Series C, Series D, Ser…\n#> $ round_type           <list> \"angel\", \"angel\", \"early_vc\", \"early_vc\", \"conver…\n#> $ round_types          <list> <\"angel\", \"angel_group\", \"investor\", \"company\", \"…\n#> $ raised_amount        <dbl> NA, 520000, NA, 1399999, NA, NA, NA, 3250000, NA,…\n#> $ post_money_valuation <dbl> NA, NA, NA, 3399998, NA, NA, NA, 10249998, NA, N…\n#> $ investors_in_round   <list> [<tbl_df[1 x 11]>], [<tbl_df[1 x 11]>], [<tbl_df…\n```\n\n\n:::\n:::\n\n\n### Conversion\n\n* Joining via `dplyr` due to memory constraint not possible.<br>\n* Joining via `Arrow` due to structure constraints not possible.<br>\n* --> Joining via `data.table` most efficient.<br>\n\nConversion to `data.tables` necessary:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1.  Funding Data\n# 1.1 Level 1\nfc_wrangled_dt |> setDT()\n\n# 1.2 Funding Data Level 2 (funding_rounds)\npurrr::walk(fc_wrangled_dt$funding_rounds, setDT)\n\n# 1.3 Remove unnecessary columns + initialize dummy for before_join\npurrr::walk(fc_wrangled_dt$funding_rounds, ~ .x[, \n          `:=`(round_uuid_pb = NULL, round_uuid_cb        = NULL, round_new          = NULL, round          = NULL,\n               exit_cycle    = NULL, last                 = NULL, round_type         = NULL, round_type_new = NULL, \n               round_types   = NULL, post_money_valuation = NULL, investors_in_round = NULL, before_join    = NA)\n          ]\n        )\n\n# 2. Matching Table\ncb_cs_joined_slct_dt |> setDT()\n\n# 3. Member experiences\nme_wrangled_dt <- me_wrangled_prqt |> collect()\n```\n:::\n\n\n### Join\n\nWorking `data.table` solution (efficiency increase through join `by reference` possible).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Add company_id from funded_companies to member experiences\nme_joined_dt <- cb_cs_joined_slct_dt[me_wrangled_dt, on = .(id_cs = company_id_cs), allow.cartesian = TRUE]\n#> 12.978.226\n\n# 2. Add funding data from funded_companies\nme_joined_dt <- fc_wrangled_dt[me_joined_dt, on = .(company_id)]\n#> 12.270.572\n\n# 3. Remove duplicates (why are there any?)\nme_joined_dt <- unique(me_joined_dt, by = setdiff(names(me_joined_dt), \"funding_rounds\"))\n#> 12.270.572 .... No duplicates anymore. Removed from cb_cs_joined_slct_dt\n```\n:::\n\n\nNot working `dplyr` solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nme_joined_dt_dplyr <- me_wrangled_dt |>\n\n  # Add company_id from funded_companies\n  left_join(cb_cs_joined_slct_dt,\n            by = c(company_id_cs = \"id_cs\")) |>\n\n  # Add data from funded_companies\n  left_join(funded_companies_wrangled_dt,\n            by = \"company_id\")  |>\n  distinct()\n```\n:::\n\n\n`Arrow` because of nested funding data not possible.\n\n:::::::\n\n# Analysis {data-stack-name=\"Features\"}\nUsing domain knowledge to extract features\n\n## Feature Engineering\n\n::::::: {.panel-tabset}\n\n### F1: T~join~ - T~found~\n\nHow many month have passed since the company was founded and before the person joined the company (in months)?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lubridate)\nme_joined_dt[, tjoin_tfound := (interval(founded_on, date_from_parsed_cs) %/% months(1))]\n```\n:::\n\n\n### Prep1\n\nUnnesting necessary due to memory constraints (takes multiple hours ... to be measured).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Working: data.table\nme_joined_unnested_dt <- me_joined_dt[,rbindlist(funding_rounds), by = setdiff(names(me_joined_dt), \"funding_rounds\")]\n# Not working: dplyr\nme_joined_unnested_tbl <- me_joined_dt |> unnest(funding_rounds)\n```\n:::\n\n\nAdd feature whether or not member joined before Announcement of a funding round:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add feature whether or not member joined before Announcement of a funding round\nme_joined_unnested_dt[,before_join := date_from_parsed_cs >= announced_on]\n\n# Inspect\nopen_dataset(\"me_joined_unnested1.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> FileSystemDataset with 1 Parquet file\n#> 88,429,236 rows x 15 columns\n#> $ company_id_cbpb           <int32> 85514, 85514, 85514, 85514, 85514, 85514, 85…\n#> $ founded_on_cbpb     <date32[day]> 2007-01-01, 2007-01-01, 2007-01-01, 2007-01-…\n#> $ company_id_cs             <int32> 10830353, 10830353, 10830353, 10830353, 1083…\n#> $ id_tie                    <int32> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 29…\n#> $ exp_id_cs                <double> 606461989, 606461989, 606461989, 606461989, …\n#> $ member_id_cs              <int32> 162, 162, 162, 162, 162, 162, 162, 162, 162,…\n#> $ company_name_cs          <string> \"Kony, Inc.\", \"Kony, Inc.\", \"Kony, Inc.\", \"K…\n#> $ title_cs           <large_string> \"Associate Engineer\", \"Associate Engineer\", …\n#> $ date_from_parsed_cs <date32[day]> 2015-06-01, 2015-06-01, 2015-06-01, 2015-06-…\n#> $ date_to_parsed_cs   <date32[day]> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ tjoin_tfound             <double> 101, 101, 101, 101, 101, 101, 101, 101, 101,…\n#> $ round_id                  <int32> 259195, 259196, 259197, 259198, 259199, 2592…\n#> $ announced_on        <date32[day]> 2011-02-24, 2011-03-01, 2011-06-07, 2012-01-…\n#> $ raised_amount            <double> 13370002, 8280000, 2352002, 2000000, 1500000…\n#> $ before_join                <bool> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TR…\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\n### F2, F3\n\nF2. How much capital has been acquired by the time the person joins?<br>\nF3. How many funding rounds have been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize empty columns (not sure yet if that increases performance)\nme_joined_unnested_dt[, `:=` (raised_amount_before_join = NA_real_, \n                              num_rounds_before_join    = NA_real_)]\n\n# Add features\nme_joined_unnested_dt[, `:=` (raised_amount_before_join = sum(raised_amount[before_join == T], na.rm = T),\n                              num_rounds_before_join    = sum(  before_join[before_join == T])), \n                      by = .(company_id, exp_id_cs)]\n\nopen_dataset(\"me_joined_unnested2.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> FileSystemDataset with 1 Parquet file\n#> 88,429,236 rows x 17 columns\n#> $ company_id_cbpb            <int32> 85514, 85514, 85514, 85514, 85514, 85514, 8…\n#> $ founded_on_cbpb      <date32[day]> 2007-01-01, 2007-01-01, 2007-01-01, 2007-01…\n#> $ company_id_cs              <int32> 10830353, 10830353, 10830353, 10830353, 108…\n#> $ id_tie                     <int32> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n#> $ exp_id_cs                 <double> 606461989, 606461989, 606461989, 606461989,…\n#> $ member_id_cs               <int32> 162, 162, 162, 162, 162, 162, 162, 162, 162…\n#> $ company_name_cs           <string> \"Kony, Inc.\", \"Kony, Inc.\", \"Kony, Inc.\", \"…\n#> $ title_cs            <large_string> \"Associate Engineer\", \"Associate Engineer\",…\n#> $ date_from_parsed_cs  <date32[day]> 2015-06-01, 2015-06-01, 2015-06-01, 2015-06…\n#> $ date_to_parsed_cs    <date32[day]> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ tjoin_tfound              <double> 101, 101, 101, 101, 101, 101, 101, 101, 101…\n#> $ round_id                   <int32> 259195, 259196, 259197, 259198, 259199, 259…\n#> $ announced_on         <date32[day]> 2011-02-24, 2011-03-01, 2011-06-07, 2012-01…\n#> $ raised_amount             <double> 13370002, 8280000, 2352002, 2000000, 150000…\n#> $ before_join                 <bool> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…\n#> $ raised_amount_before_join <double> 120528113, 120528113, 120528113, 120528113,…\n#> $ num_rounds_before_join    <double> 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5…\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\n### Prep2\n\nNest again\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# data.table\nexcluded_cols       <- setdiff(names(me_joined_unnested_dt), c(\"round_id\", \"announced_on\", \"raised_amount\", \"before_join\"))\nme_joined_nested_dt <- me_joined_unnested_dt[, list(funding_rounds=list(.SD)), by=excluded_cols]\n\n# Dplyr (not working)\n# me_joined_nested_dt <- me_joined_unnested_dt |> \n#         nest(funding_rounds = c(\"round_id\", \"announced_on\", \"raised_amount\", \"before_join\"))\n\nopen_dataset(\"me_joined_nested.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> FileSystemDataset with 1 Parquet file\n#> 12,654,304 rows x 13 columns\n#> $ company_id                 <int32> 71668, 5070, 117119, 5070, 117119, 7920, 52…\n#> $ founded_on           <date32[day]> 2019-01-01, 2014-07-01, 2015-01-01, 2014-07…\n#> $ id_cs                      <int32> 23865165, 10861408, 10861408, 10861408, 108…\n#> $ exp_id_cs                 <double> 1927546132, 1267852578, 1267852578, 2670635…\n#> $ member_id_cs               <int32> 1874511, 1874513, 1874513, 1874513, 1874513…\n#> $ company_name_cs           <string> \"Three Good\", \"Point\", \"Point\", \"Point\", \"P…\n#> $ title_cs                  <string> \"Founder & CEO\", \"Customer Operations at Po…\n#> $ date_from_parsed_cs  <date32[day]> 2015-04-01, 2018-01-01, 2018-01-01, 2018-11…\n#> $ date_to_parsed_cs    <date32[day]> NA, NA, NA, NA, NA, NA, 2019-04-01, 2019-04…\n#> $ tjoin_tfound              <double> -45, 42, 36, 52, 46, 50, 105, -33, 49, 131,…\n#> $ raised_amount_before_join <double> 0, 11399999, 12100000, 11399999, 12100000, …\n#> $ num_rounds_before_join    <double> 0, 2, 3, 2, 3, 6, 9, 0, 6, 9, 12, 7, 4, 9, …\n#> $ funding_rounds         <list<...>> [<tbl_df[5 x 4]>], [<tbl_df[5 x 4]>], [<tbl…\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\n### Titles\n\nTo differentiate between founder and non-founder CS titles are needed\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prep data (shrink / remove unnecessary data)\nme_joined_nested_foc_dt[, funding_rounds := NULL]\n\n# Prep titles\nme_wrangled_wt_dt <-  me_dist_prqt |> \n                          filter(company_id %in% cb_cs_joined_cs_ids, !is.na(date_from_parsed)) |>  \n                          select(exp_id_cs, title_cs) |> \n                          collect() |> \n                          setDT()\n\n# Join\nme_joined_nested_foc_dt[me_wrangled_wt_dt, on = .(exp_id_cs), title_cs := i.title_cs]\n\n# Inspect\nopen_dataset(\"me_joined_nested_foc.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> FileSystemDataset with 1 Parquet file\n#> 12,654,304 rows x 12 columns\n#> $ company_id                 <int32> 71668, 5070, 117119, 5070, 117119, 7920, 52…\n#> $ founded_on           <date32[day]> 2019-01-01, 2014-07-01, 2015-01-01, 2014-07…\n#> $ id_cs                      <int32> 23865165, 10861408, 10861408, 10861408, 108…\n#> $ exp_id_cs                 <double> 1927546132, 1267852578, 1267852578, 2670635…\n#> $ member_id_cs               <int32> 1874511, 1874513, 1874513, 1874513, 1874513…\n#> $ company_name_cs           <string> \"Three Good\", \"Point\", \"Point\", \"Point\", \"P…\n#> $ title_cs                  <string> \"Founder & CEO\", \"Customer Operations at Po…\n#> $ date_from_parsed_cs  <date32[day]> 2015-04-01, 2018-01-01, 2018-01-01, 2018-11…\n#> $ date_to_parsed_cs    <date32[day]> NA, NA, NA, NA, NA, NA, 2019-04-01, 2019-04…\n#> $ tjoin_tfound              <double> -45, 42, 36, 52, 46, 50, 105, -33, 49, 131,…\n#> $ raised_amount_before_join <double> 0, 11399999, 12100000, 11399999, 12100000, …\n#> $ num_rounds_before_join    <double> 0, 2, 3, 2, 3, 6, 9, 0, 6, 9, 12, 7, 4, 9, …\n#> Call `print()` for full schema details\n```\n\n\n:::\n:::\n\n\n:::::::\n\n\n# Univariate summary statistics {data-stack-name=\"Plots\"}\nDescribing patterns found in univariate data\n\n## Plots\n\n::::::: {.panel-tabset}\n\n### Data\n\nSeparate between \"Founder\" & \"Non-Founder\" and calculate summary statistics necessary for plotting.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nlookup_term <- \"founder\"\ndata        <- me_joined_nested_foc_prqt |> \n                  filter(!is.na(title_cs)) |> \n                  mutate(Role = title_cs |> tolower() |> str_detect(lookup_term)) |> \n                  collect() |> \n                  mutate(\n                    Role = Role |> factor(levels = c(TRUE, FALSE), \n                                                labels = c('Founder', 'Non-Founder'))\n                    ) \n\n# Summary Statistics (Mean & Median)\ndf_vline_long <- data |> \n  group_by(Role) |> \n  summarise(Mean = mean(tjoin_tfound), Median = median(tjoin_tfound), n = n()) |> \n  pivot_longer(c(Mean, Median,n ), names_to = \"Statistic\", values_to = \"Value\") |> \n  mutate(Value_chr    = format(round(Value, 1), big.mark=\".\", decimal.mark = \",\", drop0trailing = T),\n         gg_pos_y = rep(c(0.07,0.06, 0.05),2),\n         gg_color = rep(c(\"#8F8470\", \"#BF9240\", \"#FEA400\"), 2))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.reveal .column-output-location .column:first-of-type div.sourceCode {\n    height: auto;\n}\n</style>\n:::\n\n\n### F1\n\nHow many month have passed since the company was founded and before the person joined the company (binwidth: 3 months)?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  # Plot\n  ggplot(aes(x = tjoin_tfound, fill = Role, color = Role)) +\n  geom_histogram(aes(y =..density..), size = .2, binwidth = 3, alpha = 0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Statistics & Design\n  ggnewscale::new_scale_color() +\n  geom_vline(data = df_vline_long |> filter(Statistic != \"n\"), aes(xintercept = Value, linetype = Statistic, color = Statistic), key_glyph = \"path\") +\n  scale_linetype_manual(values = c(2,3)) +\n  scale_color_manual(values = c(\"#8F8470\", \"#BF9240\", \"#FEA400\")) +\n  geom_label(data = df_vline_long, aes(x = 100, y = gg_pos_y, label = paste0(Statistic, ' = ', Value_chr)), \n             color = df_vline_long$gg_color, fill = \"transparent\", alpha = 0.5, size = 3, hjust = \"left\") +\n  xlim(-250, 250) +\n  labs(x = \"Δ T_join, T_foundation (in month)\", y = \"Density\") + \n  theme(legend.key=element_blank())\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot1-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n### F2\n\nHow much capital has been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  # Plot\n  ggplot(aes(x = raised_amount_before_join, color = Role, fill = Role)) + \n  geom_histogram(aes(y =..density..), alpha=0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Design\n  scale_x_continuous(labels = scales::label_number(prefix = \"$\", accuracy = 0.1, scale_cut = scales::cut_short_scale()), limits = c(NA,1e+09)) +\n  labs(x = \"Raised amount before join\", y = \"Density\", fill=\"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot2-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n### F3\n\nHow many funding rounds have been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  ggplot(aes(x = num_rounds_before_join, color = Role, fill = Role)) + \n  geom_histogram(aes(y =..density..), binwidth = 1, alpha=0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Design\n  xlim(NA, 20) +\n  labs(x = \"# Rounds before join\", y = \"Density\", fill=\"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot3-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n:::::::\n\n## Fortune500\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nme_matched_members_dt <- me_matched_members_prqt |> collect()\n\n# 46 Batches (Chunks with 5 Million rows)\nslice_ids <- tibble(from = seq(1, 230000000, 5000000),to = c(seq(5000000, 225000000, 5000000), 229065592))\nfor (i in 1:46) {\n  # Build Batch\n  x <- slice_ids$from[i]; y <- slice_ids$to[i]\n  me_matched_members_slice_dt <- me_matched_members_dt[x:y,]\n  # Create Features\n  me_matched_members_slice_dt[, `:=` (f500 = (purrr::pmap_lgl(list(company_name, date_from_parsed, date_to_parsed), check_f500, .progress = TRUE)),\n                                      role = title |> tolower() |> stringr::str_detect(\"founder\"))]\n  # Save\n  me_matched_members_slice_dt |> write_parquet(paste0(\"/media/tie/ssd2/joschka/me_f500/me_f500_\", cur_id, \".parquet\"))\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_f500 <- function(name,year_from,year_to) {\n  \n  if (is.na(year_to))   {year_to <- 2023}\n  if (is.na(year_from)) {return(NA)}\n  \n  data <- fortune500 |> \n    filter(year |> between(year_from, year_to)) |> \n    pull(company)\n  \n  name |> tolower() %in% data\n}\n```\n:::\n\n \n# Employment History {data-stack-name=\"Employment History\"}\nMatch current and past employments to corresponding Fortune500 companies\n \n## Employment History (Worked for Fortune 500 company?)\n\n**Content-related problems**\n\n* Matching problems:\n  - amd <> advanced micro devices\n  - intel <> intel corporation\n  \n* Geographical issues:\n  - Just US companies (use Fortune Global data)\n  \n**Technical issues**\n\nTakes loooooooong time to calculate...\n\n## Code I (Data + Function)\n\nFunction\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Function\ncheck_f500 <- function(title, year_from, year_to) {\n  \n  # Handle NA inputs\n  if (is.na(year_to))   {year_to <- 2023}\n  if (is.na(year_from)) {return(NA)}\n  \n  # Filter time frame\n  data <- fortune500 |> \n    \n    filter(year |> between(year_from, year_to)) |> \n    pull(company)\n  \n  # Check match and return bool\n  title |> tolower() %in% data\n}\n```\n:::\n\n\n:::: {.columns}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n::: {.column width=\"50%\"}\n\nCoreSignal data (n = 229.065.592)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Data\nme_matched_members_prqt <- open_dataset(\"me_matched_members.parquet\") \nme_matched_members_prqt |> \n  \n  head() |> collect()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 6 × 7\n#>       id member_id company_id company_name title date_from_parsed date_to_parsed\n#>    <dbl>     <int>      <int> <chr>        <chr> <date>           <date>        \n#> 1 6.07e8   2605953         NA arkansas se… Corp… 2015-02-01       NA            \n#> 2 6.07e8   2605953         NA freelance m… Free… 2016-05-01       NA            \n#> 3 6.30e8   2605953   10415396 101 magazine Cont… 2012-08-01       2014-05-01    \n#> # ℹ 3 more rows\n```\n\n\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nUS Fortune 500 data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfortune500 <- readRDS(\"fortune_500_1955-2022.rds\") |> \n                \n                select(year, company) |> \n                mutate(company = company |> tolower())\nfortune500\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 34,000 × 2\n#>    year company       \n#>   <dbl> <chr>         \n#> 1  1955 general motors\n#> 2  1955 exxon mobil   \n#> 3  1955 u.s. steel    \n#> # ℹ 33,997 more rows\n```\n\n\n:::\n:::\n\n:::\n::::\n\n## Code II (Chunkwise Execution)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Collect data\nme_matched_members_dt <- me_matched_members_prqt |> collect()\n# 2.Build batches\nslice_ids <- tibble(\n  from  = seq(1, 230000000, 5000000),\n  to    = c(seq(5000000, 225000000, 5000000), 229065592),\n)\n\nfor (i in 1:46) {\n\n  # Create current batch  \n  x <- slice_ids$from[i]\n  y <- slice_ids$to[i]\n  me_matched_members_slice_dt <- me_matched_members_dt[x:y,]\n\n  # Add features\n  me_matched_members_slice_dt[, `:=` (f500 = (purrr::pmap_lgl(list(company_name, date_from_parsed, date_to_parsed), check_f500, .progress = TRUE)),\n                                      role = title |> tolower() |> stringr::str_detect(\"founder\"))]\n  \n  # Save\n  me_matched_members_slice_dt |> write_parquet(paste0(\"me_f500/me_f500_\", cur_id, \".parquet\"))\n}\n```\n:::\n\n\n## Code III (Build feature)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Load data \nme_f500 <- open_dataset(\"me_f500/\") |> \n  collect()\n\n# 2. Add Ids\nme_dist_ids_prqt <- arrow::open_dataset(\"me_dist4.parquet\") |> select(id, member_id) |> collect()\nme_f500_id       <-  me_dist_ids_prqt[me_f500, on = .(id)] \n\n# 3. Add features\n# 3.1 Earliest founding date & earliest f500 date (if founded)\nme_f500_id[,`:=` (founding_min      = (ifelse(any(role == T),                  min(date_from_parsed[role==T]),   NA_real_)),\n                  f500_min_founding = (ifelse(any(role == T) & any(f500 == T), min(date_from_parsed[f500 == T]), NA_real_))),\n           by = .(member_id)]\n\n# 3.2 Compare\nme_f500_id[, f500_before_founding := f500_min_founding <= founding_min]\n```\n:::\n\n\n## Plot\n\nConstraints: \n\n1. Analysis takes place on an annual level.\n2. First funding event is being considered\n3. Exact matches only\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\nme_f500_id <- arrow::open_dataset(\"~/02_diss/01_coresignal/02_data/me_f500_id.parquet\")\ndata <- me_f500_id |> \n  \n          # Filter \"Founder\"\n          filter(role == T) |> collect() \n  \ndata |> \n  ggplot(aes(x = f500_before_founding)) + \n    geom_bar() +\n    scale_x_discrete(labels=c(\"Employment at Fortune500\\nAFTER\\nfounding\", \"Employment at Fortune500\\nBEFORE\\nfounding\", \"Neither case\")) +\n    scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6, accuracy = 0.1)) + \n    labs(x = \"\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/unnamed-chunk-58-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n\n# Employment Skills {data-stack-name=\"Skills\"}\nInferences from semantic similarity of LinkedIn users' skills\n \n## Cluster skills\n\ntbd\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmember_skills_prqt <- arrow::open_dataset(\"member_skills.parquet\")\nmember_skills_prqt |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nskill_names_tbl <- readRDS(\"skill_names_tbl.rds\")\nskill_names_tbl\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> # A tibble: 2,423,690 × 2\n#>   skill_id skill_name \n#>      <int> <fct>      \n#> 1        1 mathematics\n#> 2        2 swimming   \n#> 3        3 analytics  \n#> # ℹ 2,423,687 more rows\n```\n\n\n:::\n:::\n\n\n# Current variables {data-stack-name=\"Current\"}\nVariables built from Experience, Education and funding data\n\n## Built variables\n\n::::::: {.panel-tabset}\n\n### All\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 67\n#> $ company_id_cbpb                      <int> 90591, 152845, 90440, 138208, 116…\n#> $ funding_after_mid                    <chr> \"yes\", NA, \"yes\", \"yes\", \"yes\", \"…\n#> $ funding_after_early                  <chr> \"yes\", \"no\", \"yes\", \"yes\", \"yes\",…\n#> $ member_id                            <int> 878, 2104, 3548, 3548, 3970, 4005…\n#> $ id_tie                               <int> 38, 67, 89, 89, 96, 104, 183, 175…\n#> $ exp_id_cs                            <dbl> 2481733250, 1423977093, 2638, 263…\n#> $ exp_corporate                        <dbl> 0.00000, 12.00000, 0.00000, 0.000…\n#> $ exp_funded_startup                   <dbl> 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 0,…\n#> $ exp_founder                          <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 0…\n#> $ exp_f500                             <dbl> 0.00000, 0.00000, 0.00000, 0.0000…\n#> $ exp_research                         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ exp_research_ivy                     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ company_id_cs                        <int> 140537, 10644128, 6068905, 606890…\n#> $ company_name_cs                      <chr> \"Bristol-Myers Squibb\", \"HERE\", \"…\n#> $ company_name_cbpb                    <chr> \"receptos\", \"HERE Technologies Ch…\n#> $ founded_on_cbpb                      <date> 2007-01-01, 2012-11-13, 2009-07-…\n#> $ closed_on_cbpb                       <date> NA, NA, NA, NA, NA, NA, 2021-04-…\n#> $ title_cs                             <chr> \"Key Account Manager\", \"GIS Analy…\n#> $ date_from_parsed_cs                  <date> 2006-01-01, 2016-01-01, 2010-01-…\n#> $ date_to_parsed_cs                    <date> 2008-08-01, NA, NA, NA, 2011-10-…\n#> $ tjoin_tfound                         <dbl> -12, 37, 6, 48, -47, 48, 17, 11, …\n#> $ raised_amount_before_join_company    <dbl> 0, 0, 0, 7722796, 0, 9961692, 333…\n#> $ num_rounds_before_join               <dbl> 0, 1, 0, 2, 0, 2, 1, 1, 2, 0, 1, …\n#> $ is_f500                              <lgl> TRUE, FALSE, TRUE, TRUE, FALSE, F…\n#> $ is_founder                           <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ is_research                          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ is_research_ivy                      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ date_1st_founder_exp                 <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ date_1st_f500_exp                    <date> 2006-01-01, NA, 2010-01-01, 2010…\n#> $ date_1st_funded_startup_exp          <date> 2006-01-01, 2016-01-01, 2010-01-…\n#> $ date_1st_research_exp                <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ date_1st_research_ivy_exp            <date> NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ date_1st_corporate_exp               <date> 2009-02-01, 2015-01-01, NA, NA, …\n#> $ time_since_1st_corporate_exp         <dbl> NA, 12, NA, NA, 116, NA, 136, 40,…\n#> $ time_since_1st_founder_exp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ time_since_1st_f500_exp              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ time_since_1st_funded_startup_exp    <dbl> NA, NA, NA, NA, NA, NA, 96, NA, N…\n#> $ time_since_1st_research_exp          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ time_since_1st_research_ivy_exp      <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ time_since_1st_experience            <dbl> 0, 12, 0, 0, 116, 0, 136, 40, 176…\n#> $ raised_amount_before_founder_member  <dbl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ raised_amount_before_all_member      <dbl> NA, NA, NA, NA, NA, NA, 0, 0, NA,…\n#> $ was_corporate_before                 <lgl> FALSE, TRUE, FALSE, FALSE, TRUE, …\n#> $ was_founder_before                   <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ was_f500_before                      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ was_fc_before                        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ was_uni_before                       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ was_ivy_before                       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE…\n#> $ stage_mid                            <lgl> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ stage_late                           <lgl> NA, NA, NA, NA, NA, NA, FALSE, NA…\n#> $ date_from_stage                      <chr> \"early1\", \"mid\", \"early2\", \"mid\",…\n#> $ company_start_mid                    <date> 2009-01-01, 2014-11-13, 2011-07-…\n#> $ company_start_late                   <date> 2009-11-23, 2017-11-13, 2014-07-…\n#> $ rank_global_2023_best                <int> 917, 1549, NA, NA, NA, NA, NA, NA…\n#> $ score_global_2023_best               <dbl> 40.6, 26.8, NA, NA, NA, NA, NA, N…\n#> $ rank_national_2023_best              <int> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ rank_national_during_enrollment_best <int> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ degree_ba2                           <lgl> FALSE, TRUE, NA, NA, TRUE, NA, NA…\n#> $ degree_ma2                           <lgl> FALSE, FALSE, NA, NA, FALSE, NA, …\n#> $ degree_phd2                          <lgl> FALSE, FALSE, NA, NA, FALSE, NA, …\n#> $ degree_mba2                          <lgl> TRUE, FALSE, NA, NA, FALSE, NA, N…\n#> $ num_rounds_cumulated_founder         <int> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ num_rounds_cumulated_all             <int> NA, NA, NA, NA, NA, NA, 1, 1, NA,…\n#> $ announced_on_sB                      <date> 2012-02-03, 2018-01-04, 2011-03-…\n#> $ round_type_new_next                  <fct> Series C, Series C, Series C, Ser…\n#> $ raised_amount_cumsum_sB              <dbl> 46043054, 0, 1905000, 11022796, 2…\n#> $ raised_amount_cumsum_sB_next         <dbl> 76043054, 0, 8712306, 13854868, 4…\n```\n\n\n:::\n:::\n\n\n### General\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(id_tie, member_id, exp_id_cs, company_id_cbpb, company_name_cbpb, company_id_cs, company_name_cs, \n         founded_on_cbpb, closed_on_cbpb,\n         title_cs) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 10\n#> $ id_tie            <int> 38, 67, 89, 89, 96, 104, 183, 175, 209, 243, 321, 37…\n#> $ member_id         <int> 878, 2104, 3548, 3548, 3970, 4005, 4224, 4224, 4317,…\n#> $ exp_id_cs         <dbl> 2481733250, 1423977093, 2638, 2638, 1736317868, 3084…\n#> $ company_id_cbpb   <int> 90591, 152845, 90440, 138208, 116099, 97810, 40123, …\n#> $ company_name_cbpb <chr> \"receptos\", \"HERE Technologies Chicago\", \"crowdtwist…\n#> $ company_id_cs     <int> 140537, 10644128, 6068905, 6068905, 11825305, 194148…\n#> $ company_name_cs   <chr> \"Bristol-Myers Squibb\", \"HERE\", \"Oracle\", \"Oracle\", …\n#> $ founded_on_cbpb   <date> 2007-01-01, 2012-11-13, 2009-07-01, 2006-01-01, 201…\n#> $ closed_on_cbpb    <date> NA, NA, NA, NA, NA, NA, 2021-04-09, NA, NA, NA, NA,…\n#> $ title_cs          <chr> \"Key Account Manager\", \"GIS Analyst I\", \"QA\", \"QA\", …\n```\n\n\n:::\n:::\n\n\n### EDA\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(date_from_parsed_cs, date_to_parsed_cs, \n         tjoin_tfound, raised_amount_before_join_company, num_rounds_before_join) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 5\n#> $ date_from_parsed_cs               <date> 2006-01-01, 2016-01-01, 2010-01-01,…\n#> $ date_to_parsed_cs                 <date> 2008-08-01, NA, NA, NA, 2011-10-01,…\n#> $ tjoin_tfound                      <dbl> -12, 37, 6, 48, -47, 48, 17, 11, 44,…\n#> $ raised_amount_before_join_company <dbl> 0, 0, 0, 7722796, 0, 9961692, 333333…\n#> $ num_rounds_before_join            <dbl> 0, 1, 0, 2, 0, 2, 1, 1, 2, 0, 1, 2, …\n```\n\n\n:::\n:::\n\n\n### Exp (dummy)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(starts_with(\"is_\"),\n         starts_with(\"was_\")) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 10\n#> $ is_f500              <lgl> TRUE, FALSE, TRUE, TRUE, FALSE, FALSE, FALSE, FAL…\n#> $ is_founder           <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ is_research          <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ is_research_ivy      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ was_corporate_before <lgl> FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE, TRU…\n#> $ was_founder_before   <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ was_f500_before      <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ was_fc_before        <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, TRUE, F…\n#> $ was_uni_before       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n#> $ was_ivy_before       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n```\n\n\n:::\n:::\n\n\n### Exp (quant)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(\n    starts_with(\"date_1st_\"),\n    starts_with(\"time_since_1st_\"),\n    starts_with(\"exp_\"), -exp_id_cs) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 19\n#> $ date_1st_founder_exp              <date> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ date_1st_f500_exp                 <date> 2006-01-01, NA, 2010-01-01, 2010-01…\n#> $ date_1st_funded_startup_exp       <date> 2006-01-01, 2016-01-01, 2010-01-01,…\n#> $ date_1st_research_exp             <date> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ date_1st_research_ivy_exp         <date> NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n#> $ date_1st_corporate_exp            <date> 2009-02-01, 2015-01-01, NA, NA, 200…\n#> $ time_since_1st_corporate_exp      <dbl> NA, 12, NA, NA, 116, NA, 136, 40, 17…\n#> $ time_since_1st_founder_exp        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ time_since_1st_f500_exp           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ time_since_1st_funded_startup_exp <dbl> NA, NA, NA, NA, NA, NA, 96, NA, NA, …\n#> $ time_since_1st_research_exp       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ time_since_1st_research_ivy_exp   <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n#> $ time_since_1st_experience         <dbl> 0, 12, 0, 0, 116, 0, 136, 40, 176, 4…\n#> $ exp_corporate                     <dbl> 0.00000, 12.00000, 0.00000, 0.00000,…\n#> $ exp_funded_startup                <dbl> 0, 0, 0, 0, 0, 0, 18, 0, 0, 0, 0, 0,…\n#> $ exp_founder                       <dbl> 0.0000, 0.0000, 0.0000, 0.0000, 0.00…\n#> $ exp_f500                          <dbl> 0.00000, 0.00000, 0.00000, 0.00000, …\n#> $ exp_research                      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n#> $ exp_research_ivy                  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n```\n\n\n:::\n:::\n\n\n### Edu\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(score_global_2023_best,\n         starts_with(\"rank\"),\n         starts_with(\"degree\")) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 8\n#> $ score_global_2023_best               <dbl> 40.6, 26.8, NA, NA, NA, NA, NA, N…\n#> $ rank_global_2023_best                <int> 917, 1549, NA, NA, NA, NA, NA, NA…\n#> $ rank_national_2023_best              <int> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ rank_national_during_enrollment_best <int> NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ degree_ba2                           <lgl> FALSE, TRUE, NA, NA, TRUE, NA, NA…\n#> $ degree_ma2                           <lgl> FALSE, FALSE, NA, NA, FALSE, NA, …\n#> $ degree_phd2                          <lgl> FALSE, FALSE, NA, NA, FALSE, NA, …\n#> $ degree_mba2                          <lgl> TRUE, FALSE, NA, NA, FALSE, NA, N…\n```\n\n\n:::\n:::\n\n\n### Fund\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_me_dist8_unest_wedu_dt |> \n  select(date_from_stage, company_start_mid, company_start_late,\n         raised_amount_before_founder_member, raised_amount_before_all_member,\n         funding_after_mid, funding_after_early) |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```hscroll\n#> Rows: 2,659,657\n#> Columns: 7\n#> $ date_from_stage                     <chr> \"early1\", \"mid\", \"early2\", \"mid\", …\n#> $ company_start_mid                   <date> 2009-01-01, 2014-11-13, 2011-07-0…\n#> $ company_start_late                  <date> 2009-11-23, 2017-11-13, 2014-07-0…\n#> $ raised_amount_before_founder_member <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA…\n#> $ raised_amount_before_all_member     <dbl> NA, NA, NA, NA, NA, NA, 0, 0, NA, …\n#> $ funding_after_mid                   <chr> \"yes\", NA, \"yes\", \"yes\", \"yes\", \"y…\n#> $ funding_after_early                 <chr> \"yes\", \"no\", \"yes\", \"yes\", \"yes\", …\n```\n\n\n:::\n:::\n\n\n::::::: \n\n\n\n# Next Steps {data-stack-name=\"Next Steps\"}\n\n## Further analysis is necessary\n\n* Match employment history with Fortune500 (revenue based selection)\n* Cluster job titles\n* Cluster skills\n\n. . .\n\n![](https://c.tenor.com/3EYd9ID79vcAAAAd/mic-drop-the-voice.gif){fig-align=\"center\" width=50%}\n",
    "supporting": [
      "cs_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}