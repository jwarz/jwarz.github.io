{
  "hash": "0eb13b9edf46a39cc14893a450e06f07",
  "result": {
    "markdown": "---\n# TITLE & AUTHOR\ntitle: \"CoreSignal Analysis\"\nsubtitle: \"Current Status\"\nauthor: \"Joschka Schwarz\"\ninstitute: \"Hamburg University of Technology\"\ndate: today\ndate-format: \"dddd, D[<sup style='font-size:65%;font-style:italic;'>th</sup>] [of] MMMM YYYY\"\nsection-divs: true\nfilters:\n   - lightbox\nlightbox: auto\nengine: knitr\nknitr:\n  opts_chunk: \n    class-output: hscroll\n---\n\n\n\n\n## Table of Contents {data-state=\"hide-menubar\"}\n<ul class=\"menu\"><ul>\n\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.hscroll {\n  overflow-x: auto;\n  white-space: nowrap;\n}\n</style>\n:::\n\n\n# Data sources I {data-stack-name=\"Data I\"}\n1^st^ objective: Prepare `CrunchBase` / `PitchBook` and `CoreSignal` data\n\n## Load & Init Companies (CrunchBase, PitchBook & CoreSignal)\n\n::::::: {.panel-tabset}\n\n### CBPB: SELECT\n\nCrunchbase data contains **150,838** startups with a valid funding trajectory.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\np_load(arrow, dplyr, tidyr)\n\nfunded_companies_prqt <- open_dataset(\"funded_companies_identifiers.parquet\") \nfunded_companies_prqt\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 150,838 × 3\n#>   company_id            domain linkedin_url                                     \n#>        <int> <list<character>> <chr>                                            \n#> 1          1               [1] <NA>                                             \n#> 2          2               [1] https://www.linkedin.com/company/luna-pharmaceut…\n#> 3          3               [1] http://www.linkedin.com/company/chainsync        \n#> # ℹ 150,835 more rows\n```\n:::\n:::\n\n\n::: {.fragment}\n\nMultiple domains (Unnesting via `Arrow` not possible. Options: `Spark` & `sparklyr.nested`):\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_unnested_tbl <- funded_companies_prqt |> collect() |> \n                      # 1. Allow multiple domains per company. No multiple linkedin handles.\n                      unnest(domain) \nfc_unnested_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 155,413 × 3\n#>   company_id domain              linkedin_url                                   \n#>        <int> <chr>               <chr>                                          \n#> 1          1 zana.io             <NA>                                           \n#> 2          2 premamawellness.com https://www.linkedin.com/company/luna-pharmace…\n#> 3          3 chainsync.com       http://www.linkedin.com/company/chainsync      \n#> # ℹ 155,410 more rows\n```\n:::\n:::\n\n\n:::\n\n\n### CBPB: WRANGLE\n\n1. Must have identifier (domain, linkedin)\n2. Clean identifiers\n3. Remove duplicates\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(stringr)\nfc_unnested_tbl |> \n  \n  # 1. At least 1 identifier: 4.518 observations are filtered out\n  filter(if_any(c(domain, linkedin_url), ~!is.na(.))) |>\n  \n  # 2. Extract linkedin handle & clean domains\n  mutate(linkedin_handle = linkedin_url |> str_extract(\"(?<=linkedin\\\\.com/company/).*?(?=(?:\\\\?|$|/))\")) |>\n  mutate(domain          = domain |> clean_domain()) |>\n\n  # 3. Remove 532 duplicates\n  distinct()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 150,363 × 3\n#>   company_id domain              linkedin_handle          \n#>        <int> <chr>               <chr>                    \n#> 1          1 zana.io             <NA>                     \n#> 2          2 premamawellness.com luna-pharmaceuticals-inc-\n#> 3          3 chainsync.com       chainsync                \n#> # ℹ 150,360 more rows\n```\n:::\n:::\n\n\n--> [145.991]{style=\"color:#cc0000; font-weight: bold;\"} distinct examineable companies.\n\n### CBPB: CLEAN\n\n`Issue:` Some extracted domains are not unique and associated with multiple companies.<br> `Manual Cleaning:` Domains with a count exceeding two were analyzed and set to NA if they do not correspond to the actual one.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# ANALYZE\n# fc_wrangled_tbl |> \n#   distinct(company_id, domain) |> \n#   count(domain, sort = T) |> \n#   filter(n>2)`\n\nunwanted_domains_cb <- c(\"webflow.io\", \"angel.co\", \"weebly.com\", \"wordpress.com\", \"wixsite.com\", \"squarespace.com\", \n                         \"webflow.io\", \"crypt2esports.com\", \"myshopify.com\", \"business.site\", \"mystrikingly.com\", \n                         \"launchrock.com\", \"square.site\", \"google.com\", \"sites.google.com\", \"t.co\", \"linktr.ee\",\n                         \"netlify.app\", \"itunes.apple.com\", \"apple.com\", \"crunchb.com\", \"tumblr.com\", \"linkedin.com\",\n                         \"godaddysites.com\", \"mit.edu\", \"paloaltonetworks.com\", \" wpengine.com\", \"facebook.com\",\n                         \"intuit.com\", \"medium.com\", \"salesforce.com\", \"strikingly.com\", \"wix.com\", \"cisco.com\",\n                         \"digi.me\", \"apps.apple.com\", \"bit.ly\", \"fleek.co\", \"harvard.edu\", \"ibm.com\", \"jimdo.com\",\n                         \"myftpupload.com\", \"odoo.com\", \"storenvy.com\", \"twitter.com\", \"umd.edu\", \"umich.edu\", \"vmware.com\", \"webs.com\")\n\n# Not all observations with unwanted domains are bad per se:\nwanted_ids_cb <- c(angel = 128006, `catapult-centres-uk` = 115854, digime1 = 140904, digimi2 = 95430, fleek = 50738, \n                   jimdo = 108655, medium = 113415, storenvy = 85742, strikingly = 95831, substack = 34304, \n                   tumblr = 84838, twitter = 53139, weebly = 91365, wpengine = 91720)\n\n# Set misleading domains to NA\nfunded_companies_clnd <- fc_wrangled_tbl |> \n                              \n  mutate(domain = if_else(\n    domain %in% unwanted_domains_cb & !(company_id %in% wanted_ids_cb), \n    NA_character_, domain))\n```\n:::\n\n\n### CS: SELECT\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nIt appears that CoreSignal has been able to locate **45.026** companies within our gathered data.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Selection & Wrangle has been done already\ncs_companies_base_slct <- readRDS(\"cs_companies_base_slct.rds\") \ncs_companies_base_slct\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 45,362 × 4\n#>      id name                                domain               linkedin_handle\n#>   <int> <chr>                               <chr>                <chr>          \n#> 1   305 Blueprint, a David's Bridal Company blueprintregistry.c… blueprint-regi…\n#> 2   793 BookingLive                         bookinglive.com      bookinglive    \n#> 3  2425 Brandvee                            momentum.ai          brandvee       \n#> # ℹ 45,359 more rows\n```\n:::\n:::\n\n\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_slct$id |> n_distinct()\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> [1] 45026\n```\n:::\n:::\n\n\n:::\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_slct |> janitor::get_dupes(id)\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 672 × 5\n#>        id dupe_count name          domain           linkedin_handle\n#>     <int>      <int> <chr>         <chr>            <chr>          \n#> 1  596494          2 Vi            vi.co            vitrainer      \n#> 2  596494          2 Vi            vi.co            vi             \n#> 3 1324413          2 Patch Lending patchlending.com patch-of-land  \n#> # ℹ 669 more rows\n```\n:::\n:::\n\n\n:::\n\n### CS: WRANGLE\n\nNothing to wrangle ...\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncs_companies_base_wrangled <- cs_companies_base_slct |> select(-name) |> \n  \n                                        # Add suffixes to col names\n                                        rename_with(~ paste(., \"cs\", sep = \"_\"))\n```\n:::\n\n\n### CS: CLEAN\n\n::: {.callout-important}\nMore cleaning necessary (same as CBPB)! The task was undertaken with a limited degree of enthusiasm.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nunwanted_domains_cs    <- c(\"bit.ly\", \"linktr.ee\", \"facebook.com\", \"linkedin.com\", \"twitter.com\", \"crunchbase.com\")\nwanted_ids_cs          <- c(crunchbase = 1634413, linkedin = 8568581, twitter = 24745469)\n\ncs_companies_base_clnd <- cs_companies_base_wrangled |> \n  \n  mutate(domain_cs = if_else(\n    domain_cs %in% unwanted_domains_cs & !(id_cs %in% wanted_ids_cs), \n    NA_character_, \n    domain_cs)\n    )\n```\n:::\n\n\n\n:::::::\n\n# Data sources II {data-stack-name=\"Data II\"}\n2^nd^ objective: Match `CrunchBase` / `PitchBook` with `CoreSignal` data\n\n## Join *companies*, *member experiences* and *funding* information\n\n::::::: {.panel-tabset}\n\n### Companies\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nWe were able to match [37.287]{.fragment fragment-index=1 style=\"color:#cc0000; font-style: italic;\"} CS & CB/PB companies.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncb_cs_joined <- funded_companies_clnd |> \n\n    # Leftjoins\n    left_join(cs_companies_base_clnd |> select(id_cs, domain_cs),          by = c(domain          = \"domain_cs\"),          na_matches = \"never\") |> \n    left_join(cs_companies_base_clnd |> select(id_cs, linkedin_handle_cs), by = c(linkedin_handle = \"linkedin_handle_cs\"), na_matches = \"never\") |> \n\n    # Remove obs with no cs_id\n    filter(!is.na(id_cs)) |>\n    distinct()\n    \ncb_cs_joined\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 39,536 × 4\n#>   company_id domain              linkedin_handle              id_cs\n#>        <int> <chr>               <chr>                        <int>\n#> 1          2 premamawellness.com luna-pharmaceuticals-inc-  8345218\n#> 2          5 micasense.com       micasense-inc-            28149599\n#> 3          8 spinn.com           <NA>                       4469271\n#> 4         11 mavenclinic.com     <NA>                       5349023\n#> 5         12 fatmap.com          10017145                   9364263\n#> # ℹ 39,531 more rows\n```\n:::\n:::\n\n\n::: {.fragment fragment-index=1}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncb_cs_joined |> distinct(company_id) |> nrow()\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> [1] 37287\n```\n:::\n:::\n\n\n:::\n\n### Jobs (all)\n\nWe got over 430 million (distinct) employment observations from CoreSignal.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Other data versions\n# 1. Complete:  member_experience_dt {462.711.794}\n# 2. Distinct1: member_experience_dist_dt <- unique(member_experience_dt) {432.368.479}\n# 3. Distinct2: unique(member_experience_dist_dt[order(id)], by = setdiff(names(member_experience_dist_dt), \"id\")) {431.899.547}\n\n# Load distinct member experiences\nme_dist2_prqt <- arrow::open_dataset(\"member_experience_dist2.parquet\") \nme_dist2_prqt |> glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 431,899,547 rows x 12 columns\n#> $ member_id                    <int32> 26, 26, 97, 162, 266, 266, 266, 266, 266,…\n#> $ id                          <double> 12, 13, 66, 104, 176, 177, 178, 179, 180,…\n#> $ title                 <large_string> \"Technical solution expert\", \"Technical s…\n#> $ location              <large_string> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n#> $ company_name          <large_string> \"Hewlett-Packard\", \"Dell\", \"IBM\", \"Kony, …\n#> $ company_url           <large_string> \"https://www.linkedin.com/company/hewlett…\n#> $ created      <timestamp[us, tz=UTC]> 2016-07-22 14:25:59, 2016-07-22 14:25:59,…\n#> $ last_updated <timestamp[us, tz=UTC]> 2018-05-09 16:49:53, 2018-05-09 16:49:53,…\n#> $ deleted                      <int32> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n#> $ company_id                   <int32> 20108188, 7035141, 3652437, 10830353, NA,…\n#> $ date_from_parsed       <date32[day]> NA, 2009-02-01, NA, 2015-06-01, 2011-01-0…\n#> $ date_to_parsed         <date32[day]> NA, 2010-07-01, NA, NA, NA, NA, NA, NA, N…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n::: {.callout-warning}\n`deleted` not considered yet!\n:::\n\n### Jobs (focal)\n\nOver 45 million [(valid: must have starting date)]{style=\"color:#cc0000; font-style: italic;\"} employments at our crunchbase / pitchbook data set companies. 385.100 with a title containing the string [founder]{style=\"color:rgb(0, 94, 115); font-style: italic;\"}.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Distinct company ids\ncb_cs_joined_cs_ids <- cb_cs_joined |> distinct(id_cs) |> pull(id_cs)\nme_wrangled_prqt    <- me_dist2_prqt |> \n  \n                          # Select features\n                          select(member_id, company_id, exp_id = \"id\", date_from_parsed) |> \n                          \n                          # Select observations\n                          filter(company_id %in% cb_cs_joined_cs_ids) |> \n                          # - 967.080 observations (date_to not considered yet)\n                          filter(!is.na(date_from_parsed)) |> \n\n                          # Add suffix to col names\n                          rename_with(~ paste(., \"cs\", sep = \"_\")) |> \n                          compute()\n\nme_wrangled_prqt |> \n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> Table\n#> 45,281,582 rows x 4 columns\n#> $ member_id_cs              <int32> 4165082, 4165428, 4165428, 4165428, 4165428,…\n#> $ company_id_cs             <int32> 2483290, 6068905, 6068905, 9020540, 6068905,…\n#> $ exp_id_cs                <double> 5574452, 5574959, 5574962, 5574965, 5574968,…\n#> $ date_from_parsed_cs <date32[day]> 2008-06-01, 2014-01-01, 2008-09-01, 2008-02-…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n### Funding\n\nMultiple Funding Dates --> [Take oldest]{style=\"color:#cc0000;\"}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_wrangled_tbl <- funded_companies_tbl |> \n  \n  # Consider multiple founding dates: Take oldest founding date\n  unnest(founded_on) |> \n  arrange(company_id, founded_on) |> \n  group_by(company_id) |> slice(1) |> ungroup()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.cell-top-margin {\n    margin-top: 0.5rem;\n}\n</style>\n:::\n\n\nExample of funding round data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfc_wrangled_tbl$funding_rounds[[1]] |>  \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> Rows: 15\n#> Columns: 14\n#> $ round_id             <int> 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, …\n#> $ round_uuid_pb        <chr> NA, \"47208-70T\", NA, \"58843-18T\", NA, NA, NA, \"78…\n#> $ round_uuid_cb        <chr> \"a6d3bfd9-5afa-47ce-86de-30a3abad6c9b\", NA, \"ea3b…\n#> $ announced_on         <date> 2013-01-01, 2014-04-01, 2015-06-01, 2015-10-07, …\n#> $ round_new            <int> 1, 2, 3, 4, 5, 6, 7, 8, 8, 9, 10, 11, 12, 12, 13\n#> $ round                <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n#> $ exit_cycle           <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n#> $ last                 <int> 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 1…\n#> $ round_type_new       <fct> Seed, Series A, Series B, Series C, Series D, Ser…\n#> $ round_type           <list> \"angel\", \"angel\", \"early_vc\", \"early_vc\", \"conver…\n#> $ round_types          <list> <\"angel\", \"angel_group\", \"investor\", \"company\", \"…\n#> $ raised_amount        <dbl> NA, 520000, NA, 1399999, NA, NA, NA, 3250000, NA,…\n#> $ post_money_valuation <dbl> NA, NA, NA, 3399998, NA, NA, NA, 10249998, NA, N…\n#> $ investors_in_round   <list> [<tbl_df[1 x 11]>], [<tbl_df[1 x 11]>], [<tbl_df…\n```\n:::\n:::\n\n\n### Conversion\n\n* Joining via `dplyr` due to memory constraint not possible.<br>\n* Joining via `Arrow` due to structure constraints not possible.<br>\n* --> Joining via `data.table` most efficient.<br>\n\nConversion to `data.tables` necessary:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1.  Funding Data\n# 1.1 Level 1\nfc_wrangled_dt |> setDT()\n\n# 1.2 Funding Data Level 2 (funding_rounds)\npurrr::walk(fc_wrangled_dt$funding_rounds, setDT)\n\n# 1.3 Remove unnecessary columns + initialize dummy for before_join\npurrr::walk(fc_wrangled_dt$funding_rounds, ~ .x[, \n          `:=`(round_uuid_pb = NULL, round_uuid_cb        = NULL, round_new          = NULL, round          = NULL,\n               exit_cycle    = NULL, last                 = NULL, round_type         = NULL, round_type_new = NULL, \n               round_types   = NULL, post_money_valuation = NULL, investors_in_round = NULL, before_join    = NA)\n          ]\n        )\n\n# 2. Matching Table\ncb_cs_joined_slct_dt |> setDT()\n\n# 3. Member experiences\nme_wrangled_dt <- me_wrangled_prqt |> collect()\n```\n:::\n\n\n### Join\n\nWorking `data.table` solution (efficiency increase through join `by reference` possible).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Add company_id from funded_companies to member experiences\nme_joined_dt <- cb_cs_joined_slct_dt[me_wrangled_dt, on = .(id_cs = company_id_cs), allow.cartesian = TRUE]\n#> 52.889.683 (before: 45.322.254)\n\n# 2. Add funding data from funded_companies\nme_joined_dt <- fc_wrangled_dt[me_joined_dt, on = .(company_id)]\n#> 52.889.683 \n\n# 3. Remove duplicates (why are there any?)\nme_joined_dt <- unique(me_joined_dt, by = setdiff(names(me_joined_dt), \"funding_rounds\"))\n#> 51.647.887\n```\n:::\n\n\nNot working `dplyr` solution\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nme_joined_dt_dplyr <- me_wrangled_dt |>\n\n  # Add company_id from funded_companies\n  left_join(cb_cs_joined_slct_dt,\n            by = c(company_id_cs = \"id_cs\")) |>\n\n  # Add data from funded_companies\n  left_join(funded_companies_wrangled_dt,\n            by = \"company_id\")  |>\n  distinct()\n```\n:::\n\n\n`Arrow` because of nested funding data not possible.\n\n:::::::\n\n# Analysis {data-stack-name=\"Features\"}\nUsing domain knowledge to extract features\n\n## Feature Engineering\n\n::::::: {.panel-tabset}\n\n### F1: T~join~ - T~found~\n\nHow many month have passed since the company was founded and before the person joined the company (in months)?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(lubridate)\nme_joined_dt[, tjoin_tfound := (interval(founded_on, date_from_parsed_cs) %/% months(1))]\n```\n:::\n\n\n~30 min calculation... (to be measured)\n\n### Prep1\n\nUnnesting necessary due to memory constraints (takes multiple hours ... to be measured).\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Working: data.table\nme_joined_unnested_dt <- me_joined_dt[,rbindlist(funding_rounds), by = setdiff(names(me_joined_dt), \"funding_rounds\")]\n# Not working: dplyr\nme_joined_unnested_tbl <- me_joined_dt |> unnest(funding_rounds)\n```\n:::\n\n\nAdd feature whether or not member joined before Announcement of a funding round:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add feature whether or not member joined before Announcement of a funding round\nme_joined_unnested_dt[,before_join := date_from_parsed_cs >= announced_on]\n\n# Inspect\nopen_dataset(\"me_joined_unnested1.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 380,866,403 rows x 10 columns\n#> $ company_id                <int32> 26340, 26340, 116099, 116099, 116099, 116099…\n#> $ founded_on          <date32[day]> 2016-07-01, 2016-07-01, 2014-01-01, 2014-01-…\n#> $ id_cs                     <int32> 11461260, 11461260, 11825305, 11825305, 1182…\n#> $ experience_id_cs         <double> 1537482593, 1537482593, 1537482603, 15374826…\n#> $ date_from_parsed_cs <date32[day]> 2017-08-01, 2017-08-01, 2013-06-01, 2013-06-…\n#> $ tjoin_tfound             <double> 13, 13, -7, -7, -7, -7, -19, -19, -19, -19, …\n#> $ round_id                  <int32> 98206, 98207, 376508, 376509, 376510, 376511…\n#> $ announced_on        <date32[day]> 2017-06-22, 2019-11-01, 2014-04-17, 2014-08-…\n#> $ raised_amount            <double> 7499984, 19800000, 600000, 3300000, 20500000…\n#> $ before_join                <bool> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n### F2, F3\n\nF2. How much capital has been acquired by the time the person joins?<br>\nF3. How many funding rounds have been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Initialize empty columns (not sure yet if that increases performance)\nme_joined_unnested_dt[, `:=` (raised_amount_before_join = NA_real_, \n                              num_rounds_before_join    = NA_real_)]\n\n# Add features\nme_joined_unnested_dt[, `:=` (raised_amount_before_join = sum(raised_amount[before_join == T], na.rm = T),\n                              num_rounds_before_join    = sum(  before_join[before_join == T])), \n                      by = .(company_id, exp_id_cs)]\n\nopen_dataset(\"me_joined_unnested2.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 380,866,403 rows x 12 columns\n#> $ company_id                 <int32> 26340, 26340, 116099, 116099, 116099, 11609…\n#> $ founded_on           <date32[day]> 2016-07-01, 2016-07-01, 2014-01-01, 2014-01…\n#> $ id_cs                      <int32> 11461260, 11461260, 11825305, 11825305, 118…\n#> $ experience_id_cs          <double> 1537482593, 1537482593, 1537482603, 1537482…\n#> $ date_from_parsed_cs  <date32[day]> 2017-08-01, 2017-08-01, 2013-06-01, 2013-06…\n#> $ tjoin_tfound              <double> 13, 13, -7, -7, -7, -7, -19, -19, -19, -19,…\n#> $ round_id                   <int32> 98206, 98207, 376508, 376509, 376510, 37651…\n#> $ announced_on         <date32[day]> 2017-06-22, 2019-11-01, 2014-04-17, 2014-08…\n#> $ raised_amount             <double> 7499984, 19800000, 600000, 3300000, 2050000…\n#> $ before_join                 <bool> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, FA…\n#> $ raised_amount_before_join <double> 7499984, 7499984, 0, 0, 0, 0, 0, 0, 0, 0, 7…\n#> $ num_rounds_before_join    <double> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n### Prep2\n\nNest again\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# data.table\nexcluded_cols       <- setdiff(names(me_joined_unnested_dt), c(\"round_id\", \"announced_on\", \"raised_amount\", \"before_join\"))\nme_joined_nested_dt <- me_joined_unnested_dt[, list(funding_rounds=list(.SD)), by=excluded_cols]\n\n# Dplyr (not working)\n# me_joined_nested_dt <- me_joined_unnested_dt |> \n#         nest(funding_rounds = c(\"round_id\", \"announced_on\", \"raised_amount\", \"before_join\"))\n\nopen_dataset(\"me_joined_nested.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 51,647,887 rows x 9 columns\n#> $ company_id                 <int32> 26340, 116099, 116099, 26340, 116099, 11609…\n#> $ founded_on           <date32[day]> 2016-07-01, 2014-01-01, 2014-01-01, 2016-07…\n#> $ id_cs                      <int32> 11461260, 11825305, 11825305, 11461260, 118…\n#> $ experience_id_cs          <double> 1537482593, 1537482603, 1537482607, 1666388…\n#> $ date_from_parsed_cs  <date32[day]> 2017-08-01, 2013-06-01, 2012-06-01, 2017-08…\n#> $ tjoin_tfound              <double> 13, -7, -19, 13, -7, -19, 13, -7, -19, 13, …\n#> $ raised_amount_before_join <double> 7499984, 0, 0, 7499984, 0, 0, 7499984, 0, 0…\n#> $ num_rounds_before_join    <double> 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0…\n#> $ funding_rounds         <list<...>> [<tbl_df[2 x 4]>], [<tbl_df[4 x 4]>], [<tbl…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n### Titles\n\nTo differentiate between founder and non-founder CS titles are needed\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prep data (shrink / remove unnecessary data)\nme_joined_nested_foc_dt[, funding_rounds := NULL]\n\n# Prep titles\nme_wrangled_wt_dt <-  me_dist_prqt |> \n                          filter(company_id %in% cb_cs_joined_cs_ids, !is.na(date_from_parsed)) |>  \n                          select(exp_id_cs, title_cs) |> \n                          collect() |> \n                          setDT()\n\n# Join\nme_joined_nested_foc_dt[me_wrangled_wt_dt, on = .(exp_id_cs), title_cs := i.title_cs]\n\n# Inspect\nopen_dataset(\"me_joined_nested_foc.parquet\") |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 51,647,887 rows x 9 columns\n#> $ company_id                 <int32> 26340, 116099, 116099, 26340, 116099, 11609…\n#> $ founded_on           <date32[day]> 2016-07-01, 2014-01-01, 2014-01-01, 2016-07…\n#> $ id_cs                      <int32> 11461260, 11825305, 11825305, 11461260, 118…\n#> $ experience_id_cs          <double> 1537482593, 1537482603, 1537482607, 1666388…\n#> $ date_from_parsed_cs  <date32[day]> 2017-08-01, 2013-06-01, 2012-06-01, 2017-08…\n#> $ tjoin_tfound              <double> 13, -7, -19, 13, -7, -19, 13, -7, -19, 13, …\n#> $ raised_amount_before_join <double> 7499984, 0, 0, 7499984, 0, 0, 7499984, 0, 0…\n#> $ num_rounds_before_join    <double> 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0…\n#> $ title_cs                  <string> \"Software Engineer\", \"Graduate Software Int…\n#> Call `print()` for full schema details\n```\n:::\n:::\n\n\n:::::::\n\n\n# Univariate summary statistics {data-stack-name=\"Plots\"}\nDescribing patterns found in univariate data\n\n## Plots\n\n::::::: {.panel-tabset}\n\n### Data\n\nSeparate between \"Founder\" & \"Non-Founder\" and calculate summary statistics necessary for plotting.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nlookup_term <- \"founder\"\ndata        <- me_joined_nested_foc_prqt |> \n                  filter(!is.na(title_cs)) |> \n                  mutate(Role = title_cs |> tolower() |> str_detect(lookup_term)) |> \n                  collect() |> \n                  mutate(\n                    Role = Role |> factor(levels = c(TRUE, FALSE), \n                                                labels = c('Founder', 'Non-Founder'))\n                    ) \n\n# Summary Statistics (Mean & Median)\ndf_vline_long <- data |> \n                    group_by(Role) |> \n                    # Statistics\n                    summarise(Mean   = mean(tjoin_tfound), \n                              Median = median(tjoin_tfound)) |> \n                    # Manipulate for ggplot \n                    pivot_longer(c(Mean, Median), names_to = \"Statistic\", values_to = \"Value\") |> \n                    mutate(Value    = Value |> round(digits = 1),\n                           gg_pos_y = rep(c(0.07,0.06),2),\n                           gg_color = rep(c(\"#7200FE\", \"#FF7E15\"), 2))\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n<style type=\"text/css\">\n.reveal .column-output-location .column:first-of-type div.sourceCode {\n    height: auto;\n}\n</style>\n:::\n\n\n### F1\n\nHow many month have passed since the company was founded and before the person joined the company (binwidth: 3 months)?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  # Plot\n  ggplot(aes(x = tjoin_tfound, fill = Role, color = Role)) +\n  geom_histogram(aes(y =..density..), size = .2, binwidth = 3, alpha = 0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Statistics & Design\n  ggnewscale::new_scale_color() +\n  geom_vline(data = df_vline_long, aes(xintercept = Value, linetype = Statistic, color = Statistic), key_glyph = \"path\") +\n  scale_linetype_manual(values = c(2,3)) +\n  scale_color_manual(values = c(\"#7200FE\", \"#FF7E15\")) +\n  geom_label(data = df_vline_long, aes(x = 125, y = gg_pos_y, label = paste0(Statistic, ' = ', Value)), \n             color = df_vline_long$gg_color, fill = \"transparent\", alpha = 0.8, size = 3) +\n  xlim(-250, 250) +\n  labs(x = \"Δ T_join, T_foundation (in month)\", y = \"Density\") + \n  theme(legend.key=element_blank())\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot1-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n### F2\n\nHow much capital has been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  # Plot\n  ggplot(aes(x = raised_amount_before_join, color = Role, fill = Role)) + \n  geom_histogram(aes(y =..density..), alpha=0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Design\n  scale_x_continuous(labels = scales::label_number(prefix = \"$\", accuracy = 0.1, scale_cut = scales::cut_short_scale()), limits = c(NA,1e+09)) +\n  labs(x = \"Raised amount before join\", y = \"Density\", fill=\"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot2-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n### F3\n\nHow many funding rounds have been acquired by the time the person joins?\n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\ndata |> \n  \n  ggplot(aes(x = num_rounds_before_join, color = Role, fill = Role)) + \n  geom_histogram(aes(y =..density..), binwidth = 1, alpha=0.5) +\n  facet_wrap(~Role, nrow=2) +\n  \n  # Design\n  xlim(NA, 20) +\n  labs(x = \"# Rounds before join\", y = \"Density\", fill=\"\", color = \"\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/plot3-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n:::::::\n\n## Fortune500\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nme_matched_members_dt <- me_matched_members_prqt |> collect()\n\n# 46 Batches (Chunks with 5 Million rows)\nslice_ids <- tibble(from = seq(1, 230000000, 5000000),to = c(seq(5000000, 225000000, 5000000), 229065592))\nfor (i in 1:46) {\n  # Build Batch\n  x <- slice_ids$from[i]; y <- slice_ids$to[i]\n  me_matched_members_slice_dt <- me_matched_members_dt[x:y,]\n  # Create Features\n  me_matched_members_slice_dt[, `:=` (f500 = (purrr::pmap_lgl(list(company_name, date_from_parsed, date_to_parsed), check_f500, .progress = TRUE)),\n                                      role = title |> tolower() |> stringr::str_detect(\"founder\"))]\n  # Save\n  me_matched_members_slice_dt |> write_parquet(paste0(\"/media/tie/ssd2/joschka/me_f500/me_f500_\", cur_id, \".parquet\"))\n}\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncheck_f500 <- function(name,year_from,year_to) {\n  \n  if (is.na(year_to))   {year_to <- 2023}\n  if (is.na(year_from)) {return(NA)}\n  \n  data <- fortune500 |> \n    filter(year |> between(year_from, year_to)) |> \n    pull(company)\n  \n  name |> tolower() %in% data\n}\n```\n:::\n\n \n# Employment History {data-stack-name=\"Employment History\"}\nMatch current and past employments to corresponding Fortune500 companies\n \n## Employment History (Worked for Fortune 500 company?)\n\n**Content-related problems**\n\n* Matching problems:\n  - amd <> advanced micro devices\n  - intel <> intel corporation\n  \n* Geographical issues:\n  - Just US companies (use Fortune Global data)\n  \n**Technical issues**\n\nTakes loooooooong time to calculate...\n\n## Code I (Data + Function)\n\nFunction\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Function\ncheck_f500 <- function(title, year_from, year_to) {\n  \n  # Handle NA inputs\n  if (is.na(year_to))   {year_to <- 2023}\n  if (is.na(year_from)) {return(NA)}\n  \n  # Filter time frame\n  data <- fortune500 |> \n    \n    filter(year |> between(year_from, year_to)) |> \n    pull(company)\n  \n  # Check match and return bool\n  title |> tolower() %in% data\n}\n```\n:::\n\n\n:::: {.columns}\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n::: {.column width=\"50%\"}\n\nCoreSignal data (n = 229.065.592)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Data\nme_matched_members_prqt <- open_dataset(\"me_matched_members.parquet\") \nme_matched_members_prqt |> \n  \n  head() |> collect()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 6 × 5\n#>         id company_name title                    date_from_parsed date_to_parsed\n#>      <dbl> <chr>        <chr>                               <int>          <int>\n#> 1 24514997 adform       IT Manager                           2014             NA\n#> 2 24514998 rimi baltic  IT Infrastructure Manag…             2013           2014\n#> 3 24514999 rimi lietuva IT Manager                           2011           2013\n#> # ℹ 3 more rows\n```\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\n\nUS Fortune 500 data\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfortune500 <- readRDS(\"fortune_500_1955-2022.rds\") |> \n                \n                select(year, company) |> \n                mutate(company = company |> tolower())\nfortune500\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 34,000 × 2\n#>    year company       \n#>   <dbl> <chr>         \n#> 1  1955 general motors\n#> 2  1955 exxon mobil   \n#> 3  1955 u.s. steel    \n#> # ℹ 33,997 more rows\n```\n:::\n:::\n\n:::\n::::\n\n## Code II (Chunkwise Execution)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Collect data\nme_matched_members_dt <- me_matched_members_prqt |> collect()\n# 2.Build batches\nslice_ids <- tibble(\n  from  = seq(1, 230000000, 5000000),\n  to    = c(seq(5000000, 225000000, 5000000), 229065592),\n)\n\nfor (i in 1:46) {\n\n  # Create current batch  \n  x <- slice_ids$from[i]\n  y <- slice_ids$to[i]\n  me_matched_members_slice_dt <- me_matched_members_dt[x:y,]\n\n  # Add features\n  me_matched_members_slice_dt[, `:=` (f500 = (purrr::pmap_lgl(list(company_name, date_from_parsed, date_to_parsed), check_f500, .progress = TRUE)),\n                                      role = title |> tolower() |> stringr::str_detect(\"founder\"))]\n  \n  # Save\n  me_matched_members_slice_dt |> write_parquet(paste0(\"me_f500/me_f500_\", cur_id, \".parquet\"))\n}\n```\n:::\n\n\n## Code III (Build feature)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# 1. Load data \nme_f500 <- open_dataset(\"me_f500/\") |> \n  collect()\n\n# 2. Add Ids\nme_dist_ids_prqt <- arrow::open_dataset(\"member_experience_dist2.parquet\") |> select(id, member_id) |> collect()\nme_f500_id       <-  me_dist_ids_prqt[me_f500, on = .(id)] \n\n# 3. Add features\n# 3.1 Earliest founding date & earliest f500 date (if founded)\nme_f500_id[,`:=` (founding_min      = (ifelse(any(role == T),                  min(date_from_parsed[role==T]),   NA_real_)),\n                  f500_min_founding = (ifelse(any(role == T) & any(f500 == T), min(date_from_parsed[f500 == T]), NA_real_))),\n           by = .(member_id)]\n\n# 3.2 Compare\nme_f500_id[, f500_before_founding := f500_min_founding <= founding_min]\n```\n:::\n\n\n## Plot\n\nConstraints: \n\n1. \n2. \n\n\n::: {.cell layout-align=\"center\" output-location='column'}\n\n```{.r .cell-code}\nme_f500_id <- arrow::open_dataset(\"~/Downloads/prqt/me_f500_id/\")\n\nme_f500_id |> \n  \n  # Filter \"Founder\"\n  filter(role == T) |> \n  collect() |> \n  \n  ggplot(aes(x = f500_before_founding)) + \n    geom_bar() +\n    scale_x_discrete(labels=c(\"Employment at Fortune500\\nAFTER\\nfounding\", \"Employment at Fortune500\\nBEFORE\\nfounding\", \"Neither case\")) +\n    scale_y_continuous(labels = scales::unit_format(unit = \"M\", scale = 1e-6, accuracy = 0.1)) + \n    labs(x = \"\", y = \"Count\")\n```\n\n::: {.cell-output-display}\n![](cs_files/figure-revealjs/unnamed-chunk-56-1.png){fig-align='center' width=576}\n:::\n:::\n\n\n\n\n# Employment Skills {data-stack-name=\"Skills\"}\nInferences from semantic similarity of LinkedIn users' skills\n \n## Cluster skills\n\ntbd\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmember_skills_prqt <- arrow::open_dataset(\"member_skills.parquet\")\nmember_skills_prqt |> \n  glimpse()\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> FileSystemDataset with 1 Parquet file\n#> 335,291,384 rows x 8 columns\n#> $ member_id                                 <int32> 162, 162, 162, 162, 162, 162…\n#> $ id                                       <double> 1670386535, 1670386536, 1670…\n#> $ skill_id                                  <int32> 148, 149, 172, 168, 472, 358…\n#> $ created                   <timestamp[us, tz=UTC]> 2017-03-15 09:52:27, 2017-03…\n#> $ last_updated              <timestamp[us, tz=UTC]> 2018-07-09 10:33:09, 2018-07…\n#> $ deleted                                   <int32> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#> $ member_skill_list_created <timestamp[us, tz=UTC]> 2016-07-22 14:26:16, 2016-07…\n#> $ member_skill_list_updated <timestamp[us, tz=UTC]> 2016-07-22 14:26:16, 2016-07…\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nskill_names_tbl <- readRDS(\"skill_names_tbl.rds\")\nskill_names_tbl\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```{.hscroll}\n#> # A tibble: 2,423,690 × 2\n#>   skill_id skill_name \n#>      <int> <fct>      \n#> 1        1 mathematics\n#> 2        2 swimming   \n#> 3        3 analytics  \n#> # ℹ 2,423,687 more rows\n```\n:::\n:::\n\n\n# Next Steps {data-stack-name=\"Next Steps\"}\n\n## Further analysis is necessary\n\n* Match employment history with Fortune500 (revenue based selection)\n* Cluster job titles\n* Cluster skills\n\n. . .\n\n![](https://c.tenor.com/3EYd9ID79vcAAAAd/mic-drop-the-voice.gif){fig-align=\"center\" width=50%}\n",
    "supporting": [
      "cs_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}